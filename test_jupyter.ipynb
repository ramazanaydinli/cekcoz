{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03df5ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file will be used for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6da3f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In cwd there is a directory called \"single_image_testing\", put the image you want to test in that directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a4a87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55129d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "test_dir_path = os.path.join(cwd, \"single_image_testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76b19d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\METE\\Desktop\\cekcoz_main\\single_image_testing\\A001259.png\n"
     ]
    }
   ],
   "source": [
    "filename=os.listdir(test_dir_path)[0]\n",
    "file_path = os.path.join(test_dir_path, filename)\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb113f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "img = cv.imread(file_path)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e800130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_fn(image, detection_model):\n",
    "    \"\"\"Detect objects in image.\"\"\"\n",
    "\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74a4a297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_object_detection_results(image_np, detections, category_index, label_id_offset=1):\n",
    "    \"\"\"\n",
    "    Displays object detection results labeled on input image\n",
    "    :param image_np: numpy formatted image\n",
    "    :param detections: detection results\n",
    "    :param category_index: detection class index\n",
    "    :param label_id_offset: class index - label name dict\n",
    "    :return: None (shows detection result)\n",
    "    \"\"\"\n",
    "    image_np_with_detections = image_np.copy()\n",
    "    from object_detection.utils import visualization_utils as viz_utils\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np_with_detections,\n",
    "        detections['detection_boxes'],\n",
    "        detections['detection_classes'] + label_id_offset,\n",
    "        detections['detection_scores'],\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        max_boxes_to_draw=200,\n",
    "        min_score_thresh=0.3,\n",
    "        agnostic_mode=False,\n",
    "        line_thickness=1,\n",
    "        skip_scores=True,\n",
    "        skip_labels = True)\n",
    "    cv.imshow(\"image with detections\", image_np_with_detections)\n",
    "    cv.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee6b102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(box, detection_class, score, label_id_offset=1):\n",
    "    \"\"\"\n",
    "    Taking TensforFlow formatted information and formats them for easy usage\n",
    "    :param box: obj det bboxes\n",
    "    :param detection_class: class of the detected object\n",
    "    :param score: detection score\n",
    "    :param label_id_offset: Highly likely equals to 1 ( for offset purpose)\n",
    "    :return: returns the list including information with some logic\n",
    "    \"\"\"\n",
    "    return list([box[0], box[1], box[2], box[3], detection_class + label_id_offset, score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8f81529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ambiguous_detections(threshold, data_list, category_index, img_width, img_height):\n",
    "    \"\"\"\n",
    "    Will take object detection results and remove doubtfull detections\n",
    "    :param threshold: confidence score, detections has lower than this score will be removed\n",
    "    :param data_list: list containing object detection results\n",
    "    :param category_index: index of the classes\n",
    "    :param img_width: x-pixel value of the current image\n",
    "    :param img_height: y-pixel value of the current image\n",
    "    :return: returns list which has cleared all ambigous detections\n",
    "    \"\"\"\n",
    "    new_data_list = []\n",
    "    for whole_values in data_list:\n",
    "        dummy_list = []\n",
    "        if whole_values[5] > threshold:\n",
    "            label_name = (category_index.get(int(whole_values[4]))).get(\"name\")\n",
    "            ymin = int(whole_values[0] * img_height)\n",
    "            xmin = int(whole_values[1] * img_width)\n",
    "            ymax = int(whole_values[2] * img_height)\n",
    "            xmax = int(whole_values[3] * img_width)\n",
    "            dummy_list.append(ymin)\n",
    "            dummy_list.append(xmin)\n",
    "            dummy_list.append(ymax)\n",
    "            dummy_list.append(xmax)\n",
    "            dummy_list.append(label_name)\n",
    "            new_data_list.append(dummy_list)\n",
    "    return new_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6969095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import time\n",
    "\n",
    "def read_text_on_image(path):\n",
    "    \"\"\"\n",
    "    Reads text on image\n",
    "    :param path: input image path\n",
    "    :return: ocr text\n",
    "    \"\"\"\n",
    "\n",
    "    subscription_key = \"d9db8bd3bed7440a86b510dca41abdc6\"\n",
    "    endpoint = \"https://cekcozocr.cognitiveservices.azure.com/\"\n",
    "\n",
    "    computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "\n",
    "    read_image_path = path\n",
    "    # Open the image\n",
    "    read_image = open(read_image_path, \"rb\")\n",
    "\n",
    "    # Call API with image and raw response (allows you to get the operation location)\n",
    "    read_response = computervision_client.read_in_stream(read_image, raw=True)\n",
    "    # Get the operation location (URL with ID as last appendage)\n",
    "    read_operation_location = read_response.headers[\"Operation-Location\"]\n",
    "    # Take the ID off and use to get results\n",
    "    operation_id = read_operation_location.split(\"/\")[-1]\n",
    "\n",
    "    # Call the \"GET\" API and wait for the retrieval of the results\n",
    "    while True:\n",
    "        read_result = computervision_client.get_read_result(operation_id)\n",
    "        if read_result.status.lower() not in ['notstarted', 'running']:\n",
    "            break\n",
    "        print('Waiting for result...')\n",
    "        time.sleep(3)\n",
    "\n",
    "    reading_results = []\n",
    "    # Print results, line by line\n",
    "    if read_result.status == OperationStatusCodes.succeeded:\n",
    "        for text_result in read_result.analyze_result.read_results:\n",
    "            for line in text_result.lines:\n",
    "                dummy_list = [line.text, line.bounding_box]\n",
    "                reading_results.append(dummy_list)\n",
    "    return reading_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6591c587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ocr_results(ocr_results):\n",
    "    \"\"\"\n",
    "    Removing bad reading characters\n",
    "    :param ocr_results: initial reading results\n",
    "    :return: cleansed results\n",
    "    \"\"\"\n",
    "    # A list of meaningless readings. You can extend this list as required\n",
    "    meaningless_readings = [\"-\"]\n",
    "\n",
    "    # Filter out results with meaningless readings\n",
    "    cleaned_results = [result for result in ocr_results if result[0] not in meaningless_readings]\n",
    "\n",
    "    return cleaned_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9755b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_spacings(spacing_bbox, readings):\n",
    "    \"\"\"\n",
    "    Takes detection results classified as \"spacing\" and matching them with corresponding reading\n",
    "    :param spacing_bbox: bbox of spacing instance\n",
    "    :param readings: ocr readings\n",
    "    :return: list [[ocr reading], [reading bbox], [obj det bbox]]\n",
    "    \"\"\"\n",
    "    final_results = []\n",
    "    for bbox in spacing_bbox:\n",
    "        threshold = adjust_threshold(bbox)\n",
    "        filtered_ocr_results = filter_results_by_distance(bbox, readings, threshold)\n",
    "        if filtered_ocr_results:\n",
    "            for item in filtered_ocr_results:\n",
    "                result = [[item[0]], item[1], bbox]\n",
    "                final_results.append(result)\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdff1940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_secondary_filter_distance(matching_results):\n",
    "    \"\"\"\n",
    "    Filters readings to remove absurd characters\n",
    "    :param matching_results: first filter results\n",
    "    :return: input with bad readings removed\n",
    "    \"\"\"\n",
    "    pattern = r\"(\\d+([.]\\d+)?|(\\d+\\s*/\\s*\\d+))\\s*(m|meters?)\"\n",
    "    for item in matching_results:\n",
    "        reading = item[0][0]\n",
    "        match = re.search(pattern, reading)\n",
    "        if match:\n",
    "            extracted_value = match.group()\n",
    "            item[0][0] = extracted_value  # Update the original reading with the extracted value\n",
    "    return matching_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac8b7b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_value_unit(sec_filtered_results):\n",
    "    \"\"\"\n",
    "    Extracts precise value and units from ocr text\n",
    "    :param sec_filtered_results: text results after two times filtering\n",
    "    :return: replacing input's text part with a list containing unit and value\n",
    "    \"\"\"\n",
    "    # regex pattern to match value and unit (supports meter, m, feet, ft, inch)\n",
    "    pattern = r'(\\d+)\\s*(meters?|ft|feet|inch(?:es)?|m)'\n",
    "    for element in sec_filtered_results:\n",
    "        match = re.search(pattern, element[0][0], re.IGNORECASE)\n",
    "        if match:\n",
    "            value, unit = match.groups()\n",
    "            element[0] = [int(value), unit]\n",
    "    return sec_filtered_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd9f7f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting_key(entry):\n",
    "    \"\"\"\n",
    "    Sorts dimensions according to avg_x and then by avg_y in reverse order\n",
    "    :param entry: List containing spacing info\n",
    "    :return: tuple used for sorting\n",
    "    \"\"\"\n",
    "    # Extract object detection bounding box\n",
    "    y1, x1, y2, x2 = entry[2]\n",
    "    avg_x = (x1 + x2) / 2\n",
    "    avg_y = (y1 + y2) / 2\n",
    "    # Return a tuple where avg_x is the primary key and -avg_y is the secondary key\n",
    "    return (avg_x, -avg_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79d30a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimension_direction(sorted_spacings, img):\n",
    "    \"\"\"\n",
    "    Decides direction of the dimension using pixel values\n",
    "    :param sorted_spacings: list of spacings\n",
    "    :param img: input image\n",
    "    :return: adds direction to the input list and returns it back\n",
    "    \"\"\"\n",
    "    sorted_spacing_with_direction = []\n",
    "    for spacing_info in sorted_spacings:\n",
    "        y1, x1, y2, x2 = spacing_info[2]\n",
    "        roi = img[y1:y2, x1:x2]\n",
    "        gray = cv.cvtColor(roi, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Threshold the image\n",
    "        _, thresh = cv.threshold(gray, 200, 255, cv.THRESH_BINARY_INV)  # Adjust the threshold value as needed\n",
    "\n",
    "        # Sum along x and y axes\n",
    "        sum_x = np.sum(thresh, axis=0)\n",
    "        sum_y = np.sum(thresh, axis=1)\n",
    "\n",
    "        # Check where the predominant sum is\n",
    "        x_peak = np.max(sum_x)\n",
    "        y_peak = np.max(sum_y)\n",
    "\n",
    "        # Decide the direction based on the peaks\n",
    "        if x_peak > 1.5 * y_peak:  # Adjust the factor as needed\n",
    "            direction = \"vertical\"\n",
    "        elif y_peak > 1.5 * x_peak:\n",
    "            direction = \"horizontal\"\n",
    "        else:\n",
    "            direction = \"angled\"\n",
    "\n",
    "        spacing_info.append(direction)\n",
    "\n",
    "        # Append the updated spacing_info to the global list\n",
    "        sorted_spacing_with_direction.append(spacing_info)\n",
    "\n",
    "    return sorted_spacing_with_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75348468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(sorted_spacings_with_directions):\n",
    "    \"\"\"\n",
    "    Initializes base classes for question\n",
    "    :param sorted_spacings_with_directions: list containing spacing information\n",
    "    :return: created instances of nodes and spacings\n",
    "    \"\"\"\n",
    "    spacing_instances = []\n",
    "    node_instances = []\n",
    "    shape_x_start = 0\n",
    "    shape_y_start = 0\n",
    "    for spacing_info in sorted_spacings_with_directions:\n",
    "        if not spacing_instances:\n",
    "            if spacing_info[3] == \"horizontal\":\n",
    "                y1, x1, y2, x2 = spacing_info[2]\n",
    "                distance = spacing_info[0][0]\n",
    "                unit = spacing_info[0][1]\n",
    "                obj_det_bbox = spacing_info[2]\n",
    "                text_bbox = spacing_info[1]\n",
    "                bbox_x = x1\n",
    "                bbox_y = int((y1 + y2) / 2)\n",
    "                node_1 = Node(bbox_x, bbox_y, shape_x_start, shape_y_start)\n",
    "                node_instances.append(node_1)\n",
    "                bbox_x = x2\n",
    "                bbox_y = int((y1 + y2) / 2)\n",
    "                node_2 = Node(bbox_x, bbox_y, shape_x_start + int(distance), shape_y_start)\n",
    "                node_instances.append(node_2)\n",
    "                spacing = Dimension(node_1, node_2, distance, unit, obj_det_bbox, text_bbox)\n",
    "                spacing_instances.append(spacing)\n",
    "            elif spacing_info[3] == \"vertical\":\n",
    "                y1, x1, y2, x2 = spacing_info[2]\n",
    "                distance = spacing_info[0][0]\n",
    "                unit = spacing_info[0][1]\n",
    "                obj_det_bbox = spacing_info[2]\n",
    "                text_bbox = spacing_info[1]\n",
    "                bbox_x = int(x1 + x2) / 2\n",
    "                bbox_y = y1\n",
    "                node_1 = Node(bbox_x, bbox_y, shape_x_start, shape_y_start)\n",
    "                node_instances.append(node_1)\n",
    "                bbox_x = int(x1 + x2) / 2\n",
    "                bbox_y = y2\n",
    "                node_2 = Node(bbox_x, bbox_y, shape_x_start, shape_y_start + int(distance))\n",
    "                node_instances.append(node_2)\n",
    "                spacing = Dimension(node_1, node_2, distance, unit, obj_det_bbox, text_bbox)\n",
    "                spacing_instances.append(spacing)\n",
    "            else:\n",
    "                # code the nodes for angled dimensioning\n",
    "                pass\n",
    "        else:\n",
    "            if spacing_info[3] == \"horizontal\":\n",
    "                y1, x1, y2, x2 = spacing_info[2]\n",
    "                distance = spacing_info[0][0]\n",
    "                unit = spacing_info[0][1]\n",
    "                obj_det_bbox = spacing_info[2]\n",
    "                text_bbox = spacing_info[1]\n",
    "                bbox_x = x1\n",
    "                bbox_y = int(y1 + y2) / 2\n",
    "                node_1 = Node(bbox_x=bbox_x, bbox_y=bbox_y)\n",
    "                bbox_x = x2\n",
    "                bbox_y = int(y1 + y2) / 2\n",
    "                node_2 = Node(bbox_x=bbox_x, bbox_y=bbox_y)\n",
    "                # psc_node = previous spacing closest node\n",
    "                # cc_node = current closest node\n",
    "                psc_node, cc_node = find_closest_node_of_previous_spacing(spacing_instances[-1], node_1, node_2)\n",
    "                if cc_node == node_1:\n",
    "                    node_2.shape_x = psc_node.shape_x + distance\n",
    "                    node_2.shape_y = psc_node.shape_y\n",
    "                    node_instances.append(node_2)\n",
    "                    spacing = Dimension(psc_node, node_2, distance, unit, obj_det_bbox, text_bbox)\n",
    "                    spacing_instances.append(spacing)\n",
    "                else:\n",
    "                    node_1.shape_x = psc_node.shape_x - distance\n",
    "                    node_1.shape_y = psc_node.shape_y\n",
    "                    node_instances.append(node_1)\n",
    "                    spacing = Dimension(node_1, psc_node, distance, unit, obj_det_bbox, text_bbox)\n",
    "                    spacing_instances.append(spacing)\n",
    "            elif spacing_info[3] == \"vertical\":\n",
    "                y1, x1, y2, x2 = spacing_info[2]\n",
    "                distance = spacing_info[0][0]\n",
    "                unit = spacing_info[0][1]\n",
    "                obj_det_bbox = spacing_info[2]\n",
    "                text_bbox = spacing_info[1]\n",
    "                bbox_x = int(x1 + x2) / 2\n",
    "                bbox_y = y1\n",
    "                node_1 = Node(bbox_x=bbox_x, bbox_y=bbox_y)\n",
    "                bbox_x = int(x1 + x2) / 2\n",
    "                bbox_y = y2\n",
    "                node_2 = Node(bbox_x=bbox_x, bbox_y=bbox_y)\n",
    "                # psc_node = previous spacing closest node\n",
    "                # cc_node = current closest node\n",
    "                psc_node, cc_node = find_closest_node_of_previous_spacing(spacing_instances[-1], node_1, node_2)\n",
    "                if cc_node == node_1:\n",
    "                    node_2.shape_x = psc_node.shape_x\n",
    "                    node_2.shape_y = psc_node.shape_y - distance\n",
    "                    node_instances.append(node_2)\n",
    "                    spacing = Dimension(psc_node, node_2, distance, unit, obj_det_bbox, text_bbox)\n",
    "                    spacing_instances.append(spacing)\n",
    "                else:\n",
    "                    node_1.shape_x = psc_node.shape_x\n",
    "                    node_1.shape_y = psc_node.shape_y + distance\n",
    "                    node_instances.append(node_1)\n",
    "                    spacing = Dimension(node_1, psc_node, distance, unit, obj_det_bbox, text_bbox)\n",
    "                    spacing_instances.append(spacing)\n",
    "            else:\n",
    "                pass\n",
    "    return spacing_instances, node_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdc1defc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_threshold(bbox):\n",
    "    \"\"\"\n",
    "    Dynamically adjusts threshold for \"filter_results_by_distance\" function\n",
    "    Logic is finding smaller axis (x or y) and adds some pixel to that axis length\n",
    "    :param bbox: bbox of the object\n",
    "    :return: calculated threshold value\n",
    "    \"\"\"\n",
    "    if bbox[3]-bbox[1] > bbox[2]-bbox[0]:\n",
    "        return bbox[2]-bbox[0]+10\n",
    "    else:\n",
    "        return bbox[3]-bbox[1] + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e42332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_center_ocr(bbox):\n",
    "    \"\"\"\n",
    "    Computes center point of ocr reading\n",
    "    :param bbox: bbox in format [x1, y1, x2, y2, x3, y3, x4, y4] (starts from top left order is clockwise)\n",
    "    :return: avg_x, avg_y\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2, x3, y3, x4, y4 = bbox\n",
    "    center_x = (x1 + x3) / 2\n",
    "    center_y = (y1 + y3) / 2\n",
    "    return center_x, center_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "882b1167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_center_obj(bbox):\n",
    "    \"\"\"\n",
    "    Computes center point of bbox\n",
    "    :param bbox: bbox in format [y1,x1,y2,x2]\n",
    "    :return: avg_x, avg_y\n",
    "    \"\"\"\n",
    "    y1, x1, y2, x2 = bbox\n",
    "    center_x = (x1 + x2) / 2\n",
    "    center_y = (y1 + y2) / 2\n",
    "    return center_x, center_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a20bb723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(center1, center2):\n",
    "    \"\"\"\n",
    "    Calculates distance between [x1,y1] and [x2,y2]\n",
    "    :param center1: center coordinates of first point\n",
    "    :param center2: center coordinates of second point\n",
    "    :return: distance\n",
    "    \"\"\"\n",
    "    return ((center1[0] - center2[0])**2 + (center1[1] - center2[1])**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78f45966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_reading_distance(reading):\n",
    "    \"\"\"\n",
    "    Checks if reading fits pattern considering distance units\n",
    "    (only check if it contains units, secondary regex will be done)\n",
    "    :param reading: reading results obtained from ocr\n",
    "    :return: returns reading if it fits pattern\n",
    "    \"\"\"\n",
    "    pattern = r\"(\\d+\\s*(?:meters?|ft|feet|inch(?:es)?|m))\"\n",
    "    return re.search(pattern, reading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "149a7c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_results_by_distance(obj_detection_bbox, ocr_results, threshold):\n",
    "    \"\"\"\n",
    "    Narrowing down possible matches for obj's and ocr's by discarding values farther away than threshold\n",
    "    :param obj_detection_bbox: bbox of object\n",
    "    :param ocr_results: bbox of ocr reading\n",
    "    :param threshold: limit value, after calculating center of obj bbox and ocr reading bbox,\n",
    "    if calculated value is more than threshold, that value will be discarded\n",
    "    :return: returns readings within threshold value\n",
    "    \"\"\"\n",
    "    filtered_results = []\n",
    "    obj_center = compute_center_obj(obj_detection_bbox)\n",
    "\n",
    "    for result in ocr_results:\n",
    "        reading, ocr_bbox = result\n",
    "        if not is_valid_reading_distance(reading):  # check if the reading is valid\n",
    "            continue\n",
    "        ocr_center = compute_center_ocr(ocr_bbox)\n",
    "        distance = euclidean_distance(obj_center, ocr_center)\n",
    "        if distance < threshold:\n",
    "            filtered_results.append(result)\n",
    "\n",
    "    return filtered_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "388af35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Dimension:\n",
    "    def __init__(self, node_1=None, node_2=None, value=None, unit=None, obj_det_bbox=None, text_bbox=None):\n",
    "        self.node_1 = node_1\n",
    "        self.node_2 = node_2\n",
    "        self.value = value\n",
    "        self.unit = unit\n",
    "        self.obj_det_bbox = obj_det_bbox\n",
    "        self.text_bbox = text_bbox\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"Dimension(node_1={self.node_1}, node_2={self.node_2}, value={self.value}, \"\n",
    "                f\"unit={self.unit}, obj_det_bbox={self.obj_det_bbox}, text_bbox={self.text_bbox})\")\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, bbox_x=None, bbox_y=None, shape_x=None, shape_y=None, name=None):\n",
    "        self.bbox_x = bbox_x\n",
    "        self.bbox_y = bbox_y\n",
    "        self.shape_x = shape_x\n",
    "        self.shape_y = shape_y\n",
    "        self.name = name\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Node):\n",
    "            return (self.bbox_x == other.bbox_x and self.bbox_y == other.bbox_y\n",
    "                    and self.shape_x == other.shape_x and self.shape_y == other.shape_y\n",
    "                    and self.name == other.name)\n",
    "        return False\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Node(name={self.name}, bbox_x={self.bbox_x}, bbox_y={self.bbox_y}, shape_x={self.shape_x},\" \\\n",
    "               f\" shape_y={self.shape_y})\"\n",
    "\n",
    "\n",
    "class FixSupport:\n",
    "    def __init__(self, node=None, fx=0, fy=0, moment=0):\n",
    "        self.node = node\n",
    "        self.fx = fx\n",
    "        self.fy = fy\n",
    "        self.moment = moment\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"FixSupport(node={self.node}, Fx={self.fx}, Fy={self.fy}, Moment={self.moment})\"\n",
    "\n",
    "\n",
    "class PinSupport:\n",
    "    def __init__(self, node=None, fx=0, fy=0):\n",
    "        self.fx = fx\n",
    "        self.fy = fy\n",
    "        self.node = node\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"PinSupport(node={self.node}, Fx={self.fx}, Fy={self.fy})\"\n",
    "\n",
    "\n",
    "class RollerSupport:\n",
    "    def __init__(self, node=None, fy=0):\n",
    "        self.fy = fy\n",
    "        self.node = node\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"RollerSupport(node={self.node}, Fy={self.fy})\"\n",
    "\n",
    "\n",
    "class Frame:\n",
    "    def __init__(self, node1=None, node2=None, obj_det_bbox=None, direction=None):\n",
    "        self.node_1 = node1\n",
    "        self.node_2 = node2\n",
    "        self.obj_det_bbox = obj_det_bbox\n",
    "        self.direction = direction\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Frame(node_1={repr(self.node_1)}, node_2={repr(self.node_2)}, obj_det_bbox={self.obj_det_bbox},\" \\\n",
    "               f\" direction={self.direction})\"\n",
    "\n",
    "\n",
    "class PointLoad:\n",
    "    def __init__(self, node=None, direction=None, value=None, unit=None, text_bbox=None, obj_det_bbox=None):\n",
    "        self.node = node\n",
    "        self.direction = direction\n",
    "        self.value = value\n",
    "        self.unit = unit\n",
    "        self.text_bbox = text_bbox\n",
    "        self.obj_det_bbox = obj_det_bbox\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"PointLoad(node={self.node}, direction={self.direction}, value={self.value}, unit={self.unit},\" \\\n",
    "               f\" text_bbox = {self.text_bbox}, obj_det_bbox = {self.obj_det_bbox})\"\n",
    "\n",
    "class DistributedLoad:\n",
    "    def __init__(self, node1=None, node2=None,obj_det_bbox = None, direction=None, value=None, unit=None):\n",
    "        self.node1 = node1\n",
    "        self.node2 = node2\n",
    "        self.obj_det_bbox = obj_det_bbox\n",
    "        self.direction = direction\n",
    "        self.value = value\n",
    "        self.unit = unit\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"DistributedLoad(node1={self.node1}, node2={self.node2}, obj_det_bbox={self.obj_det_bbox}, direction={self.direction}, value={self.value}, unit={self.unit})\"\n",
    "\n",
    "class TriangularDistributedLoad:\n",
    "    def __init__(self, node1=None, node2=None,obj_det_bbox = None, direction=None, value1=None, value2=None, unit=None):\n",
    "        self.node1 = node1\n",
    "        self.node2 = node2\n",
    "        self.obj_det_bbox = obj_det_bbox\n",
    "        self.direction = direction\n",
    "        self.value1 = value1\n",
    "        self.value2 = value2\n",
    "        self.unit = unit\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"TriangularDistributedLoad(node1={self.node1}, node2={self.node2}, obj_det_bbox={self.obj_det_bbox}, direction={self.direction}, value1={self.value1}, value2={self.value2}, unit={self.unit})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "65a5fbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_shapes(node_list):\n",
    "    \"\"\"\n",
    "    Nodes with negative values are corrected in this function\n",
    "    :param node_list: list of nodes\n",
    "    :return: corrected list of nodes\n",
    "    \"\"\"\n",
    "    # Find the minimum shape_x and shape_y values\n",
    "    min_shape_x = min(node.shape_x for node in node_list)\n",
    "    min_shape_y = min(node.shape_y for node in node_list)\n",
    "\n",
    "    # Calculate the offsets required to make the smallest shape values zero\n",
    "    offset_x = abs(min_shape_x) if min_shape_x < 0 else 0\n",
    "    offset_y = abs(min_shape_y) if min_shape_y < 0 else 0\n",
    "\n",
    "    # Apply the offsets to all node instances\n",
    "    for node in node_list:\n",
    "        node.shape_x += offset_x\n",
    "        node.shape_y += offset_y\n",
    "\n",
    "    return node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b5129f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_append_missing_nodes(node_instances):\n",
    "    \"\"\"\n",
    "    Creates missing nodes according to every definable point\n",
    "    :param node_instances: Raw (negative value corrected) node points\n",
    "    :return: New list (if any new node created in the process)\n",
    "    \"\"\"\n",
    "    # Extract unique shape_x and shape_y values\n",
    "    unique_shape_x = {node.shape_x for node in node_instances}\n",
    "    unique_shape_y = {node.shape_y for node in node_instances}\n",
    "\n",
    "    # Generate all possible combinations based on the unique values\n",
    "    shape_combinations = set(itertools.product(unique_shape_x, unique_shape_y))\n",
    "\n",
    "    # Identify existing combinations from node_instances\n",
    "    existing_shapes = {(node.shape_x, node.shape_y) for node in node_instances}\n",
    "\n",
    "    # Identify missing combinations\n",
    "    missing_shapes = shape_combinations - existing_shapes\n",
    "\n",
    "    # For each missing shape combination, create and append a new node to node_instances\n",
    "    for shape_x, shape_y in missing_shapes:\n",
    "        node_for_shape_x = next((node for node in node_instances if node.shape_x == shape_x), None)\n",
    "        node_for_shape_y = next((node for node in node_instances if node.shape_y == shape_y), None)\n",
    "\n",
    "        bbox_x = node_for_shape_x.bbox_x if node_for_shape_x else None\n",
    "        bbox_y = node_for_shape_y.bbox_y if node_for_shape_y else None\n",
    "\n",
    "        missing_node = Node(bbox_x=bbox_x, bbox_y=bbox_y, shape_x=shape_x, shape_y=shape_y)\n",
    "        node_instances.append(missing_node)\n",
    "\n",
    "    return node_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "04c88c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_names_to_nodes(node_instances, ocr_results, distance_threshold=100):\n",
    "    \"\"\"\n",
    "    Appends name to the nodes, node names are generally symbolized with one character (A,B,C, etc.)\n",
    "    Closest reading mathching to this pattern is appended if reading is in the threshold value\n",
    "    :param node_instances: node list\n",
    "    :param ocr_results: ocr text\n",
    "    :param distance_threshold: pixel value\n",
    "    :return: name appended node list\n",
    "    \"\"\"\n",
    "    pattern = r'^[A-Za-z]$'\n",
    "    for text, bbox in ocr_results:\n",
    "        if re.match(pattern, text):  # Check if the text is a single letter (either uppercase or lowercase)\n",
    "            center_x = sum(bbox[i] for i in [0, 2, 4, 6]) / 4\n",
    "            center_y = sum(bbox[i] for i in [1, 3, 5, 7]) / 4\n",
    "\n",
    "            distances = [(node, euclidean_distance([center_x, center_y], [node.bbox_x, node.bbox_y]))\n",
    "                         for node in node_instances]\n",
    "            closest_node, min_distance = min(distances, key=lambda x: x[1])\n",
    "\n",
    "            if min_distance <= distance_threshold:\n",
    "                closest_node.name = text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "24d7677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_support_instances(support_bbox, node_instances):\n",
    "    \"\"\"\n",
    "    Creating support instances according to the obj det support instances\n",
    "    :param support_bbox: bbox coordinates and class information of supports\n",
    "    :param node_instances: node information\n",
    "    :return: created support classes which also has their own nodes appended\n",
    "    \"\"\"\n",
    "    fix_support_instances = []\n",
    "    pin_support_instances = []\n",
    "    roller_support_instances = []\n",
    "    for bbox in support_bbox:\n",
    "        center_x = (bbox[1] + bbox[3]) / 2\n",
    "        center_y = (bbox[0] + bbox[2]) / 2\n",
    "        closest_node = min(node_instances, key=lambda node: euclidean_distance([center_x, center_y], [node.bbox_x, node.bbox_y]))\n",
    "        if bbox[-1] == 'fix_support':\n",
    "            fix_support_instances.append(FixSupport(node=closest_node))\n",
    "        elif bbox[-1] == 'pin_support':\n",
    "            pin_support_instances.append(PinSupport(node=closest_node))\n",
    "        elif bbox[-1] == 'roller_support':\n",
    "            roller_support_instances.append(RollerSupport(node=closest_node))\n",
    "        else:\n",
    "            pass\n",
    "    return fix_support_instances, pin_support_instances, roller_support_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4be8ddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_frame_direction(frame_boxes, img):\n",
    "    \"\"\"\n",
    "    Finds and appends direction of the frame\n",
    "    :param frame_boxes: bbox info of frame\n",
    "    :param img: input image\n",
    "    :return: direction appended bbox list\n",
    "    \"\"\"\n",
    "    for frame_info in frame_boxes:\n",
    "        y1,x1,y2,x2 = frame_info[:4]\n",
    "        roi = img[y1:y2, x1:x2]\n",
    "        gray = cv.cvtColor(roi, cv.COLOR_BGR2GRAY)\n",
    "         # Threshold the image\n",
    "        _, thresh = cv.threshold(gray, 200, 255, cv.THRESH_BINARY_INV)  # Adjust the threshold value as needed\n",
    "\n",
    "        # Sum along x and y axes\n",
    "        sum_x = np.sum(thresh, axis=0)\n",
    "        sum_y = np.sum(thresh, axis=1)\n",
    "\n",
    "        # Check where the predominant sum is\n",
    "        x_peak = np.max(sum_x)\n",
    "        y_peak = np.max(sum_y)\n",
    "\n",
    "        # Decide the direction based on the peaks\n",
    "        if x_peak > 1.5 * y_peak:  # Adjust the factor as needed\n",
    "            direction = \"vertical\"\n",
    "        elif y_peak > 1.5 * x_peak:\n",
    "            direction = \"horizontal\"\n",
    "        else:\n",
    "            direction = \"angled\"\n",
    "        frame_info.append(direction)\n",
    "    return frame_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "94b014cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_frames(frame_boxes, node_instances):\n",
    "    \"\"\"\n",
    "    Creates instances of frames\n",
    "    :param frame_boxes: bbox list of frames\n",
    "    :param node_instances: list of nodes\n",
    "    :return: list of frame instances\n",
    "    \"\"\"\n",
    "    frame_instances = []\n",
    "    for box in frame_boxes:\n",
    "        if box[5] == \"horizontal\":\n",
    "            x1 = box[1]\n",
    "            x2 = box[3]\n",
    "            y = int((box[0] + box[2]) / 2)\n",
    "\n",
    "            # Get the closest node to x1 and x2\n",
    "            c_node1 = find_closest_node(x1, y, node_instances)\n",
    "            c_node2 = find_closest_node(x2, y, node_instances)\n",
    "\n",
    "            frame_instance = Frame(node1=c_node1, node2=c_node2)\n",
    "            frame_instances.append(frame_instance)\n",
    "        elif box[5] == \"vertical\":\n",
    "            y1 = box[0]\n",
    "            y2 = box[2]\n",
    "            x = int((box[1] + box[3]) / 2)\n",
    "            # Get the closest node to x1 and x2\n",
    "            c_node1 = find_closest_node(x, y1, node_instances)\n",
    "            c_node2 = find_closest_node(x, y2, node_instances)\n",
    "\n",
    "            frame_instance = Frame(node1=c_node1, node2=c_node2)\n",
    "            frame_instances.append(frame_instance)\n",
    "        else:\n",
    "            # Need to fill this later\n",
    "            pass\n",
    "    return frame_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "69fef3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_node(x, y, nodes):\n",
    "    \"\"\"\n",
    "    Self explained\n",
    "    :param x: x coordinate\n",
    "    :param y: y coordinate\n",
    "    :param nodes: node instances\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    def node_distance(node):\n",
    "        \"\"\"\n",
    "        Distance between coordinates and nodes\n",
    "        :param node: single node instance\n",
    "        :return: distance between node bbox center and given x-y coordinates\n",
    "        \"\"\"\n",
    "        return euclidean_distance([x, y], [node.bbox_x, node.bbox_y])\n",
    "    return min(nodes, key=node_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e0ea6f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_frames(frame, node_instances):\n",
    "    \"\"\"\n",
    "    Checks current frame instance and if frame passes through any nodes except the ones it is defined, it divides frame\n",
    "    :param frame: single frame instances\n",
    "    :param node_instances: list of nodes\n",
    "    :return: list of new frames\n",
    "    \"\"\"\n",
    "    # Check if it's a horizontal frame (direction is along x-axis) or vertical (direction is along y-axis)\n",
    "    is_horizontal = frame.node_1.shape_y == frame.node_2.shape_y\n",
    "\n",
    "    new_frames = []\n",
    "\n",
    "    # Extract the node list that lies between the nodes of this frame\n",
    "    if is_horizontal:\n",
    "        intermediate_nodes = sorted([node for node in node_instances\n",
    "                                     if frame.node_1.shape_y == node.shape_y\n",
    "                                     and frame.node_1.shape_x < node.shape_x < frame.node_2.shape_x],\n",
    "                                    key=lambda n: n.shape_x)\n",
    "    else:\n",
    "        intermediate_nodes = sorted([node for node in node_instances\n",
    "                                     if frame.node_1.shape_x == node.shape_x\n",
    "                                     and frame.node_1.shape_y < node.shape_y < frame.node_2.shape_y],\n",
    "                                    key=lambda n: n.shape_y)\n",
    "\n",
    "    # If there are no intermediate nodes, just return the original frame\n",
    "    if not intermediate_nodes:\n",
    "        return [frame]\n",
    "\n",
    "    # Create new frames based on intermediate nodes\n",
    "    start_node = frame.node_1\n",
    "    for node in intermediate_nodes:\n",
    "        new_frame = Frame(start_node, node, frame.obj_det_bbox, frame.direction)\n",
    "        new_frames.append(new_frame)\n",
    "        start_node = node\n",
    "\n",
    "    new_frame = Frame(start_node, frame.node_2, frame.obj_det_bbox, frame.direction)\n",
    "    new_frames.append(new_frame)\n",
    "\n",
    "    return new_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2b001976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_frame_based_on_nodes(frame_instances, node_instances):\n",
    "    \"\"\"\n",
    "    Loops through frame instances to divide them if necessary\n",
    "    :param frame_instances:  list of frame instances\n",
    "    :param node_instances: list of node instances\n",
    "    :return: new frame instances\n",
    "    \"\"\"\n",
    "    new_frames = []\n",
    "    for frame in frame_instances:\n",
    "        split_frames = divide_frames(frame, node_instances)\n",
    "        new_frames.extend(split_frames)\n",
    "    return new_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "56e0b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nominal_frame(node_instances):\n",
    "    \"\"\"\n",
    "    Creates nominal frame if no frame detected\n",
    "    :param node_instances: list of nodes\n",
    "    :return: nominal frame\n",
    "    \"\"\"\n",
    "    new_frame_instances = []\n",
    "    for i in range(len(node_instances)):\n",
    "        for j in range(i + 1, len(node_instances)):\n",
    "            frame = Frame(node1=node_instances[i], node2=node_instances[j])\n",
    "            new_frame_instances.append(frame)\n",
    "    return new_frame_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f69f3623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  initialize_pl(pl_boxes, node_instances):\n",
    "    \"\"\"\n",
    "    Creates point load instances\n",
    "    :param pl_boxes: list of pl bbox\n",
    "    :param node_instances: node list\n",
    "    :return: instances of pl\n",
    "    \"\"\"\n",
    "    point_load_instances = []\n",
    "    for box in pl_boxes:\n",
    "        center_x = (box[1] + box[3]) / 2\n",
    "        center_y = (box[0] + box[2]) / 2\n",
    "\n",
    "        try:\n",
    "            closest_node = min(node_instances,\n",
    "                               key=lambda node: calculation_utils.euclidean_distance(\n",
    "                                   [center_x, center_y], [node.bbox_x, node.bbox_y]))\n",
    "\n",
    "            # For simplicity, I'm not assigning direction, value, and unit.\n",
    "            # These can be assigned based on further criteria or user input.\n",
    "            pl_instance = PointLoad(node=closest_node, obj_det_bbox=box[:4])\n",
    "            point_load_instances.append(pl_instance)\n",
    "        except IndexError:\n",
    "            print(f\"Error processing box with coordinates: {box}. Skipping to next box.\")\n",
    "    return point_load_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ab4dd454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pl_text(pl_boxes, ocr_results, threshold = 200):\n",
    "    \"\"\"\n",
    "    detects texts which are closet than threshold pixel\n",
    "    :param pl_boxes: list of pl boxes\n",
    "    :param ocr_results: ocr readins results\n",
    "    :return: possible readings of pl\n",
    "    \"\"\"\n",
    "    texts_within_range = []\n",
    "\n",
    "    for pl_box in pl_boxes:\n",
    "        pl_center_x = (pl_box[1] + pl_box[3]) / 2\n",
    "        pl_center_y = (pl_box[0] + pl_box[2]) / 2\n",
    "\n",
    "        for text_entry in ocr_results:\n",
    "            text, bbox = text_entry[0], text_entry[1]\n",
    "            center_x = sum(bbox[i] for i in [0, 2, 4, 6]) / 4\n",
    "            center_y = sum(bbox[i] for i in [1, 3, 5, 7]) / 4\n",
    "\n",
    "            if calculation_utils.euclidean_distance([pl_center_x, pl_center_y], [center_x, center_y]) <= threshold:\n",
    "                texts_within_range.append(text_entry)\n",
    "    return texts_within_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c95697ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_precise_text(point_load_instances, possible_pl_text):\n",
    "    \"\"\"\n",
    "    Extracts precise magnitude and value for point loads and assigns related attributes\n",
    "    :param point_load_instances: list containing pl instances\n",
    "    :param possible_pl_text: close text to bbox of object detection\n",
    "    :return: related attributes assigned version of point load instances\n",
    "    \"\"\"\n",
    "    pattern = r\"(?:[A-Za-z]*\\s*=\\s*)?(?P<value>\\d+)\\s*(?P<unit>kN|k|t)(?P<type>/ft)?\"\n",
    "    for pl in point_load_instances:\n",
    "        closest_text_entry = None\n",
    "        min_distance = float('inf')\n",
    "\n",
    "        for text_entry in possible_pl_text:\n",
    "            text = text_entry[0]\n",
    "            bbox = text_entry[1]\n",
    "            center_x = sum(bbox[i] for i in [0, 2, 4, 6]) / 4\n",
    "            center_y = sum(bbox[i] for i in [1, 3, 5, 7]) / 4\n",
    "\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                distance = calculation_utils.euclidean_distance([center_x, center_y], [pl.node.bbox_x, pl.node.bbox_y])\n",
    "                if distance < min_distance:\n",
    "                    closest_text_entry = text_entry\n",
    "                    closest_text_bbox = bbox\n",
    "                    min_distance = distance\n",
    "\n",
    "        # Assign the closest text entry (if found) to the PointLoad instance\n",
    "        if closest_text_entry:\n",
    "            text = closest_text_entry[0]\n",
    "            match = re.search(pattern, text)\n",
    "            value = match.group(\"value\")\n",
    "            unit = match.group(\"unit\")\n",
    "\n",
    "            pl.value = value\n",
    "            pl.unit = unit\n",
    "            pl.text_bbox = closest_text_bbox\n",
    "    return point_load_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "459e9c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pl_direction(pl_instances, img):\n",
    "    \"\"\"\n",
    "    Detects direction of pl by eroding arrows, eroding it until some threshold, only thickest part (arrowhead) will\n",
    "    remain, it will show the direction\n",
    "    :param pl_instances: list of pl instances\n",
    "    :param img: image\n",
    "    :return: None (directions appended instances inside)\n",
    "    \"\"\"\n",
    "    for pl in pl_instances:\n",
    "        y1, x1, y2, x2 = pl.obj_det_bbox\n",
    "        ocr_bbox = pl.text_bbox\n",
    "\n",
    "        if pl.text_bbox:\n",
    "            ry1 = int((ocr_bbox[1] + ocr_bbox[3]) / 2)\n",
    "            ry2 = int((ocr_bbox[5] + ocr_bbox[7]) / 2)\n",
    "            rx1 = int((ocr_bbox[0] + ocr_bbox[6]) / 2)\n",
    "            rx2 = int((ocr_bbox[2] + ocr_bbox[4]) / 2)\n",
    "\n",
    "            overlap_x1 = max(x1, rx1)\n",
    "            overlap_y1 = max(y1, ry1)\n",
    "            overlap_x2 = min(x2, rx2)\n",
    "            overlap_y2 = min(y2, ry2)\n",
    "\n",
    "            # If overlap exists, paint it white\n",
    "            if overlap_x1 < overlap_x2 and overlap_y1 < overlap_y2:\n",
    "                img[overlap_y1:overlap_y2, overlap_x1:overlap_x2] = 255\n",
    "\n",
    "        roi = img[y1:y2, x1:x2]\n",
    "        binary_roi = iterative_erosion(roi, max_iterations=1)\n",
    "\n",
    "        # Find the non-zero pixels' indices\n",
    "        y_indices, x_indices = np.where(binary_roi == 255)\n",
    "\n",
    "        # Calculate the average x and y coordinates\n",
    "        avg_x = np.mean(x_indices)\n",
    "        avg_y = np.mean(y_indices)\n",
    "\n",
    "        # Calculate midpoints of x and y axes\n",
    "        midpoint_x = binary_roi.shape[1] / 2\n",
    "        midpoint_y = binary_roi.shape[0] / 2\n",
    "\n",
    "        # Determine direction\n",
    "        if avg_y > midpoint_y and abs(avg_x - midpoint_x) < midpoint_x / 2:\n",
    "            direction = \"downward\"\n",
    "        elif avg_y < midpoint_y and abs(avg_x - midpoint_x) < midpoint_x / 2:\n",
    "            direction = \"upward\"\n",
    "        elif avg_x > midpoint_x and abs(avg_y - midpoint_y) < midpoint_y / 2:\n",
    "            direction = \"right\"\n",
    "        elif avg_x < midpoint_x and abs(avg_y - midpoint_y) < midpoint_y / 2:\n",
    "            direction = \"left\"\n",
    "        else:\n",
    "            direction = \"unknown\"\n",
    "\n",
    "        pl.direction = direction\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e3075b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_precise_text_dl(dl_instances, ocr_text):\n",
    "    \"\"\"\n",
    "    Decides proper text belongs to the distributed load\n",
    "    :param dl_instances: list keeping instances of distributed load\n",
    "    :param ocr_text: list keeping ocr reading result text\n",
    "    :return: instances with related attributes assigned\n",
    "    \"\"\"\n",
    "    pattern = r\"(?i)(?P<value>\\d+(\\.\\d+)?)\\s*(?P<unit>kN/m|N/m|k/ft)\"\n",
    "    for dl in dl_instances:\n",
    "        bbox = dl.obj_det_bbox  # Using the obj_det_bbox attribute\n",
    "\n",
    "        text = find_closest_text_dl(ocr_text, bbox)\n",
    "\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            dl.value = float(match.group(\"value\"))  # Convert to float instead of int\n",
    "            dl.unit = match.group(\"unit\")\n",
    "    return dl_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5bc9ef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_nodes_dl(dl_with_direction, node_instances):\n",
    "    \"\"\"\n",
    "    Assigns the closest nodes both ends of distributed load\n",
    "    :param dl_with_direction: dl instances with directions decided\n",
    "    :param node_instances: list keeping node instances\n",
    "    :return: node attributed assigned distributed load instances\n",
    "    \"\"\"\n",
    "    distributed_load_instances = []\n",
    "    for box in dl_with_direction:\n",
    "        if box[5] == \"horizontal\":\n",
    "\n",
    "            y1 = box[0]\n",
    "            y2 = box[2]\n",
    "            x = int((box[1] + box[3]) / 2)\n",
    "            # Get the closest node to x1 and x2\n",
    "            c_node1 = find_closest_node(x, y1, node_instances)\n",
    "            c_node2 = find_closest_node(x, y2, node_instances)\n",
    "\n",
    "            dl_instance = DistributedLoad(node1=c_node1, node2=c_node2, obj_det_bbox=box[:4], direction=box[6])\n",
    "            distributed_load_instances.append(dl_instance)\n",
    "        elif box[5] == \"vertical\":\n",
    "            x1 = box[1]\n",
    "            x2 = box[3]\n",
    "            y = int((box[0] + box[2]) / 2)\n",
    "\n",
    "            # Get the closest node to x1 and x2\n",
    "            c_node1 = find_closest_node(x1, y, node_instances)\n",
    "            c_node2 = find_closest_node(x2, y, node_instances)\n",
    "\n",
    "            dl_instance = DistributedLoad(node1=c_node1, node2=c_node2, obj_det_bbox=box[:4], direction=box[6])\n",
    "            distributed_load_instances.append(dl_instance)\n",
    "        else:\n",
    "            # Need to fill this later\n",
    "            pass\n",
    "    return distributed_load_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "03d16d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_direction(x_count, y_count):\n",
    "    \"\"\"\n",
    "    Counts pixels in x and y directions, decides direction of arrow\n",
    "    :param x_count: number of remained pixels after erosion in x direction\n",
    "    :param y_count: number of remained pixels after erosion in y direction\n",
    "    :return: direction\n",
    "    \"\"\"\n",
    "    # Find max values and their indices for x_count and y_count\n",
    "    max_x, idx_x = max((val, idx) for (idx, val) in enumerate(x_count))\n",
    "    max_y, idx_y = max((val, idx) for (idx, val) in enumerate(y_count))\n",
    "\n",
    "    # Determine if the arrow points horizontally or vertically\n",
    "    if max_x >= max_y:\n",
    "        if idx_x < len(x_count) / 2:\n",
    "            return \"left\"\n",
    "        else:\n",
    "            return \"right\"\n",
    "    else:\n",
    "        if idx_y < len(y_count) / 2:\n",
    "            return \"upward\"\n",
    "        else:\n",
    "            return \"downward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "86bf3ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_erosion_dl(roi, initial_iterations=1, max_iterations=10, threshold=1):\n",
    "    \"\"\"\n",
    "    Iterative erosion for distributed load\n",
    "    :param roi: region of interest of image\n",
    "    :param initial_iterations: min number of iterations completed\n",
    "    :param max_iterations: max allowable iteration\n",
    "    :param threshold: minimum number of remaining pixels acceptable\n",
    "    :return: binary image (unpadded)\n",
    "    \"\"\"\n",
    "    gray = cv.cvtColor(roi, cv.COLOR_BGR2GRAY)\n",
    "    blurred = cv.GaussianBlur(gray, (5, 5), 0)\n",
    "    ret, binary = cv.threshold(blurred, 200, 255, cv.THRESH_BINARY_INV)\n",
    "\n",
    "    # Padding to the image\n",
    "    pad_size = 2  # Choose a suitable padding size depending on the kernel size\n",
    "    binary = cv.copyMakeBorder(binary, pad_size, pad_size, pad_size, pad_size, cv.BORDER_CONSTANT, value=0)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(initial_iterations + max_iterations):\n",
    "        prev_binary = binary.copy()\n",
    "        binary = cv.erode(binary, kernel)\n",
    "\n",
    "        current_count = np.sum(binary == 255)\n",
    "        if current_count <= threshold:\n",
    "            binary = prev_binary  # Use the binary image from the previous iteration\n",
    "            break\n",
    "\n",
    "    return binary[pad_size:-pad_size, pad_size:-pad_size]  # Return the image without the added padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bef56498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_direction(dl_boxes, img, initial_iterations=1, max_iterations=10, threshold=1):\n",
    "    \"\"\"\n",
    "    Main function of deciding direction of disributed load\n",
    "    :param dl_boxes: bboxes obtained from object detection\n",
    "    :param img: current image\n",
    "    :param initial_iterations: min number of iterations required before deciding direction\n",
    "    :param max_iterations: number of max allowable iterations\n",
    "    :param threshold: min number of remaining pixels, below this threshold value iteration stops\n",
    "    :return: list containing information of dl instances (in this function direction attribute assigned)\n",
    "    \"\"\"\n",
    "    dl_with_direction = []\n",
    "\n",
    "    for dl in dl_boxes:\n",
    "        sensitivity = 5\n",
    "        y1, x1, y2, x2 = dl[:4]\n",
    "        roi = img[y1 + sensitivity:y2 - sensitivity, x1 + sensitivity:x2 - sensitivity]\n",
    "        \n",
    "        eroded_img = iterative_erosion_dl(roi, initial_iterations, max_iterations, threshold)\n",
    "        \n",
    "        x_count = np.sum(eroded_img == 255, axis=0)\n",
    "        y_count = np.sum(eroded_img == 255, axis=1)\n",
    "\n",
    "        if np.max(x_count) >= np.max(y_count):\n",
    "            direction = \"horizontal\"\n",
    "            dl.append(direction)\n",
    "            pointing_direction = determine_direction(x_count, y_count)\n",
    "            dl.append(pointing_direction)\n",
    "        else:\n",
    "            direction = \"vertical\"\n",
    "            dl.append(direction)\n",
    "            pointing_direction = determine_direction(x_count, y_count)\n",
    "            dl.append(pointing_direction)\n",
    "\n",
    "        dl_with_direction.append(dl)\n",
    "\n",
    "    return dl_with_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b1490971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_nodes_tdl(tdl_with_direction, node_instances):\n",
    "    \"\"\"\n",
    "    Assigns the closest nodes both ends of distributed load\n",
    "    :param dl_with_direction: dl instances with directions decided\n",
    "    :param node_instances: list keeping node instances\n",
    "    :return: node attributed assigned distributed load instances\n",
    "    \"\"\"\n",
    "    t_distributed_load_instances = []\n",
    "    for box in tdl_with_direction:\n",
    "        if box[5] == \"horizontal\":\n",
    "\n",
    "            y1 = box[0]\n",
    "            y2 = box[2]\n",
    "            x = int((box[1] + box[3]) / 2)\n",
    "            # Get the closest node to x1 and x2\n",
    "            c_node1 = find_closest_node(x, y1, node_instances)\n",
    "            c_node2 = find_closest_node(x, y2, node_instances)\n",
    "\n",
    "            tdl_instance = TriangularDistributedLoad(node1=c_node1, node2=c_node2, obj_det_bbox=box[:4], direction=box[6])\n",
    "            t_distributed_load_instances.append(tdl_instance)\n",
    "        elif box[5] == \"vertical\":\n",
    "            x1 = box[1]\n",
    "            x2 = box[3]\n",
    "            y = int((box[0] + box[2]) / 2)\n",
    "\n",
    "            # Get the closest node to x1 and x2\n",
    "            c_node1 = find_closest_node(x1, y, node_instances)\n",
    "            c_node2 = find_closest_node(x2, y, node_instances)\n",
    "\n",
    "            tdl_instance = TriangularDistributedLoad(node1=c_node1, node2=c_node2, obj_det_bbox=box[:4], direction=box[6])\n",
    "            t_distributed_load_instances.append(tdl_instance)\n",
    "        else:\n",
    "            # Need to fill this later\n",
    "            pass\n",
    "    return t_distributed_load_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "222c94e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_precise_text_tdl(tdl_instances, ocr_text):\n",
    "    \"\"\"\n",
    "    Decides proper text belongs to the distributed load\n",
    "    :param dl_instances: list keeping instances of distributed load\n",
    "    :param ocr_text: list keeping ocr reading result text\n",
    "    :return: instances with related attributes assigned\n",
    "    \"\"\"\n",
    "    pattern = r\"(?i)(?P<value>\\d+(\\.\\d+)?)\\s*(?P<unit>kN/m|N/m|k/ft)\"\n",
    "    for dl in dl_instances:\n",
    "        bbox = dl.obj_det_bbox  # Using the obj_det_bbox attribute\n",
    "\n",
    "        text = find_closest_text_dl(ocr_text, bbox)\n",
    "\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            dl.value = float(match.group(\"value\"))  # Convert to float instead of int\n",
    "            dl.unit = match.group(\"unit\")\n",
    "    return dl_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "81d5facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import config_util\n",
    "from object_detection.builders import model_builder\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "import numpy as np\n",
    "\n",
    "def object_detection(image, path_of_image, incoming_filename):\n",
    "    \"\"\"\n",
    "    Main part of the software\n",
    "    :param image: input image obtained from telegram chat\n",
    "    :param path_of_image: image is saved after taken from group, this variable keeps that saving path\n",
    "    :param incoming_filename: filename created according to a pattern (user_name + datetime info)\n",
    "    :return: returns solution (for now it is an image, later it will be a pdf file)\n",
    "    \"\"\"\n",
    "\n",
    "#     user_path = os.path.expanduser(\"~\")\n",
    "#     training_demo_path = os.path.join(user_path, \"Desktop\", \"cekcoz_v3\", \"workspace\", \"training_demo\")\n",
    "#     config_path = os.path.join(training_demo_path, \"models\", \"cekcoz_resnet\", \"pipeline.config\")\n",
    "#     configs = config_util.get_configs_from_pipeline_file(config_path)\n",
    "#     model_config = configs[\"model\"]\n",
    "#     detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "#     ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "#     checkpoint_path = os.path.join(training_demo_path, \"models\", \"cekcoz_resnet\")\n",
    "#     ckpt.restore(os.path.join(checkpoint_path, 'ckpt-98')).expect_partial()\n",
    "\n",
    "\n",
    "#     label_path = os.path.join(training_demo_path, \"annotations\", \"label_map.pbtxt\")\n",
    "#     category_index = label_map_util.create_category_index_from_labelmap(label_path,use_display_name=True)\n",
    "\n",
    "#     image_np = np.array(image)\n",
    "#     img_height, img_width = image_np.shape[0], image_np.shape[1]\n",
    "\n",
    "#     input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "\n",
    "#     detections = detect_fn(input_tensor, detection_model)\n",
    "\n",
    "#     num_detections = int(detections.pop('num_detections'))\n",
    "#     detections = {key: value[0, :num_detections].numpy()\n",
    "#                   for key, value in detections.items()}\n",
    "#     detections['num_detections'] = num_detections\n",
    "#     label_id_offset = 1\n",
    "\n",
    "#     # detection_classes should be ints.\n",
    "#     detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "\n",
    "# #     ----------For testing object detection results, code below could be used---------------\n",
    "# #     show_object_detection_results(image_np, detections, category_index)\n",
    "\n",
    "#     # Packs all complex data into usable data with some format\n",
    "#     aggregated_list = list(map(process_data, detections['detection_boxes'],\n",
    "#                                detections['detection_classes'],detections['detection_scores']))\n",
    "\n",
    "\n",
    "#     # Detections which has confidence score less than threshold value described below will be discarded\n",
    "#     score_threshold = 0.5\n",
    "\n",
    "\n",
    "#     # After discarding ambiguous detections, rest will be accumulated in the list below\n",
    "#     applicable_list = remove_ambiguous_detections(score_threshold, aggregated_list, category_index,\n",
    "#                                                                    img_width, img_height)\n",
    "#     print(\"Applicable List = \", applicable_list)\n",
    "    applicable_list = [[99, 108, 132, 137, 'roller_support'], [132, 117, 152, 375, 'spacing'], [21, 108, 92, 375, 'triangular_distributed_load'], [89, 116, 99, 383, 'frame'], [100, 368, 125, 384, 'pin_support']]\n",
    "    error_statement = \"\"\"Gnderilen resim zm iin uygun deildir, muhtemelen sebepler:\n",
    "    - letilen resim bu ders ile alakal deil\n",
    "    - letilen resmin kalitesi sistemin tanyamayaca kadar kt\n",
    "    - letilen resimde izimin stnde bulunan bilgiler zm iin yeterli deil\n",
    "    - letilen resimde zm iin gereken bilgiler yaz iinde aklanm\"\"\"\n",
    "    if len(applicable_list) < 3:\n",
    "        return error_statement\n",
    "#     reading_results = read_text_on_image(path_of_image)\n",
    "    reading_results = [['9B =3600N/m', [388.0, 23.0, 489.0, 21.0, 489.0, 36.0, 388.0, 39.0]], ['q4=1500N/m', [15.0, 65.0, 115.0, 63.0, 116.0, 78.0, 15.0, 81.0]], ['A', [102.0, 88.0, 113.0, 88.0, 113.0, 99.0, 102.0, 99.0]], ['B', [385.0, 87.0, 396.0, 88.0, 396.0, 99.0, 386.0, 99.0]], ['000', [107.0, 110.0, 142.0, 110.0, 141.0, 122.0, 107.0, 120.0]], ['L =6m.', [217.0, 124.0, 269.0, 124.0, 269.0, 137.0, 216.0, 136.0]]]\n",
    "    print(\"Reading results =\", reading_results)\n",
    "    if not reading_results:\n",
    "        return error_statement\n",
    "    ocr_results = clean_ocr_results(reading_results)\n",
    "    spacing_bbox = [item[:4] for item in applicable_list if item[4] == 'spacing']\n",
    "    if not spacing_bbox:\n",
    "        return error_statement\n",
    "    spacing_matching_results = match_spacings(spacing_bbox, ocr_results)\n",
    "    spacing_sec_filtered_results = ocr_secondary_filter_distance(spacing_matching_results)\n",
    "    spacing_extracted_results = extract_value_unit(spacing_sec_filtered_results)\n",
    "    sorted_spacings = sorted(spacing_extracted_results, key=sorting_key)\n",
    "    sorted_spacings_with_directions = dimension_direction(sorted_spacings, image)\n",
    "    spacing_instances, node_instances = initialize_parameters(sorted_spacings_with_directions)\n",
    "    if not node_instances or not spacing_instances:\n",
    "        return error_statement\n",
    "    \n",
    "    node_instances = correct_shapes(node_instances)\n",
    "    node_instances = find_and_append_missing_nodes(node_instances)\n",
    "    append_names_to_nodes(node_instances, ocr_results, distance_threshold=100)\n",
    "    print(\"Node instances = \", node_instances)\n",
    "    print(\"Spacing instances = \", spacing_instances)\n",
    "    \n",
    "    support_bbox = [box for box in applicable_list if 'support' in box[-1]]\n",
    "    fix_support_instances, pin_support_instances, roller_support_instances = create_support_instances(support_bbox, node_instances)\n",
    "    print(\"fix supports = \", fix_support_instances)\n",
    "    print(\"pin supports = \", pin_support_instances)\n",
    "    print(\"roller supports = \", roller_support_instances)\n",
    "    \n",
    "    frame_boxes = [box for box in applicable_list if box[-1] == 'frame']\n",
    "    frame_boxes = find_frame_direction(frame_boxes, image)\n",
    "    frame_instances = initialize_frames(frame_boxes, node_instances)\n",
    "    print(\"Frame instances = \", frame_instances)\n",
    "    \n",
    "    new_frame_instances = split_frame_based_on_nodes(frame_instances, node_instances)\n",
    "    print(\"New frame instances = \", new_frame_instances)\n",
    "    if not new_frame_instances:\n",
    "        new_frame_instances = create_nominal_frame(node_instances)\n",
    "    \n",
    "    pl_boxes = [box for box in applicable_list if box[-1] == 'point_load']\n",
    "    point_load_instances = initialize_pl(pl_boxes, node_instances)\n",
    "    possible_pl_text = extract_pl_text(pl_boxes, ocr_results)\n",
    "    point_load_instances = extract_precise_text(point_load_instances, possible_pl_text)\n",
    "    if point_load_instances:\n",
    "        pl_direction(point_load_instances, image)\n",
    "    print(\"Point load instances = \", point_load_instances)\n",
    "    \n",
    "    sorted_nodes = sorted(node_instances, key=lambda node: (node.shape_y, node.shape_x))\n",
    "    \n",
    "    dl_boxes = [box for box in applicable_list if box[-1] == 'distributed_load']\n",
    "    dl_with_direction = dl_direction(dl_boxes, image, initial_iterations=1, max_iterations=10, threshold=1)\n",
    "    distributed_load_instances = assign_nodes_dl(dl_with_direction, node_instances)\n",
    "    distributed_load_instances = extract_precise_text_dl(distributed_load_instances, ocr_results)\n",
    "    \n",
    "    print(\"Distributed load instances = \", distributed_load_instances)\n",
    "    \n",
    "    tdl_boxes = [box for box in applicable_list if box[-1] == 'triangular_distributed_load']\n",
    "    tdl_with_direction = dl_direction(tdl_boxes, image, initial_iterations=1, max_iterations=10, threshold=1)\n",
    "    print(\"tdl direction\", tdl_with_direction)\n",
    "    t_distributed_load_instances = assign_nodes_tdl(tdl_with_direction, node_instances)\n",
    "    print(\"T dist instances\", t_distributed_load_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "deb041af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading results = [['9B =3600N/m', [388.0, 23.0, 489.0, 21.0, 489.0, 36.0, 388.0, 39.0]], ['q4=1500N/m', [15.0, 65.0, 115.0, 63.0, 116.0, 78.0, 15.0, 81.0]], ['A', [102.0, 88.0, 113.0, 88.0, 113.0, 99.0, 102.0, 99.0]], ['B', [385.0, 87.0, 396.0, 88.0, 396.0, 99.0, 386.0, 99.0]], ['000', [107.0, 110.0, 142.0, 110.0, 141.0, 122.0, 107.0, 120.0]], ['L =6m.', [217.0, 124.0, 269.0, 124.0, 269.0, 137.0, 216.0, 136.0]]]\n",
      "Node instances =  [Node(name=A, bbox_x=117, bbox_y=142, shape_x=0, shape_y=0), Node(name=B, bbox_x=375, bbox_y=142, shape_x=6, shape_y=0)]\n",
      "Spacing instances =  [Dimension(node_1=Node(name=A, bbox_x=117, bbox_y=142, shape_x=0, shape_y=0), node_2=Node(name=B, bbox_x=375, bbox_y=142, shape_x=6, shape_y=0), value=6, unit=m, obj_det_bbox=[132, 117, 152, 375], text_bbox=[217.0, 124.0, 269.0, 124.0, 269.0, 137.0, 216.0, 136.0])]\n",
      "fix supports =  []\n",
      "pin supports =  [PinSupport(node=Node(name=B, bbox_x=375, bbox_y=142, shape_x=6, shape_y=0), Fx=0, Fy=0)]\n",
      "roller supports =  [RollerSupport(node=Node(name=A, bbox_x=117, bbox_y=142, shape_x=0, shape_y=0), Fy=0)]\n",
      "Frame instances =  [Frame(node_1=Node(name=A, bbox_x=117, bbox_y=142, shape_x=0, shape_y=0), node_2=Node(name=B, bbox_x=375, bbox_y=142, shape_x=6, shape_y=0), obj_det_bbox=None, direction=None)]\n",
      "New frame instances =  [Frame(node_1=Node(name=A, bbox_x=117, bbox_y=142, shape_x=0, shape_y=0), node_2=Node(name=B, bbox_x=375, bbox_y=142, shape_x=6, shape_y=0), obj_det_bbox=None, direction=None)]\n",
      "Point load instances =  []\n",
      "Distributed load instances =  []\n",
      "tdl direction [[21, 108, 92, 375, 'triangular_distributed_load', 'vertical', 'downward']]\n",
      "T dist instances [TriangularDistributedLoad(node1=Node(name=A, bbox_x=117, bbox_y=142, shape_x=0, shape_y=0), node2=Node(name=B, bbox_x=375, bbox_y=142, shape_x=6, shape_y=0), obj_det_bbox=[21, 108, 92, 375], direction=downward, value1=None, value2=None, unit=None)]\n"
     ]
    }
   ],
   "source": [
    "object_detection(img, file_path, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aec21a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead0257a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
