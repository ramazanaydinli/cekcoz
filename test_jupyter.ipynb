{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03df5ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file will be used for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6da3f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In cwd there is a directory called \"single_image_testing\", put the image you want to test in that directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a4a87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import itertools\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.builders import model_builder\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55129d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "test_dir_path = os.path.join(cwd, \"single_image_testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76b19d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\METE\\Desktop\\cekcoz_main\\single_image_testing\\A001721.png\n"
     ]
    }
   ],
   "source": [
    "filename=os.listdir(test_dir_path)[0]\n",
    "file_path = os.path.join(test_dir_path, filename)\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb113f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "img = cv.imread(file_path)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74a4a297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_object_detection_results(image_np, detections, category_index, label_id_offset=1):\n",
    "    \"\"\"\n",
    "    Displays object detection results labeled on input image\n",
    "    :param image_np: numpy formatted image\n",
    "    :param detections: detection results\n",
    "    :param category_index: detection class index\n",
    "    :param label_id_offset: class index - label name dict\n",
    "    :return: None (shows detection result)\n",
    "    \"\"\"\n",
    "    image_np_with_detections = image_np.copy()\n",
    "    from object_detection.utils import visualization_utils as viz_utils\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np_with_detections,\n",
    "        detections['detection_boxes'],\n",
    "        detections['detection_classes'] + label_id_offset,\n",
    "        detections['detection_scores'],\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        max_boxes_to_draw=200,\n",
    "        min_score_thresh=0.3,\n",
    "        agnostic_mode=False,\n",
    "        line_thickness=1,\n",
    "        skip_scores=True,\n",
    "        skip_labels = True)\n",
    "    cv.imshow(\"image with detections\", image_np_with_detections)\n",
    "    cv.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e800130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_fn(image, detection_model):\n",
    "    \"\"\"Detect objects in image.\"\"\"\n",
    "\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9956920a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From C:\\Users\\METE\\anaconda3\\envs\\trilines\\lib\\site-packages\\object_detection\\utils\\model_util.py:57: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    }
   ],
   "source": [
    "user_path = os.path.expanduser(\"~\")\n",
    "training_demo_path = os.path.join(user_path, \"Desktop\", \"cekcoz_v3\", \"workspace\", \"training_demo\")\n",
    "config_path = os.path.join(training_demo_path, \"models\", \"cekcoz_resnet\", \"pipeline.config\")\n",
    "configs = config_util.get_configs_from_pipeline_file(config_path)\n",
    "model_config = configs[\"model\"]\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "checkpoint_path = os.path.join(training_demo_path, \"models\", \"cekcoz_resnet\")\n",
    "ckpt.restore(os.path.join(checkpoint_path, 'ckpt-98')).expect_partial()\n",
    "\n",
    "\n",
    "label_path = os.path.join(training_demo_path, \"annotations\", \"label_map.pbtxt\")\n",
    "category_index = label_map_util.create_category_index_from_labelmap(label_path,use_display_name=True)\n",
    "\n",
    "image_np = np.array(img)\n",
    "img_height, img_width = image_np.shape[0], image_np.shape[1]\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "\n",
    "detections = detect_fn(input_tensor, detection_model)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "label_id_offset = 1\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "\n",
    "#     ----------For testing object detection results, code below could be used---------------\n",
    "# show_object_detection_results(image_np, detections, category_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee6b102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(box, detection_class, score, label_id_offset=1):\n",
    "    \"\"\"\n",
    "    Taking TensforFlow formatted information and formats them for easy usage\n",
    "    :param box: obj det bboxes\n",
    "    :param detection_class: class of the detected object\n",
    "    :param score: detection score\n",
    "    :param label_id_offset: Highly likely equals to 1 ( for offset purpose)\n",
    "    :return: returns the list including information with some logic\n",
    "    \"\"\"\n",
    "    return list([box[0], box[1], box[2], box[3], detection_class + label_id_offset, score])\n",
    "aggregated_list = list(map(process_data, detections['detection_boxes'], detections['detection_classes'],detections['detection_scores']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8f81529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ambiguous_detections(threshold, data_list, category_index, img_width, img_height):\n",
    "    \"\"\"\n",
    "    Will take object detection results and remove doubtfull detections\n",
    "    :param threshold: confidence score, detections has lower than this score will be removed\n",
    "    :param data_list: list containing object detection results\n",
    "    :param category_index: index of the classes\n",
    "    :param img_width: x-pixel value of the current image\n",
    "    :param img_height: y-pixel value of the current image\n",
    "    :return: returns list which has cleared all ambigous detections\n",
    "    \"\"\"\n",
    "    new_data_list = []\n",
    "    for whole_values in data_list:\n",
    "        dummy_list = []\n",
    "        if whole_values[5] > threshold:\n",
    "            label_name = (category_index.get(int(whole_values[4]))).get(\"name\")\n",
    "            ymin = int(whole_values[0] * img_height)\n",
    "            xmin = int(whole_values[1] * img_width)\n",
    "            ymax = int(whole_values[2] * img_height)\n",
    "            xmax = int(whole_values[3] * img_width)\n",
    "            dummy_list.append(ymin)\n",
    "            dummy_list.append(xmin)\n",
    "            dummy_list.append(ymax)\n",
    "            dummy_list.append(xmax)\n",
    "            dummy_list.append(label_name)\n",
    "            new_data_list.append(dummy_list)\n",
    "    return new_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd38adb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applicable List =  [[186, 535, 227, 566, 'roller_support'], [247, 312, 269, 553, 'spacing'], [169, 67, 224, 104, 'pin_support'], [238, 199, 269, 315, 'spacing'], [240, 88, 269, 204, 'spacing'], [6, 288, 150, 346, 'point_load'], [153, 65, 190, 567, 'frame'], [82, 70, 155, 307, 'triangular_distributed_load']]\n"
     ]
    }
   ],
   "source": [
    "# Detections which has confidence score less than threshold value described below will be discarded\n",
    "score_threshold = 0.5\n",
    "\n",
    "\n",
    "# After discarding ambiguous detections, rest will be accumulated in the list below\n",
    "applicable_list = remove_ambiguous_detections(score_threshold, aggregated_list, category_index,\n",
    "                                                               img_width, img_height)\n",
    "print(\"Applicable List = \", applicable_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6969095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import time\n",
    "\n",
    "def read_text_on_image(path):\n",
    "    \"\"\"\n",
    "    Reads text on image\n",
    "    :param path: input image path\n",
    "    :return: ocr text\n",
    "    \"\"\"\n",
    "\n",
    "    subscription_key = \"d9db8bd3bed7440a86b510dca41abdc6\"\n",
    "    endpoint = \"https://cekcozocr.cognitiveservices.azure.com/\"\n",
    "\n",
    "    computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "\n",
    "    read_image_path = path\n",
    "    # Open the image\n",
    "    read_image = open(read_image_path, \"rb\")\n",
    "\n",
    "    # Call API with image and raw response (allows you to get the operation location)\n",
    "    read_response = computervision_client.read_in_stream(read_image, raw=True)\n",
    "    # Get the operation location (URL with ID as last appendage)\n",
    "    read_operation_location = read_response.headers[\"Operation-Location\"]\n",
    "    # Take the ID off and use to get results\n",
    "    operation_id = read_operation_location.split(\"/\")[-1]\n",
    "\n",
    "    # Call the \"GET\" API and wait for the retrieval of the results\n",
    "    while True:\n",
    "        read_result = computervision_client.get_read_result(operation_id)\n",
    "        if read_result.status.lower() not in ['notstarted', 'running']:\n",
    "            break\n",
    "        print('Waiting for result...')\n",
    "        time.sleep(3)\n",
    "\n",
    "    reading_results = []\n",
    "    # Print results, line by line\n",
    "    if read_result.status == OperationStatusCodes.succeeded:\n",
    "        for text_result in read_result.analyze_result.read_results:\n",
    "            for line in text_result.lines:\n",
    "                dummy_list = [line.text, line.bounding_box]\n",
    "                reading_results.append(dummy_list)\n",
    "    return reading_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70976e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading_results = read_text_on_image(file_path)\n",
    "# print(reading_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d4c5b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "reading_results = [['5 kN', [290.0, 11.0, 346.0, 10.0, 346.0, 32.0, 289.0, 32.0]], ['3 kN/m', [41.0, 60.0, 129.0, 60.0, 129.0, 85.0, 41.0, 85.0]], ['A', [42.0, 169.0, 64.0, 171.0, 63.0, 192.0, 42.0, 191.0]], ['B', [558.0, 171.0, 577.0, 169.0, 577.0, 192.0, 558.0, 193.0]], ['C', [219.0, 203.0, 241.0, 204.0, 239.0, 226.0, 219.0, 225.0]], ['D', [338.0, 203.0, 360.0, 203.0, 360.0, 227.0, 337.0, 227.0]], ['- 1.5 m --- 1.5 m', [83.0, 243.0, 291.0, 243.0, 291.0, 268.0, 83.0, 268.0]], ['3 m', [412.0, 245.0, 456.0, 244.0, 456.0, 265.0, 411.0, 266.0]]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b293a375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['5 kN', [10, 289, 32, 346]], ['3 kN/m', [60, 41, 85, 129]], ['A', [170, 42, 191, 63]], ['B', [170, 558, 192, 577]], ['C', [203, 219, 225, 240]], ['D', [203, 337, 227, 360]], ['- 1.5 m --- 1.5 m', [243, 83, 268, 291]], ['3 m', [244, 411, 265, 456]]]\n"
     ]
    }
   ],
   "source": [
    "def convert_ocrbbox_to_objdet_bbox(ocr_results):\n",
    "    converted_list = []\n",
    "    for element in ocr_results:\n",
    "        dummy_list = [element[0]]\n",
    "        x1 = int((element[1][0]+element[1][6])/2)\n",
    "        x2 = int((element[1][2]+element[1][4])/2)\n",
    "        y1 = int((element[1][1]+element[1][3])/2)\n",
    "        y2 = int((element[1][5]+element[1][7])/2)\n",
    "        dummy_list.append([y1,x1,y2,x2])\n",
    "        converted_list.append(dummy_list)\n",
    "    return converted_list\n",
    "ocr_converted_bbox = convert_ocrbbox_to_objdet_bbox(reading_results)\n",
    "print(ocr_converted_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3c07c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_overlapping(box1, box2):\n",
    "    \"\"\"\n",
    "    Check if two bounding boxes are overlapping.\n",
    "    Bounding boxes are in the format: [y1, x1, y2, x2]\n",
    "    \"\"\"\n",
    "    # Check if one box is to the left of the other\n",
    "    if box1[1] > box2[3] or box2[1] > box1[3]:\n",
    "        return False\n",
    "\n",
    "    # Check if one box is above the other\n",
    "    if box1[0] > box2[2] or box2[0] > box1[2]:\n",
    "        return False\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8d971d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_ocr(roi):\n",
    "    height, width, _ = roi.shape\n",
    "    # Check if the image resolution is lower than 256x256\n",
    "    if width < 256 or height < 256:\n",
    "        # Calculate the scaling factors to reach a minimum size of 256x256\n",
    "        scale_x = max(256 / width, 1.0)\n",
    "        scale_y = max(256 / height, 1.0)\n",
    "\n",
    "        # Use the smaller of the two scaling factors to maintain aspect ratio\n",
    "        scale_factor = min(scale_x, scale_y)\n",
    "\n",
    "        # Upscale the image while maintaining aspect ratio\n",
    "        new_width = int(width * scale_factor)\n",
    "        new_height = int(height * scale_factor)\n",
    "        resized_roi = cv.resize(roi, (new_width, new_height), interpolation=cv.INTER_LINEAR)\n",
    "    return resized_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cba8e09e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading '- 1.5 m --- 1.5 m' overlaps with spacings: [[238, 199, 269, 315, 'spacing'], [240, 88, 269, 204, 'spacing']]\n",
      "Waiting for result...\n",
      "[['1.5 m', [78.0, 16.0, 203.0, 19.0, 202.0, 61.0, 74.0, 59.0]]]\n",
      "conv text 1 [['1.5 m', [17, 76, 60, 202]]]\n",
      "bbox1 [238, 199, 269, 315]\n",
      "final convtext1 [['1.5 m', [238, 199, 269, 315]]]\n",
      "Waiting for result...\n",
      "[['1.5 m', [68.0, 9.0, 189.0, 11.0, 189.0, 55.0, 69.0, 53.0]]]\n",
      "conv text 1 [['1.5 m', [238, 199, 269, 315]]]\n",
      "bbox2 [240, 88, 269, 204]\n",
      "final convtext2 [['1.5 m', [240, 88, 269, 204]]]\n",
      "after remove [['5 kN', [10, 289, 32, 346]], ['3 kN/m', [60, 41, 85, 129]], ['A', [170, 42, 191, 63]], ['B', [170, 558, 192, 577]], ['C', [203, 219, 225, 240]], ['D', [203, 337, 227, 360]], ['3 m', [244, 411, 265, 456]]]\n",
      "final list [['5 kN', [10, 289, 32, 346]], ['3 kN/m', [60, 41, 85, 129]], ['A', [170, 42, 191, 63]], ['B', [170, 558, 192, 577]], ['C', [203, 219, 225, 240]], ['D', [203, 337, 227, 360]], ['3 m', [244, 411, 265, 456]], ['1.5 m', [238, 199, 269, 315]], ['1.5 m', [240, 88, 269, 204]]]\n"
     ]
    }
   ],
   "source": [
    "objdet_bbox = [[186, 535, 227, 566, 'roller_support'], [247, 312, 269, 553, 'spacing'], [169, 67, 224, 104, 'pin_support'], [238, 199, 269, 315, 'spacing'], [240, 88, 269, 204, 'spacing'], [6, 288, 150, 346, 'point_load'], [153, 65, 190, 567, 'frame'], [82, 70, 155, 307, 'triangular_distributed_load']]\n",
    "converted_ocr = [['5 kN', [10, 289, 32, 346]], ['3 kN/m', [60, 41, 85, 129]], ['A', [170, 42, 191, 63]], ['B', [170, 558, 192, 577]], ['C', [203, 219, 225, 240]], ['D', [203, 337, 227, 360]], ['- 1.5 m --- 1.5 m', [243, 83, 268, 291]], ['3 m', [244, 411, 265, 456]]]\n",
    "\n",
    "def is_ocr_overlapping(objdet_bbox, converted_ocr, img, file_path):\n",
    "    spacings = [box for box in objdet_bbox if box[4] == 'spacing']\n",
    "    \n",
    "    for reading in converted_ocr:\n",
    "        overlapping_spacings = []\n",
    "        for spacing in spacings:\n",
    "            if is_overlapping(spacing, reading[1]):\n",
    "                overlapping_spacings.append(spacing)\n",
    "        if len(overlapping_spacings) > 1:\n",
    "            print(f\"Reading '{reading[0]}' overlaps with spacings: {overlapping_spacings}\")\n",
    "            roi1 = img[overlapping_spacings[0][0]:overlapping_spacings[0][2],overlapping_spacings[0][1]:overlapping_spacings[0][3]]\n",
    "            directory, filename = os.path.split(file_path)\n",
    "            \n",
    "            # Split the filename into name and extension\n",
    "            name, extension = os.path.splitext(filename)\n",
    "\n",
    "            # Add \"_ro1\" before the extension\n",
    "            new_filename1 = f\"{name}_roi1{extension}\"\n",
    "\n",
    "            # Create the new file path\n",
    "            new_file_path1 = os.path.join(directory, new_filename1)\n",
    "            resized_roi1 = resize_ocr(roi1)\n",
    "            cv.imwrite(new_file_path1, resized_roi1)\n",
    "            text1 = read_text_on_image(new_file_path1)\n",
    "            print(text1)\n",
    "            converted_text1 = convert_ocrbbox_to_objdet_bbox(text1)\n",
    "            print(\"conv text 1\", converted_text1)\n",
    "            bbox1 = [overlapping_spacings[0][0], overlapping_spacings[0][1], overlapping_spacings[0][2],overlapping_spacings[0][3]]\n",
    "            print(\"bbox1\", bbox1)\n",
    "            converted_text1[0][1] =  bbox1\n",
    "            print(\"final convtext1\", converted_text1)\n",
    "            \n",
    "            \n",
    "            \n",
    "            roi2 = img[overlapping_spacings[1][0]:overlapping_spacings[1][2],overlapping_spacings[1][1]:overlapping_spacings[1][3]]\n",
    "            new_filename2 = f\"{name}_roi2{extension}\"\n",
    "\n",
    "            # Create the new file path\n",
    "            new_file_path2 = os.path.join(directory, new_filename2)\n",
    "            resized_roi2 = resize_ocr(roi2)\n",
    "            cv.imwrite(new_file_path2, resized_roi2)\n",
    "            text2 = read_text_on_image(new_file_path2)\n",
    "            print(text2)\n",
    "            converted_text2 = convert_ocrbbox_to_objdet_bbox(text2)\n",
    "            print(\"conv text 1\", converted_text1)\n",
    "            bbox2 = [overlapping_spacings[1][0], overlapping_spacings[1][1], overlapping_spacings[1][2],overlapping_spacings[1][3]]\n",
    "            print(\"bbox2\", bbox2)\n",
    "            converted_text2[0][1] =  bbox2\n",
    "            print(\"final convtext2\", converted_text2)\n",
    "            converted_ocr.remove(reading)\n",
    "            print(\"after remove\", converted_ocr)\n",
    "            converted_ocr.extend(converted_text1)\n",
    "            converted_ocr.extend(converted_text2)\n",
    "            print(\"final list\", converted_ocr)\n",
    "            return converted_ocr\n",
    "# Sample Usage:\n",
    "converted_ocr = is_ocr_overlapping(objdet_bbox, converted_ocr, img, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f78f391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['3 m', [412.0, 245.0, 456.0, 244.0, 456.0, 265.0, 411.0, 266.0]], ['D', [338.0, 203.0, 360.0, 203.0, 360.0, 227.0, 337.0, 227.0]], ['C', [219.0, 203.0, 241.0, 204.0, 239.0, 226.0, 219.0, 225.0]], ['B', [558.0, 171.0, 577.0, 169.0, 577.0, 192.0, 558.0, 193.0]], ['A', [42.0, 169.0, 64.0, 171.0, 63.0, 192.0, 42.0, 191.0]], ['3 kN/m', [41.0, 60.0, 129.0, 60.0, 129.0, 85.0, 41.0, 85.0]], ['5 kN', [290.0, 11.0, 346.0, 10.0, 346.0, 32.0, 289.0, 32.0]], ['1.5 m', [199, 238, 315, 238, 315, 269, 199, 269]], ['1.5 m', [88, 240, 204, 240, 204, 269, 88, 269]]]\n"
     ]
    }
   ],
   "source": [
    "# Buray dzeltirsen gerisi kolay\n",
    "converted_ocr = [['5 kN', [10, 289, 32, 346]], ['3 kN/m', [60, 41, 85, 129]], ['A', [170, 42, 191, 63]], ['B', [170, 558, 192, 577]], ['C', [203, 219, 225, 240]], ['D', [203, 337, 227, 360]], ['3 m', [244, 411, 265, 456]], ['1.5 m', [238, 199, 269, 315]], ['1.5 m', [240, 88, 269, 204]]]\n",
    "reading_results = [['5 kN', [290.0, 11.0, 346.0, 10.0, 346.0, 32.0, 289.0, 32.0]], ['3 kN/m', [41.0, 60.0, 129.0, 60.0, 129.0, 85.0, 41.0, 85.0]], ['A', [42.0, 169.0, 64.0, 171.0, 63.0, 192.0, 42.0, 191.0]], ['B', [558.0, 171.0, 577.0, 169.0, 577.0, 192.0, 558.0, 193.0]], ['C', [219.0, 203.0, 241.0, 204.0, 239.0, 226.0, 219.0, 225.0]], ['D', [338.0, 203.0, 360.0, 203.0, 360.0, 227.0, 337.0, 227.0]], ['- 1.5 m --- 1.5 m', [83.0, 243.0, 291.0, 243.0, 291.0, 268.0, 83.0, 268.0]], ['3 m', [412.0, 245.0, 456.0, 244.0, 456.0, 265.0, 411.0, 266.0]]]\n",
    "def convert_objdet_bbox_to_ocr_bbox(converted, reading):\n",
    "    reconverted_list = []\n",
    "    for elementc in reversed(converted):\n",
    "        for elementr in reversed(reading):\n",
    "            if elementc[0] == elementr[0]:\n",
    "                reconverted_list.append(elementr)\n",
    "                reading.remove(elementr)\n",
    "                converted.remove(elementc)\n",
    "                break\n",
    "    for element in converted:\n",
    "        [r, [y1,x1,y2,x2]] = element\n",
    "        true_form = [r, [x1, y1, x2, y1, x2, y2, x1, y2]]\n",
    "        reconverted_list.append(true_form)\n",
    "    return reconverted_list\n",
    "reading_results = convert_objdet_bbox_to_ocr_bbox(converted_ocr, reading_results)\n",
    "print(reading_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6591c587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('3 m', [412.0, 245.0, 456.0, 244.0, 456.0, 265.0, 411.0, 266.0]), ('D', [338.0, 203.0, 360.0, 203.0, 360.0, 227.0, 337.0, 227.0]), ('C', [219.0, 203.0, 241.0, 204.0, 239.0, 226.0, 219.0, 225.0]), ('B', [558.0, 171.0, 577.0, 169.0, 577.0, 192.0, 558.0, 193.0]), ('A', [42.0, 169.0, 64.0, 171.0, 63.0, 192.0, 42.0, 191.0]), ('3 kN/m', [41.0, 60.0, 129.0, 60.0, 129.0, 85.0, 41.0, 85.0]), ('5 kN', [290.0, 11.0, 346.0, 10.0, 346.0, 32.0, 289.0, 32.0]), ('1.5 m', [199, 238, 315, 238, 315, 269, 199, 269]), ('1.5 m', [88, 240, 204, 240, 204, 269, 88, 269])]\n"
     ]
    }
   ],
   "source": [
    "def clean_ocr_results(ocr_results):\n",
    "    \"\"\"\n",
    "    Removing bad reading characters and any text before the \"=\" symbol\n",
    "    :param ocr_results: initial reading results\n",
    "    :return: cleansed results\n",
    "    \"\"\"\n",
    "    # A list of meaningless readings. You can extend this list as required\n",
    "    meaningless_readings = [\"-\"]\n",
    "\n",
    "    cleaned_results = []\n",
    "\n",
    "    for result in ocr_results:\n",
    "        text, *rest = result\n",
    "\n",
    "        # Remove everything before and including the \"=\" symbol\n",
    "        if \"=\" in text:\n",
    "            text = text.split(\"=\", 1)[1]\n",
    "\n",
    "        # Append the cleaned text to the cleaned results list if not in meaningless readings\n",
    "        if text not in meaningless_readings:\n",
    "            cleaned_results.append((text, *rest))\n",
    "\n",
    "    return cleaned_results\n",
    "ocr_results = clean_ocr_results(reading_results)\n",
    "print(ocr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cae5d3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_threshold(bbox):\n",
    "    \"\"\"\n",
    "    Dynamically adjusts threshold for \"filter_results_by_distance\" function\n",
    "    Logic is finding smaller axis (x or y) and adds some pixel to that axis length\n",
    "    :param bbox: bbox of the object\n",
    "    :return: calculated threshold value\n",
    "    \"\"\"\n",
    "    if bbox[3]-bbox[1] > bbox[2]-bbox[0]:\n",
    "        return bbox[2]-bbox[0]+10\n",
    "    else:\n",
    "        return bbox[3]-bbox[1] + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b533471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_center_obj(bbox):\n",
    "    \"\"\"\n",
    "    Computes center point of bbox\n",
    "    :param bbox: bbox in format [y1,x1,y2,x2]\n",
    "    :return: avg_x, avg_y\n",
    "    \"\"\"\n",
    "    y1, x1, y2, x2 = bbox\n",
    "    center_x = (x1 + x2) / 2\n",
    "    center_y = (y1 + y2) / 2\n",
    "    return center_x, center_y\n",
    "\n",
    "\n",
    "def compute_center_ocr(bbox):\n",
    "    \"\"\"\n",
    "    Computes center point of ocr reading\n",
    "    :param bbox: bbox in format [x1, y1, x2, y2, x3, y3, x4, y4] (starts from top left order is clockwise)\n",
    "    :return: avg_x, avg_y\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2, x3, y3, x4, y4 = bbox\n",
    "    center_x = (x1 + x3) / 2\n",
    "    center_y = (y1 + y3) / 2\n",
    "    return center_x, center_y\n",
    "def is_valid_reading_distance(reading):\n",
    "    \"\"\"\n",
    "    Checks if reading fits pattern considering distance units\n",
    "    (only check if it contains units, secondary regex will be done)\n",
    "    :param reading: reading results obtained from ocr\n",
    "    :return: returns reading if it fits pattern\n",
    "    \"\"\"\n",
    "    pattern = r\"(\\d+\\s*(?:meters?|ft|feet|inch(?:es)?|m))\"\n",
    "    return re.search(pattern, reading)\n",
    "def euclidean_distance(center1, center2):\n",
    "    \"\"\"\n",
    "    Calculates distance between [x1,y1] and [x2,y2]\n",
    "    :param center1: center coordinates of first point\n",
    "    :param center2: center coordinates of second point\n",
    "    :return: distance\n",
    "    \"\"\"\n",
    "    return ((center1[0] - center2[0])**2 + (center1[1] - center2[1])**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc837536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_results_by_distance(obj_detection_bbox, ocr_results, threshold):\n",
    "    \"\"\"\n",
    "    Narrowing down possible matches for obj's and ocr's by discarding values farther away than threshold\n",
    "    :param obj_detection_bbox: bbox of object\n",
    "    :param ocr_results: bbox of ocr reading\n",
    "    :param threshold: limit value, after calculating center of obj bbox and ocr reading bbox,\n",
    "    if calculated value is more than threshold, that value will be discarded\n",
    "    :return: returns readings within threshold value\n",
    "    \"\"\"\n",
    "    filtered_results = []\n",
    "    obj_center = compute_center_obj(obj_detection_bbox)\n",
    "\n",
    "    for result in ocr_results:\n",
    "        reading, ocr_bbox = result\n",
    "        if not is_valid_reading_distance(reading):  # check if the reading is valid\n",
    "            continue\n",
    "        ocr_center = compute_center_ocr(ocr_bbox)\n",
    "        distance = euclidean_distance(obj_center, ocr_center)\n",
    "        if distance < threshold:\n",
    "            filtered_results.append(result)\n",
    "\n",
    "    return filtered_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "388af35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Dimension:\n",
    "    def __init__(self, node_1=None, node_2=None, value=None, unit=None, obj_det_bbox=None, text_bbox=None):\n",
    "        self.node_1 = node_1\n",
    "        self.node_2 = node_2\n",
    "        self.value = value\n",
    "        self.unit = unit\n",
    "        self.obj_det_bbox = obj_det_bbox\n",
    "        self.text_bbox = text_bbox\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"Dimension(node_1={self.node_1}, node_2={self.node_2}, value={self.value}, \"\n",
    "                f\"unit={self.unit}, obj_det_bbox={self.obj_det_bbox}, text_bbox={self.text_bbox})\")\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, bbox_x=None, bbox_y=None, shape_x=None, shape_y=None, name=None):\n",
    "        self.bbox_x = bbox_x\n",
    "        self.bbox_y = bbox_y\n",
    "        self.shape_x = shape_x\n",
    "        self.shape_y = shape_y\n",
    "        self.name = name\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Node):\n",
    "            return (self.bbox_x == other.bbox_x and self.bbox_y == other.bbox_y\n",
    "                    and self.shape_x == other.shape_x and self.shape_y == other.shape_y\n",
    "                    and self.name == other.name)\n",
    "        return False\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Node(name={self.name}, bbox_x={self.bbox_x}, bbox_y={self.bbox_y}, shape_x={self.shape_x},\" \\\n",
    "               f\" shape_y={self.shape_y})\"\n",
    "\n",
    "\n",
    "class FixSupport:\n",
    "    def __init__(self, node=None, fx=0, fy=0, moment=0):\n",
    "        self.node = node\n",
    "        self.fx = fx\n",
    "        self.fy = fy\n",
    "        self.moment = moment\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"FixSupport(node={self.node}, Fx={self.fx}, Fy={self.fy}, Moment={self.moment})\"\n",
    "\n",
    "\n",
    "class PinSupport:\n",
    "    def __init__(self, node=None, fx=0, fy=0):\n",
    "        self.fx = fx\n",
    "        self.fy = fy\n",
    "        self.node = node\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"PinSupport(node={self.node}, Fx={self.fx}, Fy={self.fy})\"\n",
    "\n",
    "\n",
    "class RollerSupport:\n",
    "    def __init__(self, node=None, fy=0):\n",
    "        self.fy = fy\n",
    "        self.node = node\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"RollerSupport(node={self.node}, Fy={self.fy})\"\n",
    "\n",
    "\n",
    "class Frame:\n",
    "    def __init__(self, node1=None, node2=None, obj_det_bbox=None, direction=None):\n",
    "        self.node_1 = node1\n",
    "        self.node_2 = node2\n",
    "        self.obj_det_bbox = obj_det_bbox\n",
    "        self.direction = direction\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Frame(node_1={repr(self.node_1)}, node_2={repr(self.node_2)}, obj_det_bbox={self.obj_det_bbox},\" \\\n",
    "               f\" direction={self.direction})\"\n",
    "\n",
    "\n",
    "class PointLoad:\n",
    "    def __init__(self, node=None, direction=None, value=None, unit=None, text_bbox=None, obj_det_bbox=None):\n",
    "        self.node = node\n",
    "        self.direction = direction\n",
    "        self.value = value\n",
    "        self.unit = unit\n",
    "        self.text_bbox = text_bbox\n",
    "        self.obj_det_bbox = obj_det_bbox\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"PointLoad(node={self.node}, direction={self.direction}, value={self.value}, unit={self.unit},\" \\\n",
    "               f\" text_bbox = {self.text_bbox}, obj_det_bbox = {self.obj_det_bbox})\"\n",
    "\n",
    "class DistributedLoad:\n",
    "    def __init__(self, node1=None, node2=None,obj_det_bbox = None, direction=None, value=None, unit=None):\n",
    "        self.node1 = node1\n",
    "        self.node2 = node2\n",
    "        self.obj_det_bbox = obj_det_bbox\n",
    "        self.direction = direction\n",
    "        self.value = value\n",
    "        self.unit = unit\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"DistributedLoad(node1={self.node1}, node2={self.node2}, obj_det_bbox={self.obj_det_bbox}, direction={self.direction}, value={self.value}, unit={self.unit})\"\n",
    "\n",
    "class TriangularDistributedLoad:\n",
    "    def __init__(self, node1=None, node2=None,obj_det_bbox = None, direction=None, value1=None, value2=None, unit=None):\n",
    "        self.node1 = node1\n",
    "        self.node2 = node2\n",
    "        self.obj_det_bbox = obj_det_bbox\n",
    "        self.direction = direction\n",
    "        self.value1 = value1\n",
    "        self.value2 = value2\n",
    "        self.unit = unit\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"TriangularDistributedLoad(node1={self.node1}, node2={self.node2}, obj_det_bbox={self.obj_det_bbox}, direction={self.direction}, value1={self.value1}, value2={self.value2}, unit={self.unit})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9755b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['3 m'], [412.0, 245.0, 456.0, 244.0, 456.0, 265.0, 411.0, 266.0], [247, 312, 269, 553]], [['1.5 m'], [199, 238, 315, 238, 315, 269, 199, 269], [238, 199, 269, 315]], [['1.5 m'], [88, 240, 204, 240, 204, 269, 88, 269], [240, 88, 269, 204]]]\n"
     ]
    }
   ],
   "source": [
    "def match_spacings(spacing_bbox, readings):\n",
    "    \"\"\"\n",
    "    Takes detection results classified as \"spacing\" and matching them with corresponding reading\n",
    "    :param spacing_bbox: bbox of spacing instance\n",
    "    :param readings: ocr readings\n",
    "    :return: list [[ocr reading], [reading bbox], [obj det bbox]]\n",
    "    \"\"\"\n",
    "    final_results = []\n",
    "    for bbox in spacing_bbox:\n",
    "        threshold = adjust_threshold(bbox)\n",
    "        filtered_ocr_results = filter_results_by_distance(bbox, readings, threshold)\n",
    "        if filtered_ocr_results:\n",
    "            for item in filtered_ocr_results:\n",
    "                result = [[item[0]], item[1], bbox]\n",
    "                final_results.append(result)\n",
    "    return final_results\n",
    "\n",
    "spacing_bbox = [item[:4] for item in applicable_list if item[4] == 'spacing']\n",
    "spacing_matching_results = match_spacings(spacing_bbox, ocr_results)\n",
    "print(spacing_matching_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdff1940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['3 m'], [412.0, 245.0, 456.0, 244.0, 456.0, 265.0, 411.0, 266.0], [247, 312, 269, 553]], [['1.5 m'], [199, 238, 315, 238, 315, 269, 199, 269], [238, 199, 269, 315]], [['1.5 m'], [88, 240, 204, 240, 204, 269, 88, 269], [240, 88, 269, 204]]]\n"
     ]
    }
   ],
   "source": [
    "def ocr_secondary_filter_distance(matching_results):\n",
    "    \"\"\"\n",
    "    Filters readings to remove absurd characters\n",
    "    :param matching_results: first filter results\n",
    "    :return: input with bad readings removed\n",
    "    \"\"\"\n",
    "    pattern = r\"(\\d+([.]\\d+)?|(\\d+\\s*/\\s*\\d+))\\s*(m|meters?)\"\n",
    "    for item in matching_results:\n",
    "        reading = item[0][0]\n",
    "        match = re.search(pattern, reading)\n",
    "        if match:\n",
    "            extracted_value = match.group()\n",
    "            item[0][0] = extracted_value  # Update the original reading with the extracted value\n",
    "    return matching_results\n",
    "spacing_sec_filtered_results = ocr_secondary_filter_distance(spacing_matching_results)\n",
    "print(spacing_sec_filtered_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac8b7b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[3.0, 'm'], [412.0, 245.0, 456.0, 244.0, 456.0, 265.0, 411.0, 266.0], [247, 312, 269, 553]], [[1.5, 'm'], [199, 238, 315, 238, 315, 269, 199, 269], [238, 199, 269, 315]], [[1.5, 'm'], [88, 240, 204, 240, 204, 269, 88, 269], [240, 88, 269, 204]]]\n"
     ]
    }
   ],
   "source": [
    "def extract_value_unit(sec_filtered_results):\n",
    "    \"\"\"\n",
    "    Extracts precise value and units from OCR text.\n",
    "    :param sec_filtered_results: text results after two times filtering\n",
    "    :return: replacing input's text part with a list containing unit and value\n",
    "    \"\"\"\n",
    "    # regex pattern to match value and unit (supports meter, m, feet, ft, inch)\n",
    "    pattern = r'(\\d+(?:\\.\\d+)?)\\s*(meters?|ft|feet|inch(?:es)?|m)'\n",
    "    for element in sec_filtered_results:\n",
    "        match = re.search(pattern, element[0][0], re.IGNORECASE)\n",
    "        if match:\n",
    "            value, unit = match.groups()\n",
    "            element[0] = [float(value), unit]  # Use float to handle decimal values\n",
    "    return sec_filtered_results\n",
    "spacing_extracted_results = extract_value_unit(spacing_sec_filtered_results)\n",
    "print(spacing_extracted_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd9f7f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.5, 'm'], [88, 240, 204, 240, 204, 269, 88, 269], [240, 88, 269, 204]], [[1.5, 'm'], [199, 238, 315, 238, 315, 269, 199, 269], [238, 199, 269, 315]], [[3.0, 'm'], [412.0, 245.0, 456.0, 244.0, 456.0, 265.0, 411.0, 266.0], [247, 312, 269, 553]]]\n"
     ]
    }
   ],
   "source": [
    "def sorting_key(entry):\n",
    "    \"\"\"\n",
    "    Sorts dimensions according to avg_x and then by avg_y in reverse order\n",
    "    :param entry: List containing spacing info\n",
    "    :return: tuple used for sorting\n",
    "    \"\"\"\n",
    "    # Extract object detection bounding box\n",
    "    y1, x1, y2, x2 = entry[2]\n",
    "    avg_x = (x1 + x2) / 2\n",
    "    avg_y = (y1 + y2) / 2\n",
    "    # Return a tuple where avg_x is the primary key and -avg_y is the secondary key\n",
    "    return (avg_x, -avg_y)\n",
    "\n",
    "sorted_spacings = sorted(spacing_extracted_results, key=sorting_key)\n",
    "print(sorted_spacings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79d30a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.5, 'm'], [88, 240, 204, 240, 204, 269, 88, 269], [240, 88, 269, 204], 'horizontal'], [[1.5, 'm'], [199, 238, 315, 238, 315, 269, 199, 269], [238, 199, 269, 315], 'horizontal'], [[3.0, 'm'], [412.0, 245.0, 456.0, 244.0, 456.0, 265.0, 411.0, 266.0], [247, 312, 269, 553], 'horizontal']]\n"
     ]
    }
   ],
   "source": [
    "def dimension_direction(sorted_spacings, img):\n",
    "    \"\"\"\n",
    "    Decides direction of the dimension using pixel values\n",
    "    :param sorted_spacings: list of spacings\n",
    "    :param img: input image\n",
    "    :return: adds direction to the input list and returns it back\n",
    "    \"\"\"\n",
    "    sorted_spacing_with_direction = []\n",
    "    for spacing_info in sorted_spacings:\n",
    "        y1, x1, y2, x2 = spacing_info[2]\n",
    "        roi = img[y1:y2, x1:x2]\n",
    "        gray = cv.cvtColor(roi, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Threshold the image\n",
    "        _, thresh = cv.threshold(gray, 200, 255, cv.THRESH_BINARY_INV)  # Adjust the threshold value as needed\n",
    "\n",
    "        # Sum along x and y axes\n",
    "        sum_x = np.sum(thresh, axis=0)\n",
    "        sum_y = np.sum(thresh, axis=1)\n",
    "\n",
    "        # Check where the predominant sum is\n",
    "        x_peak = np.max(sum_x)\n",
    "        y_peak = np.max(sum_y)\n",
    "\n",
    "        # Decide the direction based on the peaks\n",
    "        if x_peak > 1.5 * y_peak:  # Adjust the factor as needed\n",
    "            direction = \"vertical\"\n",
    "        elif y_peak > 1.5 * x_peak:\n",
    "            direction = \"horizontal\"\n",
    "        else:\n",
    "            direction = \"angled\"\n",
    "\n",
    "        spacing_info.append(direction)\n",
    "\n",
    "        # Append the updated spacing_info to the global list\n",
    "        sorted_spacing_with_direction.append(spacing_info)\n",
    "\n",
    "    return sorted_spacing_with_direction\n",
    "sorted_spacings_with_directions = dimension_direction(sorted_spacings, img)\n",
    "print(sorted_spacings_with_directions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66e63bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_node_of_previous_spacing(spacing, node1, node2):\n",
    "    \"\"\"\n",
    "    Before placing nodes in a logical order, calculating distances between nodes to find which node is common between\n",
    "    adjacent spacings\n",
    "    :param spacing: Dimension instance\n",
    "    :param node1: first node of the spacing\n",
    "    :param node2: second node of the spacing\n",
    "    :return: between 4 input nodes, sends back two which has the minimum distance between them\n",
    "    \"\"\"\n",
    "    sn1 = [spacing.node_1.bbox_x, spacing.node_1.bbox_y]\n",
    "    sn2 = [spacing.node_2.bbox_x, spacing.node_2.bbox_y]\n",
    "    n1 = [node1.bbox_x, node1.bbox_y]\n",
    "    n2 = [node2.bbox_x, node2.bbox_y]\n",
    "\n",
    "    # Find distances between nodes\n",
    "    dist_sn1_n1 = euclidean_distance(sn1, n1)\n",
    "    dist_sn1_n2 = euclidean_distance(sn1, n2)\n",
    "    dist_sn2_n1 = euclidean_distance(sn2, n1)\n",
    "    dist_sn2_n2 = euclidean_distance(sn2, n2)\n",
    "\n",
    "    # Determine the node (either node1 or node2) that is closest to any of the spacing nodes\n",
    "    dist_list = [dist_sn1_n1, dist_sn1_n2, dist_sn2_n1, dist_sn2_n2]\n",
    "    min_dist = min(dist_list)\n",
    "\n",
    "    if min_dist == dist_sn1_n1:\n",
    "        return spacing.node_1, node1\n",
    "    elif min_dist == dist_sn1_n2:\n",
    "        return spacing.node_1, node2\n",
    "    elif min_dist == dist_sn2_n1:\n",
    "        return spacing.node_2, node1\n",
    "    else:\n",
    "        return spacing.node_2, node2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75348468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spacings are [Dimension(node_1=Node(name=None, bbox_x=88, bbox_y=254, shape_x=0, shape_y=0), node_2=Node(name=None, bbox_x=204, bbox_y=254, shape_x=1.5, shape_y=0), value=1.5, unit=m, obj_det_bbox=[240, 88, 269, 204], text_bbox=[88, 240, 204, 240, 204, 269, 88, 269]), Dimension(node_1=Node(name=None, bbox_x=204, bbox_y=254, shape_x=1.5, shape_y=0), node_2=Node(name=None, bbox_x=315, bbox_y=253.5, shape_x=3.0, shape_y=0), value=1.5, unit=m, obj_det_bbox=[238, 199, 269, 315], text_bbox=[199, 238, 315, 238, 315, 269, 199, 269]), Dimension(node_1=Node(name=None, bbox_x=315, bbox_y=253.5, shape_x=3.0, shape_y=0), node_2=Node(name=None, bbox_x=553, bbox_y=258.0, shape_x=6.0, shape_y=0), value=3.0, unit=m, obj_det_bbox=[247, 312, 269, 553], text_bbox=[412.0, 245.0, 456.0, 244.0, 456.0, 265.0, 411.0, 266.0])]\n",
      "----------------------------------------------------------------------------------\n",
      "nodes are [Node(name=None, bbox_x=88, bbox_y=254, shape_x=0, shape_y=0), Node(name=None, bbox_x=204, bbox_y=254, shape_x=1.5, shape_y=0), Node(name=None, bbox_x=315, bbox_y=253.5, shape_x=3.0, shape_y=0), Node(name=None, bbox_x=553, bbox_y=258.0, shape_x=6.0, shape_y=0)]\n"
     ]
    }
   ],
   "source": [
    "def initialize_parameters(sorted_spacings_with_directions):\n",
    "    \"\"\"\n",
    "    Initializes base classes for question\n",
    "    :param sorted_spacings_with_directions: list containing spacing information\n",
    "    :return: created instances of nodes and spacings\n",
    "    \"\"\"\n",
    "    spacing_instances = []\n",
    "    node_instances = []\n",
    "    shape_x_start = 0\n",
    "    shape_y_start = 0\n",
    "    for spacing_info in sorted_spacings_with_directions:\n",
    "        if not spacing_instances:\n",
    "            if spacing_info[3] == \"horizontal\":\n",
    "                y1, x1, y2, x2 = spacing_info[2]\n",
    "                distance = spacing_info[0][0]\n",
    "                unit = spacing_info[0][1]\n",
    "                obj_det_bbox = spacing_info[2]\n",
    "                text_bbox = spacing_info[1]\n",
    "                bbox_x = x1\n",
    "                bbox_y = int((y1 + y2) / 2)\n",
    "                node_1 = Node(bbox_x, bbox_y, shape_x_start, shape_y_start)\n",
    "                node_instances.append(node_1)\n",
    "                bbox_x = x2\n",
    "                bbox_y = int((y1 + y2) / 2)\n",
    "                node_2 = Node(bbox_x, bbox_y, shape_x_start + distance, shape_y_start)\n",
    "                node_instances.append(node_2)\n",
    "                spacing = Dimension(node_1, node_2, distance, unit, obj_det_bbox, text_bbox)\n",
    "                spacing_instances.append(spacing)\n",
    "            elif spacing_info[3] == \"vertical\":\n",
    "                y1, x1, y2, x2 = spacing_info[2]\n",
    "                distance = spacing_info[0][0]\n",
    "                unit = spacing_info[0][1]\n",
    "                obj_det_bbox = spacing_info[2]\n",
    "                text_bbox = spacing_info[1]\n",
    "                bbox_x = int(x1 + x2) / 2\n",
    "                bbox_y = y1\n",
    "                node_1 = Node(bbox_x, bbox_y, shape_x_start, shape_y_start)\n",
    "                node_instances.append(node_1)\n",
    "                bbox_x = int(x1 + x2) / 2\n",
    "                bbox_y = y2\n",
    "                node_2 = Node(bbox_x, bbox_y, shape_x_start, shape_y_start + distance)\n",
    "                node_instances.append(node_2)\n",
    "                spacing = Dimension(node_1, node_2, distance, unit, obj_det_bbox, text_bbox)\n",
    "                spacing_instances.append(spacing)\n",
    "            else:\n",
    "                # code the nodes for angled dimensioning\n",
    "                pass\n",
    "        else:\n",
    "            if spacing_info[3] == \"horizontal\":\n",
    "                y1, x1, y2, x2 = spacing_info[2]\n",
    "                distance = spacing_info[0][0]\n",
    "                unit = spacing_info[0][1]\n",
    "                obj_det_bbox = spacing_info[2]\n",
    "                text_bbox = spacing_info[1]\n",
    "                bbox_x = x1\n",
    "                bbox_y = int(y1 + y2) / 2\n",
    "                node_1 = Node(bbox_x=bbox_x, bbox_y=bbox_y)\n",
    "                bbox_x = x2\n",
    "                bbox_y = int(y1 + y2) / 2\n",
    "                node_2 = Node(bbox_x=bbox_x, bbox_y=bbox_y)\n",
    "                # psc_node = previous spacing closest node\n",
    "                # cc_node = current closest node\n",
    "                psc_node, cc_node = find_closest_node_of_previous_spacing(spacing_instances[-1], node_1, node_2)\n",
    "                if cc_node == node_1:\n",
    "                    node_2.shape_x = psc_node.shape_x + distance\n",
    "                    node_2.shape_y = psc_node.shape_y\n",
    "                    node_instances.append(node_2)\n",
    "                    spacing = Dimension(psc_node, node_2, distance, unit, obj_det_bbox, text_bbox)\n",
    "                    spacing_instances.append(spacing)\n",
    "                else:\n",
    "                    node_1.shape_x = psc_node.shape_x - distance\n",
    "                    node_1.shape_y = psc_node.shape_y\n",
    "                    node_instances.append(node_1)\n",
    "                    spacing = Dimension(node_1, psc_node, distance, unit, obj_det_bbox, text_bbox)\n",
    "                    spacing_instances.append(spacing)\n",
    "            elif spacing_info[3] == \"vertical\":\n",
    "                y1, x1, y2, x2 = spacing_info[2]\n",
    "                distance = spacing_info[0][0]\n",
    "                unit = spacing_info[0][1]\n",
    "                obj_det_bbox = spacing_info[2]\n",
    "                text_bbox = spacing_info[1]\n",
    "                bbox_x = int(x1 + x2) / 2\n",
    "                bbox_y = y1\n",
    "                node_1 = Node(bbox_x=bbox_x, bbox_y=bbox_y)\n",
    "                bbox_x = int(x1 + x2) / 2\n",
    "                bbox_y = y2\n",
    "                node_2 = Node(bbox_x=bbox_x, bbox_y=bbox_y)\n",
    "                # psc_node = previous spacing closest node\n",
    "                # cc_node = current closest node\n",
    "                psc_node, cc_node = find_closest_node_of_previous_spacing(spacing_instances[-1], node_1, node_2)\n",
    "                if cc_node == node_1:\n",
    "                    node_2.shape_x = psc_node.shape_x\n",
    "                    node_2.shape_y = psc_node.shape_y - distance\n",
    "                    node_instances.append(node_2)\n",
    "                    spacing = Dimension(psc_node, node_2, distance, unit, obj_det_bbox, text_bbox)\n",
    "                    spacing_instances.append(spacing)\n",
    "                else:\n",
    "                    node_1.shape_x = psc_node.shape_x\n",
    "                    node_1.shape_y = psc_node.shape_y + distance\n",
    "                    node_instances.append(node_1)\n",
    "                    spacing = Dimension(node_1, psc_node, distance, unit, obj_det_bbox, text_bbox)\n",
    "                    spacing_instances.append(spacing)\n",
    "            else:\n",
    "                pass\n",
    "    return spacing_instances, node_instances\n",
    "spacing_instances, node_instances = initialize_parameters(sorted_spacings_with_directions)\n",
    "print(\"spacings are\", spacing_instances)\n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "print(\"nodes are\", node_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "469bda6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_shapes(node_list):\n",
    "    \"\"\"\n",
    "    Nodes with negative values are corrected in this function\n",
    "    :param node_list: list of nodes\n",
    "    :return: corrected list of nodes\n",
    "    \"\"\"\n",
    "    # Find the minimum shape_x and shape_y values\n",
    "    min_shape_x = min(node.shape_x for node in node_list)\n",
    "    min_shape_y = min(node.shape_y for node in node_list)\n",
    "\n",
    "    # Calculate the offsets required to make the smallest shape values zero\n",
    "    offset_x = abs(min_shape_x) if min_shape_x < 0 else 0\n",
    "    offset_y = abs(min_shape_y) if min_shape_y < 0 else 0\n",
    "\n",
    "    # Apply the offsets to all node instances\n",
    "    for node in node_list:\n",
    "        node.shape_x += offset_x\n",
    "        node.shape_y += offset_y\n",
    "\n",
    "    return node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea9c6140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Node(name=None, bbox_x=88, bbox_y=254, shape_x=0, shape_y=0), Node(name=None, bbox_x=204, bbox_y=254, shape_x=1.5, shape_y=0), Node(name=None, bbox_x=315, bbox_y=253.5, shape_x=3.0, shape_y=0), Node(name=None, bbox_x=553, bbox_y=258.0, shape_x=6.0, shape_y=0)]\n"
     ]
    }
   ],
   "source": [
    "def find_and_append_missing_nodes(node_instances):\n",
    "    \"\"\"\n",
    "    Creates missing nodes according to every definable point\n",
    "    :param node_instances: Raw (negative value corrected) node points\n",
    "    :return: New list (if any new node created in the process)\n",
    "    \"\"\"\n",
    "    # Extract unique shape_x and shape_y values\n",
    "    unique_shape_x = {node.shape_x for node in node_instances}\n",
    "    unique_shape_y = {node.shape_y for node in node_instances}\n",
    "\n",
    "    # Generate all possible combinations based on the unique values\n",
    "    shape_combinations = set(itertools.product(unique_shape_x, unique_shape_y))\n",
    "\n",
    "    # Identify existing combinations from node_instances\n",
    "    existing_shapes = {(node.shape_x, node.shape_y) for node in node_instances}\n",
    "\n",
    "    # Identify missing combinations\n",
    "    missing_shapes = shape_combinations - existing_shapes\n",
    "\n",
    "    # For each missing shape combination, create and append a new node to node_instances\n",
    "    for shape_x, shape_y in missing_shapes:\n",
    "        node_for_shape_x = next((node for node in node_instances if node.shape_x == shape_x), None)\n",
    "        node_for_shape_y = next((node for node in node_instances if node.shape_y == shape_y), None)\n",
    "\n",
    "        bbox_x = node_for_shape_x.bbox_x if node_for_shape_x else None\n",
    "        bbox_y = node_for_shape_y.bbox_y if node_for_shape_y else None\n",
    "\n",
    "        missing_node = Node(bbox_x=bbox_x, bbox_y=bbox_y, shape_x=shape_x, shape_y=shape_y)\n",
    "        node_instances.append(missing_node)\n",
    "\n",
    "    return node_instances\n",
    "node_instances = find_and_append_missing_nodes(node_instances)\n",
    "print(node_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "31d8c678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Node(name=A, bbox_x=88, bbox_y=254, shape_x=0, shape_y=0), Node(name=C, bbox_x=204, bbox_y=254, shape_x=1.5, shape_y=0), Node(name=D, bbox_x=315, bbox_y=253.5, shape_x=3.0, shape_y=0), Node(name=B, bbox_x=553, bbox_y=258.0, shape_x=6.0, shape_y=0)]\n"
     ]
    }
   ],
   "source": [
    "def append_names_to_nodes(node_instances, ocr_results, distance_threshold=100):\n",
    "    \"\"\"\n",
    "    Appends name to the nodes, node names are generally symbolized with one character (A,B,C, etc.)\n",
    "    Closest reading mathching to this pattern is appended if reading is in the threshold value\n",
    "    :param node_instances: node list\n",
    "    :param ocr_results: ocr text\n",
    "    :param distance_threshold: pixel value\n",
    "    :return: name appended node list\n",
    "    \"\"\"\n",
    "    pattern = r'^[A-Za-z]$'\n",
    "    for text, bbox in ocr_results:\n",
    "        if re.match(pattern, text):  # Check if the text is a single letter (either uppercase or lowercase)\n",
    "            center_x = sum(bbox[i] for i in [0, 2, 4, 6]) / 4\n",
    "            center_y = sum(bbox[i] for i in [1, 3, 5, 7]) / 4\n",
    "\n",
    "            distances = [(node, euclidean_distance([center_x, center_y], [node.bbox_x, node.bbox_y]))\n",
    "                         for node in node_instances]\n",
    "            closest_node, min_distance = min(distances, key=lambda x: x[1])\n",
    "\n",
    "            if min_distance <= distance_threshold:\n",
    "                closest_node.name = text\n",
    "    return None\n",
    "append_names_to_nodes(node_instances, ocr_results, distance_threshold=100)\n",
    "print(node_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a5c1fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[186, 535, 227, 566, 'roller_support'], [169, 67, 224, 104, 'pin_support']]\n"
     ]
    }
   ],
   "source": [
    "support_bbox = [box for box in applicable_list if 'support' in box[-1]]\n",
    "print(support_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24d7677b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fix []\n",
      "pin [PinSupport(node=Node(name=A, bbox_x=88, bbox_y=254, shape_x=0, shape_y=0), Fx=0, Fy=0)]\n",
      "roller [RollerSupport(node=Node(name=B, bbox_x=553, bbox_y=258.0, shape_x=6.0, shape_y=0), Fy=0)]\n"
     ]
    }
   ],
   "source": [
    "def create_support_instances(support_bbox, node_instances):\n",
    "    \"\"\"\n",
    "    Creating support instances according to the obj det support instances\n",
    "    :param support_bbox: bbox coordinates and class information of supports\n",
    "    :param node_instances: node information\n",
    "    :return: created support classes which also has their own nodes appended\n",
    "    \"\"\"\n",
    "    fix_support_instances = []\n",
    "    pin_support_instances = []\n",
    "    roller_support_instances = []\n",
    "    for bbox in support_bbox:\n",
    "        center_x = (bbox[1] + bbox[3]) / 2\n",
    "        center_y = (bbox[0] + bbox[2]) / 2\n",
    "        closest_node = min(node_instances, key=lambda node: \n",
    "                           euclidean_distance([center_x, center_y], [node.bbox_x, node.bbox_y]))\n",
    "        if bbox[-1] == 'fix_support':\n",
    "            fix_support_instances.append(FixSupport(node=closest_node))\n",
    "        elif bbox[-1] == 'pin_support':\n",
    "            pin_support_instances.append(PinSupport(node=closest_node))\n",
    "        elif bbox[-1] == 'roller_support':\n",
    "            roller_support_instances.append(RollerSupport(node=closest_node))\n",
    "        else:\n",
    "            pass\n",
    "    return fix_support_instances, pin_support_instances, roller_support_instances\n",
    "fix_support_instances, pin_support_instances, roller_support_instances = create_support_instances(support_bbox, node_instances)\n",
    "print(\"fix\", fix_support_instances)\n",
    "print(\"pin\", pin_support_instances)\n",
    "print(\"roller\", roller_support_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3dc7d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[153, 65, 190, 567, 'frame']]\n"
     ]
    }
   ],
   "source": [
    "frame_boxes = [box for box in applicable_list if box[-1] == 'frame']\n",
    "print(frame_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4be8ddb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[153, 65, 190, 567, 'frame', 'horizontal']]\n"
     ]
    }
   ],
   "source": [
    "def find_frame_direction(frame_boxes, img):\n",
    "    \"\"\"\n",
    "    Finds and appends direction of the frame\n",
    "    :param frame_boxes: bbox info of frame\n",
    "    :param img: input image\n",
    "    :return: direction appended bbox list\n",
    "    \"\"\"\n",
    "    for frame_info in frame_boxes:\n",
    "        y1,x1,y2,x2 = frame_info[:4]\n",
    "        roi = img[y1:y2, x1:x2]\n",
    "        gray = cv.cvtColor(roi, cv.COLOR_BGR2GRAY)\n",
    "         # Threshold the image\n",
    "        _, thresh = cv.threshold(gray, 200, 255, cv.THRESH_BINARY_INV)  # Adjust the threshold value as needed\n",
    "\n",
    "        # Sum along x and y axes\n",
    "        sum_x = np.sum(thresh, axis=0)\n",
    "        sum_y = np.sum(thresh, axis=1)\n",
    "\n",
    "        # Check where the predominant sum is\n",
    "        x_peak = np.max(sum_x)\n",
    "        y_peak = np.max(sum_y)\n",
    "\n",
    "        # Decide the direction based on the peaks\n",
    "        if x_peak > 1.5 * y_peak:  # Adjust the factor as needed\n",
    "            direction = \"vertical\"\n",
    "        elif y_peak > 1.5 * x_peak:\n",
    "            direction = \"horizontal\"\n",
    "        else:\n",
    "            direction = \"angled\"\n",
    "        frame_info.append(direction)\n",
    "    return frame_boxes\n",
    "frame_boxes = find_frame_direction(frame_boxes, img)\n",
    "print(frame_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69fef3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_node(x, y, nodes):\n",
    "    \"\"\"\n",
    "    Self explained\n",
    "    :param x: x coordinate\n",
    "    :param y: y coordinate\n",
    "    :param nodes: node instances\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    def node_distance(node):\n",
    "        \"\"\"\n",
    "        Distance between coordinates and nodes\n",
    "        :param node: single node instance\n",
    "        :return: distance between node bbox center and given x-y coordinates\n",
    "        \"\"\"\n",
    "        return euclidean_distance([x, y], [node.bbox_x, node.bbox_y])\n",
    "    return min(nodes, key=node_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "94b014cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Frame(node_1=Node(name=A, bbox_x=88, bbox_y=254, shape_x=0, shape_y=0), node_2=Node(name=B, bbox_x=553, bbox_y=258.0, shape_x=6.0, shape_y=0), obj_det_bbox=None, direction=None)]\n"
     ]
    }
   ],
   "source": [
    "def initialize_frames(frame_boxes, node_instances):\n",
    "    \"\"\"\n",
    "    Creates instances of frames\n",
    "    :param frame_boxes: bbox list of frames\n",
    "    :param node_instances: list of nodes\n",
    "    :return: list of frame instances\n",
    "    \"\"\"\n",
    "    frame_instances = []\n",
    "    for box in frame_boxes:\n",
    "        if box[5] == \"horizontal\":\n",
    "            x1 = box[1]\n",
    "            x2 = box[3]\n",
    "            y = int((box[0] + box[2]) / 2)\n",
    "\n",
    "            # Get the closest node to x1 and x2\n",
    "            c_node1 = find_closest_node(x1, y, node_instances)\n",
    "            c_node2 = find_closest_node(x2, y, node_instances)\n",
    "\n",
    "            frame_instance = Frame(node1=c_node1, node2=c_node2)\n",
    "            frame_instances.append(frame_instance)\n",
    "        elif box[5] == \"vertical\":\n",
    "            y1 = box[0]\n",
    "            y2 = box[2]\n",
    "            x = int((box[1] + box[3]) / 2)\n",
    "            # Get the closest node to x1 and x2\n",
    "            c_node1 = find_closest_node(x, y1, node_instances)\n",
    "            c_node2 = find_closest_node(x, y2, node_instances)\n",
    "\n",
    "            frame_instance = Frame(node1=c_node1, node2=c_node2)\n",
    "            frame_instances.append(frame_instance)\n",
    "        else:\n",
    "            # Need to fill this later\n",
    "            pass\n",
    "    return frame_instances\n",
    "frame_instances = initialize_frames(frame_boxes, node_instances)\n",
    "print(frame_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e0ea6f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_frames(frame, node_instances):\n",
    "    \"\"\"\n",
    "    Checks current frame instance and if frame passes through any nodes except the ones it is defined, it divides frame\n",
    "    :param frame: single frame instances\n",
    "    :param node_instances: list of nodes\n",
    "    :return: list of new frames\n",
    "    \"\"\"\n",
    "    # Check if it's a horizontal frame (direction is along x-axis) or vertical (direction is along y-axis)\n",
    "    is_horizontal = frame.node_1.shape_y == frame.node_2.shape_y\n",
    "\n",
    "    new_frames = []\n",
    "\n",
    "    # Extract the node list that lies between the nodes of this frame\n",
    "    if is_horizontal:\n",
    "        intermediate_nodes = sorted([node for node in node_instances\n",
    "                                     if frame.node_1.shape_y == node.shape_y\n",
    "                                     and frame.node_1.shape_x < node.shape_x < frame.node_2.shape_x],\n",
    "                                    key=lambda n: n.shape_x)\n",
    "    else:\n",
    "        intermediate_nodes = sorted([node for node in node_instances\n",
    "                                     if frame.node_1.shape_x == node.shape_x\n",
    "                                     and frame.node_1.shape_y < node.shape_y < frame.node_2.shape_y],\n",
    "                                    key=lambda n: n.shape_y)\n",
    "\n",
    "    # If there are no intermediate nodes, just return the original frame\n",
    "    if not intermediate_nodes:\n",
    "        return [frame]\n",
    "\n",
    "    # Create new frames based on intermediate nodes\n",
    "    start_node = frame.node_1\n",
    "    for node in intermediate_nodes:\n",
    "        new_frame = Frame(start_node, node, frame.obj_det_bbox, frame.direction)\n",
    "        new_frames.append(new_frame)\n",
    "        start_node = node\n",
    "\n",
    "    new_frame = Frame(start_node, frame.node_2, frame.obj_det_bbox, frame.direction)\n",
    "    new_frames.append(new_frame)\n",
    "\n",
    "    return new_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2b001976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Frame(node_1=Node(name=A, bbox_x=88, bbox_y=254, shape_x=0, shape_y=0), node_2=Node(name=C, bbox_x=204, bbox_y=254, shape_x=1.5, shape_y=0), obj_det_bbox=None, direction=None), Frame(node_1=Node(name=C, bbox_x=204, bbox_y=254, shape_x=1.5, shape_y=0), node_2=Node(name=D, bbox_x=315, bbox_y=253.5, shape_x=3.0, shape_y=0), obj_det_bbox=None, direction=None), Frame(node_1=Node(name=D, bbox_x=315, bbox_y=253.5, shape_x=3.0, shape_y=0), node_2=Node(name=B, bbox_x=553, bbox_y=258.0, shape_x=6.0, shape_y=0), obj_det_bbox=None, direction=None)]\n"
     ]
    }
   ],
   "source": [
    "def split_frame_based_on_nodes(frame_instances, node_instances):\n",
    "    \"\"\"\n",
    "    Loops through frame instances to divide them if necessary\n",
    "    :param frame_instances:  list of frame instances\n",
    "    :param node_instances: list of node instances\n",
    "    :return: new frame instances\n",
    "    \"\"\"\n",
    "    new_frames = []\n",
    "    for frame in frame_instances:\n",
    "        split_frames = divide_frames(frame, node_instances)\n",
    "        new_frames.extend(split_frames)\n",
    "    return new_frames\n",
    "new_frame_instances = split_frame_based_on_nodes(frame_instances, node_instances)\n",
    "print(new_frame_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "56e0b7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Frame(node_1=Node(name=A, bbox_x=88, bbox_y=254, shape_x=0, shape_y=0), node_2=Node(name=C, bbox_x=204, bbox_y=254, shape_x=1.5, shape_y=0), obj_det_bbox=None, direction=None), Frame(node_1=Node(name=C, bbox_x=204, bbox_y=254, shape_x=1.5, shape_y=0), node_2=Node(name=D, bbox_x=315, bbox_y=253.5, shape_x=3.0, shape_y=0), obj_det_bbox=None, direction=None), Frame(node_1=Node(name=D, bbox_x=315, bbox_y=253.5, shape_x=3.0, shape_y=0), node_2=Node(name=B, bbox_x=553, bbox_y=258.0, shape_x=6.0, shape_y=0), obj_det_bbox=None, direction=None)]\n"
     ]
    }
   ],
   "source": [
    "def create_nominal_frame(node_instances):\n",
    "    \"\"\"\n",
    "    Creates nominal frame if no frame detected\n",
    "    :param node_instances: list of nodes\n",
    "    :return: nominal frame\n",
    "    \"\"\"\n",
    "    new_frame_instances = []\n",
    "    for i in range(len(node_instances)):\n",
    "        for j in range(i + 1, len(node_instances)):\n",
    "            frame = Frame(node1=node_instances[i], node2=node_instances[j])\n",
    "            new_frame_instances.append(frame)\n",
    "    return new_frame_instances\n",
    "if not new_frame_instances:\n",
    "    new_frame_instances = create_nominal_frame(node_instances)\n",
    "print(new_frame_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2305e67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 288, 150, 346, 'point_load']]\n"
     ]
    }
   ],
   "source": [
    "pl_boxes = [box for box in applicable_list if box[-1] == 'point_load']\n",
    "print(pl_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f69f3623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PointLoad(node=Node(name=D, bbox_x=315, bbox_y=253.5, shape_x=3.0, shape_y=0), direction=None, value=None, unit=None, text_bbox = None, obj_det_bbox = [6, 288, 150, 346])]\n"
     ]
    }
   ],
   "source": [
    "def  initialize_pl(pl_boxes, node_instances):\n",
    "    \"\"\"\n",
    "    Creates point load instances\n",
    "    :param pl_boxes: list of pl bbox\n",
    "    :param node_instances: node list\n",
    "    :return: instances of pl\n",
    "    \"\"\"\n",
    "    point_load_instances = []\n",
    "    for box in pl_boxes:\n",
    "        center_x = (box[1] + box[3]) / 2\n",
    "        center_y = (box[0] + box[2]) / 2\n",
    "\n",
    "        try:\n",
    "            closest_node = min(node_instances,\n",
    "                               key=lambda node: euclidean_distance(\n",
    "                                   [center_x, center_y], [node.bbox_x, node.bbox_y]))\n",
    "\n",
    "            # For simplicity, I'm not assigning direction, value, and unit.\n",
    "            # These can be assigned based on further criteria or user input.\n",
    "            pl_instance = PointLoad(node=closest_node, obj_det_bbox=box[:4])\n",
    "            point_load_instances.append(pl_instance)\n",
    "        except IndexError:\n",
    "            print(f\"Error processing box with coordinates: {box}. Skipping to next box.\")\n",
    "    return point_load_instances\n",
    "point_load_instances = initialize_pl(pl_boxes, node_instances)\n",
    "print(point_load_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab4dd454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('D', [338.0, 203.0, 360.0, 203.0, 360.0, 227.0, 337.0, 227.0]), ('C', [219.0, 203.0, 241.0, 204.0, 239.0, 226.0, 219.0, 225.0]), ('5 kN', [290.0, 11.0, 346.0, 10.0, 346.0, 32.0, 289.0, 32.0]), ('1.5 m', [199, 238, 315, 238, 315, 269, 199, 269])]\n"
     ]
    }
   ],
   "source": [
    "def extract_pl_text(pl_boxes, ocr_results, threshold = 200):\n",
    "    \"\"\"\n",
    "    detects texts which are closet than threshold pixel\n",
    "    :param pl_boxes: list of pl boxes\n",
    "    :param ocr_results: ocr readins results\n",
    "    :return: possible readings of pl\n",
    "    \"\"\"\n",
    "    texts_within_range = []\n",
    "\n",
    "    for pl_box in pl_boxes:\n",
    "        pl_center_x = (pl_box[1] + pl_box[3]) / 2\n",
    "        pl_center_y = (pl_box[0] + pl_box[2]) / 2\n",
    "\n",
    "        for text_entry in ocr_results:\n",
    "            text, bbox = text_entry[0], text_entry[1]\n",
    "            center_x = sum(bbox[i] for i in [0, 2, 4, 6]) / 4\n",
    "            center_y = sum(bbox[i] for i in [1, 3, 5, 7]) / 4\n",
    "\n",
    "            if euclidean_distance([pl_center_x, pl_center_y], [center_x, center_y]) <= threshold:\n",
    "                texts_within_range.append(text_entry)\n",
    "    return texts_within_range\n",
    "possible_pl_text = extract_pl_text(pl_boxes, ocr_results)\n",
    "print(possible_pl_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c95697ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PointLoad(node=Node(name=D, bbox_x=315, bbox_y=253.5, shape_x=3.0, shape_y=0), direction=None, value=5, unit=kN, text_bbox = [290.0, 11.0, 346.0, 10.0, 346.0, 32.0, 289.0, 32.0], obj_det_bbox = [6, 288, 150, 346])]\n"
     ]
    }
   ],
   "source": [
    "def extract_precise_text(point_load_instances, possible_pl_text):\n",
    "    \"\"\"\n",
    "    Extracts precise magnitude and value for point loads and assigns related attributes\n",
    "    :param point_load_instances: list containing pl instances\n",
    "    :param possible_pl_text: close text to bbox of object detection\n",
    "    :return: related attributes assigned version of point load instances\n",
    "    \"\"\"\n",
    "    pattern = r\"(?:[A-Za-z]*\\s*=\\s*)?(?P<value>\\d+)\\s*(?P<unit>kN|k|t)(?P<type>/ft)?\"\n",
    "    for pl in point_load_instances:\n",
    "        closest_text_entry = None\n",
    "        min_distance = float('inf')\n",
    "\n",
    "        for text_entry in possible_pl_text:\n",
    "            text = text_entry[0]\n",
    "            bbox = text_entry[1]\n",
    "            center_x = sum(bbox[i] for i in [0, 2, 4, 6]) / 4\n",
    "            center_y = sum(bbox[i] for i in [1, 3, 5, 7]) / 4\n",
    "\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                distance = euclidean_distance([center_x, center_y], [pl.node.bbox_x, pl.node.bbox_y])\n",
    "                if distance < min_distance:\n",
    "                    closest_text_entry = text_entry\n",
    "                    closest_text_bbox = bbox\n",
    "                    min_distance = distance\n",
    "\n",
    "        # Assign the closest text entry (if found) to the PointLoad instance\n",
    "        if closest_text_entry:\n",
    "            text = closest_text_entry[0]\n",
    "            match = re.search(pattern, text)\n",
    "            value = match.group(\"value\")\n",
    "            unit = match.group(\"unit\")\n",
    "\n",
    "            pl.value = value\n",
    "            pl.unit = unit\n",
    "            pl.text_bbox = closest_text_bbox\n",
    "    return point_load_instances\n",
    "point_load_instances = extract_precise_text(point_load_instances, possible_pl_text)\n",
    "print(point_load_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a996f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_erosion(roi, max_iterations=10, threshold=1):\n",
    "    \"\"\"\n",
    "    Erodes image until remaining pixels drops lower than threshold\n",
    "    :param roi: region of interest on the image\n",
    "    :param max_iterations: self-explanatory\n",
    "    :param threshold: threshold limit\n",
    "    :return: returns binary image\n",
    "    \"\"\"\n",
    "    gray = cv.cvtColor(roi, cv.COLOR_BGR2GRAY)\n",
    "    _, binary = cv.threshold(gray, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "    prev_count = np.sum(binary == 255)\n",
    "\n",
    "    for _ in range(max_iterations):\n",
    "        eroded = cv.erode(binary, kernel)\n",
    "\n",
    "        # Count the non-zero pixels in the eroded image\n",
    "        current_count = np.sum(eroded == 255)\n",
    "\n",
    "        if current_count <= threshold or abs(current_count - prev_count) < 10:  # Change threshold as per requirement\n",
    "            break\n",
    "\n",
    "        binary = eroded\n",
    "        prev_count = current_count\n",
    "\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "459e9c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PointLoad(node=Node(name=D, bbox_x=315, bbox_y=253.5, shape_x=3.0, shape_y=0), direction=downward, value=5, unit=kN, text_bbox = [290.0, 11.0, 346.0, 10.0, 346.0, 32.0, 289.0, 32.0], obj_det_bbox = [6, 288, 150, 346])]\n"
     ]
    }
   ],
   "source": [
    "def pl_direction(pl_instances, img):\n",
    "    \"\"\"\n",
    "    Detects direction of pl by eroding arrows, eroding it until some threshold, only thickest part (arrowhead) will\n",
    "    remain, it will show the direction\n",
    "    :param pl_instances: list of pl instances\n",
    "    :param img: image\n",
    "    :return: None (directions appended instances inside)\n",
    "    \"\"\"\n",
    "    for pl in pl_instances:\n",
    "        y1, x1, y2, x2 = pl.obj_det_bbox\n",
    "        ocr_bbox = pl.text_bbox\n",
    "\n",
    "        if pl.text_bbox:\n",
    "            ry1 = int((ocr_bbox[1] + ocr_bbox[3]) / 2)\n",
    "            ry2 = int((ocr_bbox[5] + ocr_bbox[7]) / 2)\n",
    "            rx1 = int((ocr_bbox[0] + ocr_bbox[6]) / 2)\n",
    "            rx2 = int((ocr_bbox[2] + ocr_bbox[4]) / 2)\n",
    "\n",
    "            overlap_x1 = max(x1, rx1)\n",
    "            overlap_y1 = max(y1, ry1)\n",
    "            overlap_x2 = min(x2, rx2)\n",
    "            overlap_y2 = min(y2, ry2)\n",
    "\n",
    "            # If overlap exists, paint it white\n",
    "            if overlap_x1 < overlap_x2 and overlap_y1 < overlap_y2:\n",
    "                img[overlap_y1:overlap_y2, overlap_x1:overlap_x2] = 255\n",
    "\n",
    "        roi = img[y1:y2, x1:x2]\n",
    "        binary_roi = iterative_erosion(roi, max_iterations=1)\n",
    "\n",
    "        # Find the non-zero pixels' indices\n",
    "        y_indices, x_indices = np.where(binary_roi == 255)\n",
    "\n",
    "        # Calculate the average x and y coordinates\n",
    "        avg_x = np.mean(x_indices)\n",
    "        avg_y = np.mean(y_indices)\n",
    "\n",
    "        # Calculate midpoints of x and y axes\n",
    "        midpoint_x = binary_roi.shape[1] / 2\n",
    "        midpoint_y = binary_roi.shape[0] / 2\n",
    "\n",
    "        # Determine direction\n",
    "        if avg_y > midpoint_y and abs(avg_x - midpoint_x) < midpoint_x / 2:\n",
    "            direction = \"downward\"\n",
    "        elif avg_y < midpoint_y and abs(avg_x - midpoint_x) < midpoint_x / 2:\n",
    "            direction = \"upward\"\n",
    "        elif avg_x > midpoint_x and abs(avg_y - midpoint_y) < midpoint_y / 2:\n",
    "            direction = \"right\"\n",
    "        elif avg_x < midpoint_x and abs(avg_y - midpoint_y) < midpoint_y / 2:\n",
    "            direction = \"left\"\n",
    "        else:\n",
    "            direction = \"unknown\"\n",
    "\n",
    "        pl.direction = direction\n",
    "\n",
    "    return None\n",
    "if point_load_instances:\n",
    "    pl_direction(point_load_instances, img)\n",
    "print(point_load_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "318585e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Node(name=A, bbox_x=88, bbox_y=254, shape_x=0, shape_y=0), Node(name=C, bbox_x=204, bbox_y=254, shape_x=1.5, shape_y=0), Node(name=D, bbox_x=315, bbox_y=253.5, shape_x=3.0, shape_y=0), Node(name=B, bbox_x=553, bbox_y=258.0, shape_x=6.0, shape_y=0)]\n"
     ]
    }
   ],
   "source": [
    "sorted_nodes = sorted(node_instances, key=lambda node: (node.shape_y, node.shape_x))\n",
    "print(sorted_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9ec50954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "dl_boxes = [box for box in applicable_list if box[-1] == 'distributed_load']\n",
    "print(dl_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "86bf3ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_erosion_dl(roi, initial_iterations=1, max_iterations=10, threshold=1):\n",
    "    \"\"\"\n",
    "    Iterative erosion for distributed load\n",
    "    :param roi: region of interest of image\n",
    "    :param initial_iterations: min number of iterations completed\n",
    "    :param max_iterations: max allowable iteration\n",
    "    :param threshold: minimum number of remaining pixels acceptable\n",
    "    :return: binary image (unpadded)\n",
    "    \"\"\"\n",
    "    gray = cv.cvtColor(roi, cv.COLOR_BGR2GRAY)\n",
    "    blurred = cv.GaussianBlur(gray, (5, 5), 0)\n",
    "    ret, binary = cv.threshold(blurred, 200, 255, cv.THRESH_BINARY_INV)\n",
    "\n",
    "    # Padding to the image\n",
    "    pad_size = 2  # Choose a suitable padding size depending on the kernel size\n",
    "    binary = cv.copyMakeBorder(binary, pad_size, pad_size, pad_size, pad_size, cv.BORDER_CONSTANT, value=0)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(initial_iterations + max_iterations):\n",
    "        prev_binary = binary.copy()\n",
    "        binary = cv.erode(binary, kernel)\n",
    "\n",
    "        current_count = np.sum(binary == 255)\n",
    "        if current_count <= threshold:\n",
    "            binary = prev_binary  # Use the binary image from the previous iteration\n",
    "            break\n",
    "\n",
    "    return binary[pad_size:-pad_size, pad_size:-pad_size]  # Return the image without the added padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "056868cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_direction(x_count, y_count):\n",
    "    \"\"\"\n",
    "    Counts pixels in x and y directions, decides direction of arrow\n",
    "    :param x_count: number of remained pixels after erosion in x direction\n",
    "    :param y_count: number of remained pixels after erosion in y direction\n",
    "    :return: direction\n",
    "    \"\"\"\n",
    "    # Find max values and their indices for x_count and y_count\n",
    "    max_x, idx_x = max((val, idx) for (idx, val) in enumerate(x_count))\n",
    "    max_y, idx_y = max((val, idx) for (idx, val) in enumerate(y_count))\n",
    "\n",
    "    # Determine if the arrow points horizontally or vertically\n",
    "    if max_x >= max_y:\n",
    "        if idx_x < len(x_count) / 2:\n",
    "            return \"left\"\n",
    "        else:\n",
    "            return \"right\"\n",
    "    else:\n",
    "        if idx_y < len(y_count) / 2:\n",
    "            return \"upward\"\n",
    "        else:\n",
    "            return \"downward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "80be14b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "def dl_direction(dl_boxes, img, initial_iterations=1, max_iterations=10, threshold=1):\n",
    "    \"\"\"\n",
    "    Main function of deciding direction of disributed load\n",
    "    :param dl_boxes: bboxes obtained from object detection\n",
    "    :param img: current image\n",
    "    :param initial_iterations: min number of iterations required before deciding direction\n",
    "    :param max_iterations: number of max allowable iterations\n",
    "    :param threshold: min number of remaining pixels, below this threshold value iteration stops\n",
    "    :return: list containing information of dl instances (in this function direction attribute assigned)\n",
    "    \"\"\"\n",
    "    dl_with_direction = []\n",
    "\n",
    "    for dl in dl_boxes:\n",
    "        sensitivity = 5\n",
    "        y1, x1, y2, x2 = dl[:4]\n",
    "        roi = img[y1 + sensitivity:y2 - sensitivity, x1 + sensitivity:x2 - sensitivity]\n",
    "\n",
    "        eroded_img = iterative_erosion_dl(roi, initial_iterations, max_iterations, threshold)\n",
    "\n",
    "        x_count = np.sum(eroded_img == 255, axis=0)\n",
    "        y_count = np.sum(eroded_img == 255, axis=1)\n",
    "\n",
    "        if np.max(x_count) >= np.max(y_count):\n",
    "            direction = \"horizontal\"\n",
    "            dl.append(direction)\n",
    "            pointing_direction = determine_direction(x_count, y_count)\n",
    "            dl.append(pointing_direction)\n",
    "        else:\n",
    "            direction = \"vertical\"\n",
    "            dl.append(direction)\n",
    "            pointing_direction = determine_direction(x_count, y_count)\n",
    "            dl.append(pointing_direction)\n",
    "\n",
    "        dl_with_direction.append(dl)\n",
    "\n",
    "    return dl_with_direction\n",
    "dl_with_direction = dl_direction(dl_boxes, img, initial_iterations=1, max_iterations=10, threshold=1)\n",
    "print(dl_with_direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c81fdbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "def assign_nodes_dl(dl_with_direction, node_instances):\n",
    "    \"\"\"\n",
    "    Assigns the closest nodes both ends of distributed load\n",
    "    :param dl_with_direction: dl instances with directions decided\n",
    "    :param node_instances: list keeping node instances\n",
    "    :return: node attributed assigned distributed load instances\n",
    "    \"\"\"\n",
    "    distributed_load_instances = []\n",
    "    for box in dl_with_direction:\n",
    "        if box[5] == \"horizontal\":\n",
    "\n",
    "            y1 = box[0]\n",
    "            y2 = box[2]\n",
    "            x = int((box[1] + box[3]) / 2)\n",
    "            # Get the closest node to x1 and x2\n",
    "            c_node1 = find_closest_node(x, y1, node_instances)\n",
    "            c_node2 = find_closest_node(x, y2, node_instances)\n",
    "\n",
    "            dl_instance = DistributedLoad(node1=c_node1, node2=c_node2, obj_det_bbox=box[:4], direction=box[6])\n",
    "            distributed_load_instances.append(dl_instance)\n",
    "        elif box[5] == \"vertical\":\n",
    "            x1 = box[1]\n",
    "            x2 = box[3]\n",
    "            y = int((box[0] + box[2]) / 2)\n",
    "\n",
    "            # Get the closest node to x1 and x2\n",
    "            c_node1 = find_closest_node(x1, y, node_instances)\n",
    "            c_node2 = find_closest_node(x2, y, node_instances)\n",
    "\n",
    "            dl_instance = DistributedLoad(node1=c_node1, node2=c_node2, obj_det_bbox=box[:4], direction=box[6])\n",
    "            distributed_load_instances.append(dl_instance)\n",
    "        else:\n",
    "            # Need to fill this later\n",
    "            pass\n",
    "    return distributed_load_instances\n",
    "distributed_load_instances = assign_nodes_dl(dl_with_direction, node_instances)\n",
    "print(distributed_load_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e3075b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_precise_text_dl(dl_instances, ocr_text):\n",
    "    \"\"\"\n",
    "    Decides proper text belongs to the distributed load\n",
    "    :param dl_instances: list keeping instances of distributed load\n",
    "    :param ocr_text: list keeping ocr reading result text\n",
    "    :return: instances with related attributes assigned\n",
    "    \"\"\"\n",
    "    pattern = r\"(?i)(?P<value>\\d+(\\.\\d+)?)\\s*(?P<unit>kN/m|N/m|k/ft)\"\n",
    "    for dl in dl_instances:\n",
    "        bbox = dl.obj_det_bbox  # Using the obj_det_bbox attribute\n",
    "\n",
    "        text = find_closest_text_dl(ocr_text, bbox)\n",
    "\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            dl.value = float(match.group(\"value\"))  # Convert to float instead of int\n",
    "            dl.unit = match.group(\"unit\")\n",
    "    return dl_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "245671b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[82, 70, 155, 307, 'triangular_distributed_load']]\n"
     ]
    }
   ],
   "source": [
    "tdl_boxes = [box for box in applicable_list if box[-1] == 'triangular_distributed_load']\n",
    "print(tdl_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "39793581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[82, 70, 155, 307, 'triangular_distributed_load', 'vertical', 'downward']]\n"
     ]
    }
   ],
   "source": [
    "tdl_with_direction = dl_direction(tdl_boxes, img, initial_iterations=1, max_iterations=10, threshold=1)\n",
    "print(tdl_with_direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "104342c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_nodes_tdl(tdl_with_direction, node_instances):\n",
    "    \"\"\"\n",
    "    Assigns the closest nodes both ends of distributed load\n",
    "    :param dl_with_direction: dl instances with directions decided\n",
    "    :param node_instances: list keeping node instances\n",
    "    :return: node attributed assigned distributed load instances\n",
    "    \"\"\"\n",
    "    t_distributed_load_instances = []\n",
    "    for box in tdl_with_direction:\n",
    "        if box[5] == \"horizontal\":\n",
    "\n",
    "            y1 = box[0]\n",
    "            y2 = box[2]\n",
    "            x = int((box[1] + box[3]) / 2)\n",
    "            # Get the closest node to x1 and x2\n",
    "            c_node1 = find_closest_node(x, y1, node_instances)\n",
    "            c_node2 = find_closest_node(x, y2, node_instances)\n",
    "\n",
    "            tdl_instance = TriangularDistributedLoad(node1=c_node1, node2=c_node2, obj_det_bbox=box[:4], direction=box[6])\n",
    "            t_distributed_load_instances.append(tdl_instance)\n",
    "        elif box[5] == \"vertical\":\n",
    "            x1 = box[1]\n",
    "            x2 = box[3]\n",
    "            y = int((box[0] + box[2]) / 2)\n",
    "\n",
    "            # Get the closest node to x1 and x2\n",
    "            c_node1 = find_closest_node(x1, y, node_instances)\n",
    "            c_node2 = find_closest_node(x2, y, node_instances)\n",
    "\n",
    "            tdl_instance = TriangularDistributedLoad(node1=c_node1, node2=c_node2, obj_det_bbox=box[:4], direction=box[6])\n",
    "            t_distributed_load_instances.append(tdl_instance)\n",
    "        else:\n",
    "            # Need to fill this later\n",
    "            pass\n",
    "    return t_distributed_load_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "39fd2cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TriangularDistributedLoad(node1=Node(name=A, bbox_x=88, bbox_y=254, shape_x=0, shape_y=0), node2=Node(name=D, bbox_x=315, bbox_y=253.5, shape_x=3.0, shape_y=0), obj_det_bbox=[82, 70, 155, 307], direction=downward, value1=None, value2=None, unit=None)]\n"
     ]
    }
   ],
   "source": [
    "t_distributed_load_instances = assign_nodes_tdl(tdl_with_direction, node_instances)\n",
    "print(t_distributed_load_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "71d55a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_text_tdl(ocr_list, bbox):\n",
    "    pattern = re.compile(r\"(?i)(?P<value>\\d+(\\.\\d+)?)\\s*(?P<unit>kN/m|N/m|k/ft)\")\n",
    "    center_x, center_y = bbox\n",
    "    threshold = 150\n",
    "\n",
    "    sorted_ocr_list = sorted(\n",
    "        ocr_list,\n",
    "        key=lambda entry: (\n",
    "                                  center_x - (entry[1][0] + entry[1][2] + entry[1][4] + entry[1][6]) / 4) ** 2 +\n",
    "                          (center_y - (entry[1][1] + entry[1][3] + entry[1][5] + entry[1][7]) / 4) ** 2\n",
    "    )\n",
    "\n",
    "    for entry in sorted_ocr_list:\n",
    "        text_distance = (\n",
    "                                (center_x - (entry[1][0] + entry[1][2] + entry[1][4] + entry[1][6]) / 4) ** 2 +\n",
    "                                (center_y - (entry[1][1] + entry[1][3] + entry[1][5] + entry[1][7]) / 4) ** 2\n",
    "                        ) ** 0.5\n",
    "\n",
    "        if text_distance > threshold:\n",
    "            continue\n",
    "\n",
    "        text = entry[0]\n",
    "        match = pattern.match(text)\n",
    "        if match:\n",
    "            return match\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "73630837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_precise_text_tdl(tdl_instances, dl_instances, ocr_text):\n",
    "    for tdl in tdl_instances:\n",
    "        bbox1 = [tdl.node1.bbox_x, tdl.node1.bbox_y]\n",
    "        match1 = find_closest_text_tdl(ocr_text, bbox1)\n",
    "        if match1:\n",
    "            tdl.value1 = float(match1.group(\"value\"))\n",
    "            tdl.unit = match1.group(\"unit\")\n",
    "        bbox2 = [tdl.node2.bbox_x, tdl.node2.bbox_y]\n",
    "        match2 = find_closest_text_tdl(ocr_text, bbox2)\n",
    "        if match2:\n",
    "            tdl.value2 = float(match2.group(\"value\"))\n",
    "            tdl.unit = match2.group(\"unit\")\n",
    "    return tdl_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4c778546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TriangularDistributedLoad(node1=Node(name=A, bbox_x=88, bbox_y=254, shape_x=0, shape_y=0), node2=Node(name=D, bbox_x=315, bbox_y=253.5, shape_x=3.0, shape_y=0), obj_det_bbox=[82, 70, 155, 307], direction=downward, value1=None, value2=None, unit=None)]\n"
     ]
    }
   ],
   "source": [
    "t_distributed_load_instances = extract_precise_text_tdl(t_distributed_load_instances,distributed_load_instances, ocr_results)\n",
    "print(t_distributed_load_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc9ef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_nodes_dl(dl_with_direction, node_instances):\n",
    "    \"\"\"\n",
    "    Assigns the closest nodes both ends of distributed load\n",
    "    :param dl_with_direction: dl instances with directions decided\n",
    "    :param node_instances: list keeping node instances\n",
    "    :return: node attributed assigned distributed load instances\n",
    "    \"\"\"\n",
    "    distributed_load_instances = []\n",
    "    for box in dl_with_direction:\n",
    "        if box[5] == \"horizontal\":\n",
    "\n",
    "            y1 = box[0]\n",
    "            y2 = box[2]\n",
    "            x = int((box[1] + box[3]) / 2)\n",
    "            # Get the closest node to x1 and x2\n",
    "            c_node1 = find_closest_node(x, y1, node_instances)\n",
    "            c_node2 = find_closest_node(x, y2, node_instances)\n",
    "\n",
    "            dl_instance = DistributedLoad(node1=c_node1, node2=c_node2, obj_det_bbox=box[:4], direction=box[6])\n",
    "            distributed_load_instances.append(dl_instance)\n",
    "        elif box[5] == \"vertical\":\n",
    "            x1 = box[1]\n",
    "            x2 = box[3]\n",
    "            y = int((box[0] + box[2]) / 2)\n",
    "\n",
    "            # Get the closest node to x1 and x2\n",
    "            c_node1 = find_closest_node(x1, y, node_instances)\n",
    "            c_node2 = find_closest_node(x2, y, node_instances)\n",
    "\n",
    "            dl_instance = DistributedLoad(node1=c_node1, node2=c_node2, obj_det_bbox=box[:4], direction=box[6])\n",
    "            distributed_load_instances.append(dl_instance)\n",
    "        else:\n",
    "            # Need to fill this later\n",
    "            pass\n",
    "    return distributed_load_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d16d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_direction(x_count, y_count):\n",
    "    \"\"\"\n",
    "    Counts pixels in x and y directions, decides direction of arrow\n",
    "    :param x_count: number of remained pixels after erosion in x direction\n",
    "    :param y_count: number of remained pixels after erosion in y direction\n",
    "    :return: direction\n",
    "    \"\"\"\n",
    "    # Find max values and their indices for x_count and y_count\n",
    "    max_x, idx_x = max((val, idx) for (idx, val) in enumerate(x_count))\n",
    "    max_y, idx_y = max((val, idx) for (idx, val) in enumerate(y_count))\n",
    "\n",
    "    # Determine if the arrow points horizontally or vertically\n",
    "    if max_x >= max_y:\n",
    "        if idx_x < len(x_count) / 2:\n",
    "            return \"left\"\n",
    "        else:\n",
    "            return \"right\"\n",
    "    else:\n",
    "        if idx_y < len(y_count) / 2:\n",
    "            return \"upward\"\n",
    "        else:\n",
    "            return \"downward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef56498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_direction(dl_boxes, img, initial_iterations=1, max_iterations=10, threshold=1):\n",
    "    \"\"\"\n",
    "    Main function of deciding direction of disributed load\n",
    "    :param dl_boxes: bboxes obtained from object detection\n",
    "    :param img: current image\n",
    "    :param initial_iterations: min number of iterations required before deciding direction\n",
    "    :param max_iterations: number of max allowable iterations\n",
    "    :param threshold: min number of remaining pixels, below this threshold value iteration stops\n",
    "    :return: list containing information of dl instances (in this function direction attribute assigned)\n",
    "    \"\"\"\n",
    "    dl_with_direction = []\n",
    "\n",
    "    for dl in dl_boxes:\n",
    "        sensitivity = 5\n",
    "        y1, x1, y2, x2 = dl[:4]\n",
    "        roi = img[y1 + sensitivity:y2 - sensitivity, x1 + sensitivity:x2 - sensitivity]\n",
    "        \n",
    "        eroded_img = iterative_erosion_dl(roi, initial_iterations, max_iterations, threshold)\n",
    "        \n",
    "        x_count = np.sum(eroded_img == 255, axis=0)\n",
    "        y_count = np.sum(eroded_img == 255, axis=1)\n",
    "\n",
    "        if np.max(x_count) >= np.max(y_count):\n",
    "            direction = \"horizontal\"\n",
    "            dl.append(direction)\n",
    "            pointing_direction = determine_direction(x_count, y_count)\n",
    "            dl.append(pointing_direction)\n",
    "        else:\n",
    "            direction = \"vertical\"\n",
    "            dl.append(direction)\n",
    "            pointing_direction = determine_direction(x_count, y_count)\n",
    "            dl.append(pointing_direction)\n",
    "\n",
    "        dl_with_direction.append(dl)\n",
    "\n",
    "    return dl_with_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1490971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_nodes_tdl(tdl_with_direction, node_instances):\n",
    "    \"\"\"\n",
    "    Assigns the closest nodes both ends of distributed load\n",
    "    :param dl_with_direction: dl instances with directions decided\n",
    "    :param node_instances: list keeping node instances\n",
    "    :return: node attributed assigned distributed load instances\n",
    "    \"\"\"\n",
    "    t_distributed_load_instances = []\n",
    "    for box in tdl_with_direction:\n",
    "        if box[5] == \"horizontal\":\n",
    "\n",
    "            y1 = box[0]\n",
    "            y2 = box[2]\n",
    "            x = int((box[1] + box[3]) / 2)\n",
    "            # Get the closest node to x1 and x2\n",
    "            c_node1 = find_closest_node(x, y1, node_instances)\n",
    "            c_node2 = find_closest_node(x, y2, node_instances)\n",
    "\n",
    "            tdl_instance = TriangularDistributedLoad(node1=c_node1, node2=c_node2, obj_det_bbox=box[:4], direction=box[6])\n",
    "            t_distributed_load_instances.append(tdl_instance)\n",
    "        elif box[5] == \"vertical\":\n",
    "            x1 = box[1]\n",
    "            x2 = box[3]\n",
    "            y = int((box[0] + box[2]) / 2)\n",
    "\n",
    "            # Get the closest node to x1 and x2\n",
    "            c_node1 = find_closest_node(x1, y, node_instances)\n",
    "            c_node2 = find_closest_node(x2, y, node_instances)\n",
    "\n",
    "            tdl_instance = TriangularDistributedLoad(node1=c_node1, node2=c_node2, obj_det_bbox=box[:4], direction=box[6])\n",
    "            t_distributed_load_instances.append(tdl_instance)\n",
    "        else:\n",
    "            # Need to fill this later\n",
    "            pass\n",
    "    return t_distributed_load_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65688cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_text_tdl(ocr_list, bbox):\n",
    "    pattern = re.compile(r\"(?i)(?P<value>\\d+(\\.\\d+)?)\\s*(?P<unit>kN/m|N/m|k/ft)\")\n",
    "    center_x, center_y = bbox\n",
    "    threshold = 150\n",
    "\n",
    "    sorted_ocr_list = sorted(\n",
    "        ocr_list,\n",
    "        key=lambda entry: (\n",
    "                                  center_x - (entry[1][0] + entry[1][2] + entry[1][4] + entry[1][6]) / 4) ** 2 +\n",
    "                          (center_y - (entry[1][1] + entry[1][3] + entry[1][5] + entry[1][7]) / 4) ** 2\n",
    "    )\n",
    "\n",
    "    for entry in sorted_ocr_list:\n",
    "        text_distance = (\n",
    "                                (center_x - (entry[1][0] + entry[1][2] + entry[1][4] + entry[1][6]) / 4) ** 2 +\n",
    "                                (center_y - (entry[1][1] + entry[1][3] + entry[1][5] + entry[1][7]) / 4) ** 2\n",
    "                        ) ** 0.5\n",
    "\n",
    "        if text_distance > threshold:\n",
    "            continue\n",
    "\n",
    "        text = entry[0]\n",
    "        match = pattern.match(text)\n",
    "        if match:\n",
    "            return match\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222c94e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_precise_text_tdl(tdl_instances, dl_instances, ocr_text):\n",
    "    for tdl in tdl_instances:\n",
    "        bbox1 = [tdl.node1.bbox_x, tdl.node1.bbox_y]\n",
    "        match1 = find_closest_text_tdl(ocr_text, bbox1)\n",
    "        if match1:\n",
    "            tdl.value1 = float(match1.group(\"value\"))\n",
    "            tdl.unit = match1.group(\"unit\")\n",
    "        bbox2 = [tdl.node2.bbox_x, tdl.node2.bbox_y]\n",
    "        match2 = find_closest_text_tdl(ocr_text, bbox2)\n",
    "        if match2:\n",
    "            tdl.value2 = float(match2.group(\"value\"))\n",
    "            tdl.unit = match2.group(\"unit\")\n",
    "    return tdl_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bef6333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d5facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def object_detection(image, path_of_image, incoming_filename):\n",
    "    \"\"\"\n",
    "    Main part of the software\n",
    "    :param image: input image obtained from telegram chat\n",
    "    :param path_of_image: image is saved after taken from group, this variable keeps that saving path\n",
    "    :param incoming_filename: filename created according to a pattern (user_name + datetime info)\n",
    "    :return: returns solution (for now it is an image, later it will be a pdf file)\n",
    "    \"\"\"\n",
    "\n",
    "#     user_path = os.path.expanduser(\"~\")\n",
    "#     training_demo_path = os.path.join(user_path, \"Desktop\", \"cekcoz_v3\", \"workspace\", \"training_demo\")\n",
    "#     config_path = os.path.join(training_demo_path, \"models\", \"cekcoz_resnet\", \"pipeline.config\")\n",
    "#     configs = config_util.get_configs_from_pipeline_file(config_path)\n",
    "#     model_config = configs[\"model\"]\n",
    "#     detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "#     ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "#     checkpoint_path = os.path.join(training_demo_path, \"models\", \"cekcoz_resnet\")\n",
    "#     ckpt.restore(os.path.join(checkpoint_path, 'ckpt-98')).expect_partial()\n",
    "\n",
    "\n",
    "#     label_path = os.path.join(training_demo_path, \"annotations\", \"label_map.pbtxt\")\n",
    "#     category_index = label_map_util.create_category_index_from_labelmap(label_path,use_display_name=True)\n",
    "\n",
    "#     image_np = np.array(image)\n",
    "#     img_height, img_width = image_np.shape[0], image_np.shape[1]\n",
    "\n",
    "#     input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "\n",
    "#     detections = detect_fn(input_tensor, detection_model)\n",
    "\n",
    "#     num_detections = int(detections.pop('num_detections'))\n",
    "#     detections = {key: value[0, :num_detections].numpy()\n",
    "#                   for key, value in detections.items()}\n",
    "#     detections['num_detections'] = num_detections\n",
    "#     label_id_offset = 1\n",
    "\n",
    "#     # detection_classes should be ints.\n",
    "#     detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "\n",
    "# #     ----------For testing object detection results, code below could be used---------------\n",
    "#     show_object_detection_results(image_np, detections, category_index)\n",
    "\n",
    "#     # Packs all complex data into usable data with some format\n",
    "#     aggregated_list = list(map(process_data, detections['detection_boxes'],\n",
    "#                                detections['detection_classes'],detections['detection_scores']))\n",
    "\n",
    "\n",
    "#     # Detections which has confidence score less than threshold value described below will be discarded\n",
    "#     score_threshold = 0.5\n",
    "\n",
    "\n",
    "#     # After discarding ambiguous detections, rest will be accumulated in the list below\n",
    "#     applicable_list = remove_ambiguous_detections(score_threshold, aggregated_list, category_index,\n",
    "#                                                                    img_width, img_height)\n",
    "#     print(\"Applicable List = \", applicable_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    applicable_list = [[186, 535, 227, 566, 'roller_support'], [247, 312, 269, 553, 'spacing'], [169, 67, 224, 104, 'pin_support'], [238, 199, 269, 315, 'spacing'], [240, 88, 269, 204, 'spacing'], [6, 288, 150, 346, 'point_load'], [153, 65, 190, 567, 'frame'], [82, 70, 155, 307, 'triangular_distributed_load']]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    error_statement = \"\"\"Gnderilen resim zm iin uygun deildir, muhtemelen sebepler:\n",
    "    - letilen resim bu ders ile alakal deil\n",
    "    - letilen resmin kalitesi sistemin tanyamayaca kadar kt\n",
    "    - letilen resimde izimin stnde bulunan bilgiler zm iin yeterli deil\n",
    "    - letilen resimde zm iin gereken bilgiler yaz iinde aklanm\"\"\"\n",
    "    if len(applicable_list) < 3:\n",
    "        return error_statement\n",
    "    \n",
    "    \n",
    "    \n",
    "#     reading_results = read_text_on_image(path_of_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    reading_results = [['5 kN', [290.0, 11.0, 346.0, 10.0, 346.0, 32.0, 289.0, 32.0]], ['3 kN/m', [41.0, 60.0, 129.0, 60.0, 129.0, 85.0, 41.0, 85.0]], ['A', [42.0, 169.0, 64.0, 171.0, 63.0, 192.0, 42.0, 191.0]], ['B', [558.0, 171.0, 577.0, 169.0, 577.0, 192.0, 558.0, 193.0]], ['C', [219.0, 203.0, 241.0, 204.0, 239.0, 226.0, 219.0, 225.0]], ['D', [338.0, 203.0, 360.0, 203.0, 360.0, 227.0, 337.0, 227.0]], ['- 1.5 m --- 1.5 m', [83.0, 243.0, 291.0, 243.0, 291.0, 268.0, 83.0, 268.0]], ['3 m', [412.0, 245.0, 456.0, 244.0, 456.0, 265.0, 411.0, 266.0]]]\n",
    "    \n",
    "    ocr_converted_bbox = convert_ocrbbox_to_objdet_bbox(reading_results)\n",
    "\n",
    "    match_objdet_ocr(applicable_list, ocr_converted_bbox)\n",
    "    \n",
    "    \n",
    "#     print(\"Reading results =\", reading_results)\n",
    "#     if not reading_results:\n",
    "#         return error_statement\n",
    "#     ocr_results = clean_ocr_results(reading_results)\n",
    "#     spacing_bbox = [item[:4] for item in applicable_list if item[4] == 'spacing']\n",
    "#     if not spacing_bbox:\n",
    "#         return error_statement\n",
    "#     spacing_matching_results = match_spacings(spacing_bbox, ocr_results)\n",
    "#     spacing_sec_filtered_results = ocr_secondary_filter_distance(spacing_matching_results)\n",
    "#     spacing_extracted_results = extract_value_unit(spacing_sec_filtered_results)\n",
    "#     sorted_spacings = sorted(spacing_extracted_results, key=sorting_key)\n",
    "#     sorted_spacings_with_directions = dimension_direction(sorted_spacings, image)\n",
    "#     spacing_instances, node_instances = initialize_parameters(sorted_spacings_with_directions)\n",
    "#     if not node_instances or not spacing_instances:\n",
    "#         return error_statement\n",
    "    \n",
    "#     node_instances = correct_shapes(node_instances)\n",
    "#     node_instances = find_and_append_missing_nodes(node_instances)\n",
    "#     append_names_to_nodes(node_instances, ocr_results, distance_threshold=100)\n",
    "#     print(\"Node instances = \", node_instances)\n",
    "#     print(\"Spacing instances = \", spacing_instances)\n",
    "    \n",
    "#     support_bbox = [box for box in applicable_list if 'support' in box[-1]]\n",
    "#     fix_support_instances, pin_support_instances, roller_support_instances = create_support_instances(support_bbox, node_instances)\n",
    "#     print(\"fix supports = \", fix_support_instances)\n",
    "#     print(\"pin supports = \", pin_support_instances)\n",
    "#     print(\"roller supports = \", roller_support_instances)\n",
    "    \n",
    "#     frame_boxes = [box for box in applicable_list if box[-1] == 'frame']\n",
    "#     frame_boxes = find_frame_direction(frame_boxes, image)\n",
    "#     frame_instances = initialize_frames(frame_boxes, node_instances)\n",
    "#     print(\"Frame instances = \", frame_instances)\n",
    "    \n",
    "#     new_frame_instances = split_frame_based_on_nodes(frame_instances, node_instances)\n",
    "#     print(\"New frame instances = \", new_frame_instances)\n",
    "#     if not new_frame_instances:\n",
    "#         new_frame_instances = create_nominal_frame(node_instances)\n",
    "    \n",
    "#     pl_boxes = [box for box in applicable_list if box[-1] == 'point_load']\n",
    "#     point_load_instances = initialize_pl(pl_boxes, node_instances)\n",
    "#     possible_pl_text = extract_pl_text(pl_boxes, ocr_results)\n",
    "#     point_load_instances = extract_precise_text(point_load_instances, possible_pl_text)\n",
    "#     if point_load_instances:\n",
    "#         pl_direction(point_load_instances, image)\n",
    "#     print(\"Point load instances = \", point_load_instances)\n",
    "    \n",
    "#     sorted_nodes = sorted(node_instances, key=lambda node: (node.shape_y, node.shape_x))\n",
    "    \n",
    "#     dl_boxes = [box for box in applicable_list if box[-1] == 'distributed_load']\n",
    "#     dl_with_direction = dl_direction(dl_boxes, image, initial_iterations=1, max_iterations=10, threshold=1)\n",
    "#     distributed_load_instances = assign_nodes_dl(dl_with_direction, node_instances)\n",
    "#     distributed_load_instances = extract_precise_text_dl(distributed_load_instances, ocr_results)\n",
    "    \n",
    "#     print(\"Distributed load instances = \", distributed_load_instances)\n",
    "    \n",
    "#     tdl_boxes = [box for box in applicable_list if box[-1] == 'triangular_distributed_load']\n",
    "#     tdl_with_direction = dl_direction(tdl_boxes, image, initial_iterations=1, max_iterations=10, threshold=1)\n",
    "#     print(\"tdl direction\", tdl_with_direction)\n",
    "#     t_distributed_load_instances = assign_nodes_tdl(tdl_with_direction, node_instances)\n",
    "#     print(\"T dist instances\", t_distributed_load_instances)\n",
    "#     t_distributed_load_instances = extract_precise_text_tdl(t_distributed_load_instances, distributed_load_instances, ocr_results)\n",
    "#     print(\"T dist\", t_distributed_load_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb041af",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_detection(img, file_path, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aec21a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead0257a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
