{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ad1ebfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\METE\\Desktop\\cekcoz_v3\\workspace\\training_demo\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)\n",
    "\n",
    "# Enable GPU dynamic memory allocation\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "main_path=os.getcwd()\n",
    "print(main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d90e250b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\METE\\Desktop\\single_image_trial\\deneme_1.png\n"
     ]
    }
   ],
   "source": [
    "image_path = []\n",
    "for image_name in os.listdir(\"C:\\\\Users\\\\METE\\\\Desktop\\\\single_image_trial\"):\n",
    "    image_path.append(os.path.join(\"C:\\\\Users\\\\METE\\\\Desktop\\\\single_image_trial\", image_name))\n",
    "image_path = image_path[0]\n",
    "print(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d145a6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_fn(image, detection_model):\n",
    "    \"\"\"Detect objects in image.\"\"\"\n",
    "\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "845d14e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import label_map_util\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "image_np = np.array(Image.open(image_path))\n",
    "\n",
    "user_path = os.path.expanduser(\"~\")\n",
    "training_demo_path = os.path.join(user_path, \"Desktop\", \"cekcoz_v3\", \"workspace\", \"training_demo\")\n",
    "config_path = os.path.join(training_demo_path, \"models\", \"cekcoz_resnet\", \"pipeline.config\")\n",
    "configs = config_util.get_configs_from_pipeline_file(config_path)\n",
    "model_config = configs[\"model\"]\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "checkpoint_path = os.path.join(training_demo_path, \"models\", \"cekcoz_resnet\")\n",
    "ckpt.restore(os.path.join(checkpoint_path, 'ckpt-98')).expect_partial()\n",
    "\n",
    "\n",
    "label_path = os.path.join(training_demo_path, \"annotations\", \"label_map.pbtxt\")\n",
    "category_index = label_map_util.create_category_index_from_labelmap(label_path,use_display_name=True)\n",
    "\n",
    "\n",
    "img_height, img_width = image_np.shape[0], image_np.shape[1]\n",
    "\n",
    "# cv.imshow(\"image\",image)\n",
    "# cv.waitKey()\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "\n",
    "detections = detect_fn(input_tensor, detection_model)\n",
    "\n",
    "# All outputs are batches tensors.\n",
    "# Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "# We're only interested in the first num_detections.\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "    image_np_with_detections,\n",
    "    detections['detection_boxes'],\n",
    "    detections['detection_classes'] + label_id_offset,\n",
    "    detections['detection_scores'],\n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    max_boxes_to_draw=200,\n",
    "    min_score_thresh=0.3,\n",
    "    agnostic_mode=False)\n",
    "plt.imshow(image_np_with_detections)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef6a21d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102, 284, 132, 317, 'roller_support'], [22, 99, 102, 116, 'point_load'], [136, 303, 167, 369, 'spacing'], [24, 362, 101, 377, 'point_load'], [22, 230, 102, 246, 'point_load'], [137, 237, 168, 305, 'spacing'], [97, 34, 111, 49, 'pin_support'], [138, 106, 170, 236, 'spacing'], [139, 43, 170, 109, 'spacing']]\n"
     ]
    }
   ],
   "source": [
    "def process_data(box, detection_class, score):\n",
    "    return list([box[0], box[1], box[2], box[3], detection_class + label_id_offset, score])\n",
    "\n",
    "aggregated_list = list(map(process_data, detections['detection_boxes'], detections['detection_classes'],\n",
    "                      detections['detection_scores']))\n",
    "\n",
    "score_threshold = 0.5\n",
    "applicable_list = []\n",
    "for whole_values in aggregated_list:\n",
    "    dummy_list = []\n",
    "    if whole_values[5] > score_threshold:\n",
    "        label_name = (category_index.get(int(whole_values[4]))).get(\"name\")\n",
    "        ymin = int(whole_values[0] * img_height)\n",
    "        xmin = int(whole_values[1] * img_width)\n",
    "        ymax = int(whole_values[2] * img_height)\n",
    "        xmax = int(whole_values[3] * img_width)\n",
    "        dummy_list.append(ymin)\n",
    "        dummy_list.append(xmin)\n",
    "        dummy_list.append(ymax)\n",
    "        dummy_list.append(xmax)\n",
    "        dummy_list.append(label_name)\n",
    "        applicable_list.append(dummy_list)\n",
    "def area(bbox):\n",
    "    \"\"\"Calculate area of a bounding box.\"\"\"\n",
    "    ymin, xmin, ymax, xmax, _ = bbox\n",
    "    return (ymax - ymin) * (xmax - xmin)\n",
    "\n",
    "def overlap_area(bbox1, bbox2):\n",
    "    \"\"\"Calculate overlap area between two bounding boxes.\"\"\"\n",
    "    ymin1, xmin1, ymax1, xmax1 = bbox1[:4]\n",
    "    ymin2, xmin2, ymax2, xmax2 = bbox2[:4]\n",
    "\n",
    "    overlap_ymin = max(ymin1, ymin2)\n",
    "    overlap_xmin = max(xmin1, xmin2)\n",
    "    overlap_ymax = min(ymax1, ymax2)\n",
    "    overlap_xmax = min(xmax1, xmax2)\n",
    "\n",
    "    # Check if the boxes overlap at all\n",
    "    if overlap_xmin < overlap_xmax and overlap_ymin < overlap_ymax:\n",
    "        return area([overlap_ymin, overlap_xmin, overlap_ymax, overlap_xmax, ''])\n",
    "    return 0\n",
    "\n",
    "filtered_boxes = []\n",
    "for i in range(len(applicable_list)):\n",
    "    for j in range(i + 1, len(applicable_list)):\n",
    "        if applicable_list[i][4] == applicable_list[j][4]:  # If the labels are the same\n",
    "            overlap = overlap_area(applicable_list[i], applicable_list[j])\n",
    "            if overlap >= 0.7 * area(applicable_list[i]):  # If bbox j contains 70% or more of bbox i\n",
    "                break\n",
    "            elif overlap >= 0.7 * area(applicable_list[j]):  # If bbox i contains 70% or more of bbox j\n",
    "                continue\n",
    "    else:  # If the loop didn't break, add the box to the filtered list\n",
    "        filtered_boxes.append(applicable_list[i])\n",
    "\n",
    "print(filtered_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9495dce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for result...\n",
      "[['10 kN', [115.0, 25.0, 157.0, 24.0, 157.0, 38.0, 115.0, 38.0]], ['20 kN', [244.0, 23.0, 286.0, 22.0, 287.0, 36.0, 244.0, 37.0]], ['5 kN', [375.0, 22.0, 410.0, 22.0, 409.0, 35.0, 375.0, 35.0]], ['A', [22.0, 84.0, 33.0, 84.0, 34.0, 95.0, 23.0, 95.0]], ['B.', [86.0, 82.0, 102.0, 83.0, 103.0, 96.0, 86.0, 94.0]], ['C', [215.0, 81.0, 225.0, 81.0, 226.0, 94.0, 215.0, 94.0]], ['D', [297.0, 81.0, 307.0, 81.0, 307.0, 93.0, 297.0, 93.0]], ['E', [347.0, 79.0, 358.0, 80.0, 357.0, 93.0, 347.0, 92.0]], ['1 m', [61.0, 141.0, 88.0, 142.0, 88.0, 153.0, 61.0, 153.0]], ['2 m', [159.0, 139.0, 186.0, 140.0, 186.0, 153.0, 158.0, 152.0]], ['1 m', [257.0, 139.0, 284.0, 140.0, 284.0, 151.0, 256.0, 152.0]], ['1 m', [326.0, 139.0, 351.0, 139.0, 352.0, 152.0, 326.0, 151.0]], ['-', [308.0, 145.0, 308.0, 158.0, 300.0, 157.0, 300.0, 145.0]], ['-', [112.0, 146.0, 112.0, 158.0, 103.0, 158.0, 103.0, 146.0]], ['X', [245.0, 158.0, 237.0, 172.0, 225.0, 162.0, 233.0, 148.0]]]\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "def read_text_on_image(path):\n",
    "\n",
    "    subscription_key = \"d9db8bd3bed7440a86b510dca41abdc6\"\n",
    "    endpoint = \"https://cekcozocr.cognitiveservices.azure.com/\"\n",
    "\n",
    "    computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "\n",
    "\n",
    "    read_image_path = path\n",
    "    # Open the image\n",
    "    read_image = open(read_image_path, \"rb\")\n",
    "\n",
    "    # Call API with image and raw response (allows you to get the operation location)\n",
    "    read_response = computervision_client.read_in_stream(read_image, raw=True)\n",
    "    # Get the operation location (URL with ID as last appendage)\n",
    "    read_operation_location = read_response.headers[\"Operation-Location\"]\n",
    "    # Take the ID off and use to get results\n",
    "    operation_id = read_operation_location.split(\"/\")[-1]\n",
    "\n",
    "    # Call the \"GET\" API and wait for the retrieval of the results\n",
    "    while True:\n",
    "        read_result = computervision_client.get_read_result(operation_id)\n",
    "        if read_result.status.lower () not in ['notstarted', 'running']:\n",
    "            break\n",
    "        print ('Waiting for result...')\n",
    "        time.sleep(10)\n",
    "\n",
    "\n",
    "    reading_results = []\n",
    "    # Print results, line by line\n",
    "    if read_result.status == OperationStatusCodes.succeeded:\n",
    "        for text_result in read_result.analyze_result.read_results:\n",
    "            for line in text_result.lines:\n",
    "                dummy_list = []\n",
    "                dummy_list.append(line.text)\n",
    "                dummy_list.append(line.bounding_box)\n",
    "                # print(line.text)\n",
    "                # print(line.bounding_box)\n",
    "                reading_results.append(dummy_list)\n",
    "\n",
    "    return reading_results\n",
    "\n",
    "ocr_results = read_text_on_image(image_path)\n",
    "print(ocr_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19a8e3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacing (Dimension) and Node classes defined and data prepared below this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88a83648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute center of an object detection bounding box\n",
    "def compute_center_obj(bbox):\n",
    "    y1, x1, y2, x2 = bbox\n",
    "    center_x = (x1 + x2) / 2\n",
    "    center_y = (y1 + y2) / 2\n",
    "    return center_x, center_y\n",
    "\n",
    "# Function to compute center of an OCR bounding box\n",
    "def compute_center_ocr(bbox):\n",
    "    x1, y1, x2, y2, x3, y3, x4, y4 = bbox\n",
    "    center_x = (x1 + x3) / 2\n",
    "    center_y = (y1 + y3) / 2\n",
    "    return center_x, center_y\n",
    "\n",
    "# Function to compute Euclidean distance between two centers\n",
    "def euclidean_distance(center1, center2):\n",
    "    return ((center1[0] - center2[0])**2 + (center1[1] - center2[1])**2)**0.5\n",
    "\n",
    "# Function to compute distances between OCR results and object detection results\n",
    "# and keep results with distance < 100 pixels\n",
    "def filter_results_by_distance(obj_detection_bbox, ocr_results, threshold):\n",
    "    filtered_results = []\n",
    "    obj_center = compute_center_obj(obj_detection_bbox)\n",
    "    \n",
    "    for result in ocr_results:\n",
    "        _, ocr_bbox = result\n",
    "        ocr_center = compute_center_ocr(ocr_bbox)\n",
    "        distance = euclidean_distance(obj_center, ocr_center)\n",
    "        if distance < threshold:\n",
    "            filtered_results.append(result)\n",
    "        \n",
    "    return filtered_results\n",
    "\n",
    "def adjust_threshold(bbox):\n",
    "    if bbox[3]-bbox[1] > bbox[2]-bbox[0]:\n",
    "        return bbox[2]-bbox[0]+10\n",
    "    else:\n",
    "        return bbox[3]-bbox[1] + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb8b5c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[136, 303, 167, 369], [137, 237, 168, 305], [138, 106, 170, 236], [139, 43, 170, 109]]\n",
      "[[['1 m', [326.0, 139.0, 351.0, 139.0, 352.0, 152.0, 326.0, 151.0]], ['-', [308.0, 145.0, 308.0, 158.0, 300.0, 157.0, 300.0, 145.0]], [136, 303, 167, 369]], [['1 m', [257.0, 139.0, 284.0, 140.0, 284.0, 151.0, 256.0, 152.0]], ['-', [308.0, 145.0, 308.0, 158.0, 300.0, 157.0, 300.0, 145.0]], ['X', [245.0, 158.0, 237.0, 172.0, 225.0, 162.0, 233.0, 148.0]], [137, 237, 168, 305]], [['2 m', [159.0, 139.0, 186.0, 140.0, 186.0, 153.0, 158.0, 152.0]], [138, 106, 170, 236]], [['1 m', [61.0, 141.0, 88.0, 142.0, 88.0, 153.0, 61.0, 153.0]], ['-', [112.0, 146.0, 112.0, 158.0, 103.0, 158.0, 103.0, 146.0]], [139, 43, 170, 109]]]\n"
     ]
    }
   ],
   "source": [
    "def match_spacings(spacing_bbox, readings):\n",
    "    final_results = []\n",
    "    for bbox in spacing_bbox:\n",
    "        threshold = adjust_threshold(bbox)\n",
    "        filtered_ocr_results = filter_results_by_distance(bbox, readings, threshold)\n",
    "        filtered_ocr_results.append(bbox)\n",
    "        final_results.append(filtered_ocr_results)\n",
    "    return final_results\n",
    "spacing_bbox = [item[:4] for item in filtered_boxes if item[4] == 'spacing']\n",
    "spacing_matching_results = match_spacings(spacing_bbox, ocr_results)\n",
    "print(spacing_bbox)\n",
    "print(spacing_matching_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34fc737f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1 m', [326.0, 139.0, 351.0, 139.0, 352.0, 152.0, 326.0, 151.0]], ['-', [308.0, 145.0, 308.0, 158.0, 300.0, 157.0, 300.0, 145.0]], [136, 303, 167, 369]]\n",
      "[['1 m', [257.0, 139.0, 284.0, 140.0, 284.0, 151.0, 256.0, 152.0]], ['-', [308.0, 145.0, 308.0, 158.0, 300.0, 157.0, 300.0, 145.0]], ['X', [245.0, 158.0, 237.0, 172.0, 225.0, 162.0, 233.0, 148.0]], [137, 237, 168, 305]]\n",
      "[['2 m', [159.0, 139.0, 186.0, 140.0, 186.0, 153.0, 158.0, 152.0]], [138, 106, 170, 236]]\n",
      "[['1 m', [61.0, 141.0, 88.0, 142.0, 88.0, 153.0, 61.0, 153.0]], ['-', [112.0, 146.0, 112.0, 158.0, 103.0, 158.0, 103.0, 146.0]], [139, 43, 170, 109]]\n"
     ]
    }
   ],
   "source": [
    "for element in spacing_matching_results:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6d04df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['1 m', [326.0, 139.0, 351.0, 139.0, 352.0, 152.0, 326.0, 151.0]], ['-', [308.0, 145.0, 308.0, 158.0, 300.0, 157.0, 300.0, 145.0]], [136, 303, 167, 369]], [['1 m', [257.0, 139.0, 284.0, 140.0, 284.0, 151.0, 256.0, 152.0]], ['-', [308.0, 145.0, 308.0, 158.0, 300.0, 157.0, 300.0, 145.0]], ['X', [245.0, 158.0, 237.0, 172.0, 225.0, 162.0, 233.0, 148.0]], [137, 237, 168, 305]], [['2 m', [159.0, 139.0, 186.0, 140.0, 186.0, 153.0, 158.0, 152.0]], [138, 106, 170, 236]], [['1 m', [61.0, 141.0, 88.0, 142.0, 88.0, 153.0, 61.0, 153.0]], ['-', [112.0, 146.0, 112.0, 158.0, 103.0, 158.0, 103.0, 146.0]], [139, 43, 170, 109]]]\n"
     ]
    }
   ],
   "source": [
    "spacing_matching_results = [item for item in spacing_matching_results if isinstance(item[0][0], str)]\n",
    "print(spacing_matching_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd0b727f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['1 m', [326.0, 139.0, 351.0, 139.0, 352.0, 152.0, 326.0, 151.0]], ['-', [308.0, 145.0, 308.0, 158.0, 300.0, 157.0, 300.0, 145.0]], [136, 303, 167, 369]], [['1 m', [257.0, 139.0, 284.0, 140.0, 284.0, 151.0, 256.0, 152.0]], ['-', [308.0, 145.0, 308.0, 158.0, 300.0, 157.0, 300.0, 145.0]], ['X', [245.0, 158.0, 237.0, 172.0, 225.0, 162.0, 233.0, 148.0]], [137, 237, 168, 305]], [['2 m', [159.0, 139.0, 186.0, 140.0, 186.0, 153.0, 158.0, 152.0]], [138, 106, 170, 236]], [['1 m', [61.0, 141.0, 88.0, 142.0, 88.0, 153.0, 61.0, 153.0]], ['-', [112.0, 146.0, 112.0, 158.0, 103.0, 158.0, 103.0, 146.0]], [139, 43, 170, 109]]]\n"
     ]
    }
   ],
   "source": [
    "# Removing absurd characters from spacing readings\n",
    "\n",
    "import re\n",
    "\n",
    "pattern = r\"(\\d+([.]\\d+)?|(\\d+\\s*/\\s*\\d+))\\s*(m|meters?)\"\n",
    "\n",
    "for item in spacing_matching_results:\n",
    "    reading = item[0][0]  # OCR reading is the second element in each item\n",
    "    match = re.search(pattern, reading)\n",
    "    if match:\n",
    "        extracted_value = match.group()\n",
    "        item[0][0] = extracted_value  # Update the original reading with the extracted value\n",
    "\n",
    "print(spacing_matching_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24bfaa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['1 m', [326.0, 139.0, 351.0, 139.0, 352.0, 152.0, 326.0, 151.0]], [136, 303, 167, 369]], [['1 m', [257.0, 139.0, 284.0, 140.0, 284.0, 151.0, 256.0, 152.0]], [137, 237, 168, 305]], [['2 m', [159.0, 139.0, 186.0, 140.0, 186.0, 153.0, 158.0, 152.0]], [138, 106, 170, 236]], [['1 m', [61.0, 141.0, 88.0, 142.0, 88.0, 153.0, 61.0, 153.0]], [139, 43, 170, 109]]]\n"
     ]
    }
   ],
   "source": [
    "filtered_results = []\n",
    "for group in spacing_matching_results:\n",
    "    filtered_group = [element for element in group if (isinstance(element[0], str) and re.match(pattern, element[0])) or isinstance(element[0], int)]\n",
    "    filtered_results.append(filtered_group)\n",
    "\n",
    "print(filtered_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b85492d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[['1', 'm'], [326.0, 139.0, 351.0, 139.0, 352.0, 152.0, 326.0, 151.0]], [136, 303, 167, 369]], [[['1', 'm'], [257.0, 139.0, 284.0, 140.0, 284.0, 151.0, 256.0, 152.0]], [137, 237, 168, 305]], [[['2', 'm'], [159.0, 139.0, 186.0, 140.0, 186.0, 153.0, 158.0, 152.0]], [138, 106, 170, 236]], [[['1', 'm'], [61.0, 141.0, 88.0, 142.0, 88.0, 153.0, 61.0, 153.0]], [139, 43, 170, 109]]]\n"
     ]
    }
   ],
   "source": [
    "def extract_value_unit(text):\n",
    "    # regex pattern to match value and unit (supports meter, m, feet, ft, inch)\n",
    "    match = re.match(r'(\\d+)\\s*(meters?|ft|feet|inch(?:es)?|m)', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        value, unit = match.groups()\n",
    "        return [value, unit]\n",
    "    return [text]\n",
    "\n",
    "reformatted_results = []\n",
    "for entry in filtered_results:\n",
    "    text_data, bbox_data = entry\n",
    "    text, coords = text_data\n",
    "    new_text_data = [extract_value_unit(text), coords]\n",
    "    reformatted_results.append([new_text_data, bbox_data])\n",
    "\n",
    "print(reformatted_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec73dcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[['1', 'm'], [326.0, 139.0, 351.0, 139.0, 352.0, 152.0, 326.0, 151.0]], [136, 303, 167, 369]], [[['1', 'm'], [257.0, 139.0, 284.0, 140.0, 284.0, 151.0, 256.0, 152.0]], [137, 237, 168, 305]], [[['2', 'm'], [159.0, 139.0, 186.0, 140.0, 186.0, 153.0, 158.0, 152.0]], [138, 106, 170, 236]], [[['1', 'm'], [61.0, 141.0, 88.0, 142.0, 88.0, 153.0, 61.0, 153.0]], [139, 43, 170, 109]]]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "horizontal_spacings = []\n",
    "vertical_spacings = []\n",
    "for element in reformatted_results:\n",
    "    y1,x1,y2,x2 = element[1]\n",
    "    if x2-x1 > y2-y1:\n",
    "        horizontal_spacings.append(element)\n",
    "    else:\n",
    "        vertical_spacings.appende(element)\n",
    "print(horizontal_spacings)\n",
    "print(vertical_spacings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0ea1de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[['1', 'm'], [61.0, 141.0, 88.0, 142.0, 88.0, 153.0, 61.0, 153.0]], [139, 43, 170, 109]], [[['2', 'm'], [159.0, 139.0, 186.0, 140.0, 186.0, 153.0, 158.0, 152.0]], [138, 106, 170, 236]], [[['1', 'm'], [257.0, 139.0, 284.0, 140.0, 284.0, 151.0, 256.0, 152.0]], [137, 237, 168, 305]], [[['1', 'm'], [326.0, 139.0, 351.0, 139.0, 352.0, 152.0, 326.0, 151.0]], [136, 303, 167, 369]]]\n"
     ]
    }
   ],
   "source": [
    "sorted_horizontal_spacings = sorted(horizontal_spacings, key=lambda x: (x[1][1] + x[1][3]) / 2)\n",
    "\n",
    "print(sorted_horizontal_spacings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8be56c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dimension:\n",
    "    def __init__(self, node_1=None, node_2=None, value=None, unit=None, obj_det_bbox=None, text_bbox=None):\n",
    "        self.node_1 = node_1\n",
    "        self.node_2 = node_2\n",
    "        self.value = value\n",
    "        self.unit = unit\n",
    "        self.obj_det_bbox = obj_det_bbox\n",
    "        self.text_bbox = text_bbox\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"Dimension(node_1={self.node_1}, node_2={self.node_2}, value={self.value}, \"\n",
    "                f\"unit={self.unit}, obj_det_bbox={self.obj_det_bbox}, text_bbox={self.text_bbox})\")\n",
    "class Node:\n",
    "    def __init__(self, bbox_x=None, bbox_y=None, shape_x=None, shape_y=None, name=None):\n",
    "        self.bbox_x = bbox_x\n",
    "        self.bbox_y = bbox_y\n",
    "        self.shape_x = shape_x\n",
    "        self.shape_y = shape_y\n",
    "        self.name = name\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Node):\n",
    "            return (self.bbox_x == other.bbox_x and self.bbox_y == other.bbox_y \n",
    "                    and self.shape_x == other.shape_x and self.shape_y == other.shape_y \n",
    "                    and self.name == other.name)\n",
    "        return False\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Node(name={self.name}, bbox_x={self.bbox_x}, bbox_y={self.bbox_y}, shape_x={self.shape_x}, shape_y={self.shape_y})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ac1f0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dimension(node_1=Node(name=None, bbox_x=43, bbox_y=154, shape_x=0, shape_y=0), node_2=Node(name=None, bbox_x=109, bbox_y=154, shape_x=1, shape_y=0), value=1, unit=m, obj_det_bbox=[139, 43, 170, 109], text_bbox=[61.0, 141.0, 88.0, 142.0, 88.0, 153.0, 61.0, 153.0]), Dimension(node_1=Node(name=None, bbox_x=109, bbox_y=154, shape_x=1, shape_y=0), node_2=Node(name=None, bbox_x=236, bbox_y=154, shape_x=3, shape_y=0), value=2, unit=m, obj_det_bbox=[138, 106, 170, 236], text_bbox=[159.0, 139.0, 186.0, 140.0, 186.0, 153.0, 158.0, 152.0]), Dimension(node_1=Node(name=None, bbox_x=236, bbox_y=154, shape_x=3, shape_y=0), node_2=Node(name=None, bbox_x=305, bbox_y=152, shape_x=4, shape_y=0), value=1, unit=m, obj_det_bbox=[137, 237, 168, 305], text_bbox=[257.0, 139.0, 284.0, 140.0, 284.0, 151.0, 256.0, 152.0]), Dimension(node_1=Node(name=None, bbox_x=305, bbox_y=152, shape_x=4, shape_y=0), node_2=Node(name=None, bbox_x=369, bbox_y=151, shape_x=5, shape_y=0), value=1, unit=m, obj_det_bbox=[136, 303, 167, 369], text_bbox=[326.0, 139.0, 351.0, 139.0, 352.0, 152.0, 326.0, 151.0])]\n"
     ]
    }
   ],
   "source": [
    "spacing_instances = []\n",
    "node_instances = []\n",
    "shape_x_start = 0\n",
    "for spacing_number in range(len(sorted_horizontal_spacings)):\n",
    "    if spacing_number == 0:\n",
    "        y1,x1,y2,x2 = sorted_horizontal_spacings[0][1]\n",
    "        distance = sorted_horizontal_spacings[0][0][0][0]\n",
    "        unit = sorted_horizontal_spacings[0][0][0][1]\n",
    "        obj_det_bbox = sorted_horizontal_spacings[0][1]\n",
    "        text_bbox = sorted_horizontal_spacings[0][0][1]\n",
    "        bbox_x = x1\n",
    "        bbox_y = int((y1+y2)/2)\n",
    "        node_1 = Node(bbox_x,bbox_y,shape_x_start,0)\n",
    "        node_instances.append(node_1)\n",
    "        bbox_x = x2\n",
    "        bbox_y = int((y1+y2)/2)\n",
    "        node_2 = Node(bbox_x,bbox_y,shape_x_start+int(distance),0)\n",
    "        node_instances.append(node_2)\n",
    "        spacing = Dimension(node_1, node_2, distance, unit, obj_det_bbox, text_bbox)\n",
    "        spacing_instances.append(spacing)\n",
    "    else:\n",
    "        spacing_data = sorted_horizontal_spacings[spacing_number]\n",
    "        y1,x1,y2,x2 = sorted_horizontal_spacings[spacing_number][1]\n",
    "        for node_info in node_instances:\n",
    "            if np.absolute(node_info.bbox_x - x1) < 20:\n",
    "                distance = sorted_horizontal_spacings[spacing_number][0][0][0]\n",
    "                unit = sorted_horizontal_spacings[spacing_number][0][0][1]\n",
    "                obj_det_bbox = sorted_horizontal_spacings[spacing_number][1]\n",
    "                text_bbox = sorted_horizontal_spacings[spacing_number][0][1]\n",
    "                bbox_x = x2\n",
    "                bbox_y = int((y1+y2)/2)\n",
    "                shape_x = node_info.shape_x + int(distance)\n",
    "                node_2 = Node(bbox_x,bbox_y,shape_x,0)\n",
    "                node_instances.append(node_2)\n",
    "                spacing = Dimension(node_info, node_2, distance, unit, obj_det_bbox, text_bbox)\n",
    "                spacing_instances.append(spacing)\n",
    "                break\n",
    "            elif np.absolute(node_info.bbox_x - x2) < 20:\n",
    "                distance = sorted_horizontal_spacings[spacing_number][0][0][0]\n",
    "                unit = sorted_horizontal_spacings[spacing_number][0][0][1]\n",
    "                obj_det_bbox = sorted_horizontal_spacings[spacing_number][1]\n",
    "                text_bbox = sorted_horizontal_spacings[spacing_number][0][1]\n",
    "                bbox_x = x1\n",
    "                bbox_y = int((y1+y2)/2)\n",
    "                shape_x = node_info.shape_x - int(distance)\n",
    "                node_1 = Node(bbox_x,bbox_y,shape_x,0)\n",
    "                node_instances.append(node_1)\n",
    "                spacing = Dimension(node_1, node_info, distance, unit, obj_det_bbox, text_bbox)\n",
    "                spacing_instances.append(spacing)\n",
    "    \n",
    "\n",
    "print(spacing_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b225a73",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Node(name=None, bbox_x=43, bbox_y=154, shape_x=0, shape_y=0), Node(name=None, bbox_x=109, bbox_y=154, shape_x=1, shape_y=0), Node(name=None, bbox_x=236, bbox_y=154, shape_x=3, shape_y=0), Node(name=None, bbox_x=305, bbox_y=152, shape_x=4, shape_y=0), Node(name=None, bbox_x=369, bbox_y=151, shape_x=5, shape_y=0)]\n"
     ]
    }
   ],
   "source": [
    "print(node_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c32d7677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(x1, y1, x2, y2):\n",
    "    return ((x2 - x1) ** 2 + (y2 - y1) ** 2) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ef8e6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Node(name=A, bbox_x=43, bbox_y=154, shape_x=0, shape_y=0), Node(name=None, bbox_x=109, bbox_y=154, shape_x=1, shape_y=0), Node(name=X, bbox_x=236, bbox_y=154, shape_x=3, shape_y=0), Node(name=D, bbox_x=305, bbox_y=152, shape_x=4, shape_y=0), Node(name=E, bbox_x=369, bbox_y=151, shape_x=5, shape_y=0)]\n"
     ]
    }
   ],
   "source": [
    "# Bound it to image resolution later if needed\n",
    "distance_threshold = 100\n",
    "for text, bbox in ocr_results:\n",
    "    if re.match(r'^[A-Za-z]$', text):  # Check if the text is a single letter (either uppercase or lowercase)\n",
    "        center_x = sum(bbox[i] for i in [0, 2, 4, 6]) / 4\n",
    "        center_y = sum(bbox[i] for i in [1, 3, 5, 7]) / 4\n",
    "        \n",
    "        distances = [(node, calculate_distance(center_x, center_y, node.bbox_x, node.bbox_y)) for node in node_instances]\n",
    "        closest_node, min_distance = min(distances, key=lambda x: x[1])\n",
    "\n",
    "        if min_distance <= distance_threshold:\n",
    "            closest_node.name = text\n",
    "\n",
    "print(node_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d43b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support related operations (class definiton, data preparation) done below this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33fd3e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102, 284, 132, 317, 'roller_support'], [97, 34, 111, 49, 'pin_support']]\n"
     ]
    }
   ],
   "source": [
    "support_bbox = [box for box in filtered_boxes if 'support' in box[-1]]\n",
    "print(support_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d280da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixSupport:\n",
    "    def __init__(self, node=None):\n",
    "        self.node = node\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"FixSupport(node={self.node})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f344e85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PinSupport:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4989e1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RollerSupport:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ed8537a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "fix_support_instances = []\n",
    "\n",
    "for bbox in support_bbox:\n",
    "    if bbox[-1] == 'fix_support':\n",
    "        center_x = (bbox[1] + bbox[3]) / 2\n",
    "        center_y = (bbox[0] + bbox[2]) / 2\n",
    "        \n",
    "        closest_node = min(node_instances, key=lambda node: calculate_distance(center_x, center_y, node.bbox_x, node.bbox_y))\n",
    "        \n",
    "        fix_support_instances.append(FixSupport(node=closest_node))\n",
    "\n",
    "print(fix_support_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed535aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frame related operations done below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec8e4435",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Frame:\n",
    "    def __init__(self, *nodes):\n",
    "        if len(nodes) < 2:\n",
    "            raise ValueError(\"A Frame requires at least two nodes.\")\n",
    "        self.nodes = nodes\n",
    "\n",
    "    def add_node(self, node):\n",
    "        self.nodes = (*self.nodes, node)\n",
    "\n",
    "    def contains(self, node):\n",
    "        x_vals = [n.shape_x for n in self.nodes]\n",
    "        y_vals = [n.shape_y for n in self.nodes]\n",
    "        \n",
    "        return min(x_vals) <= node.shape_x <= max(x_vals) and min(y_vals) <= node.shape_y <= max(y_vals)\n",
    "\n",
    "    def __repr__(self):\n",
    "        nodes_representation = ', '.join([repr(node) for node in self.nodes])\n",
    "        return f\"Frame(nodes=({nodes_representation}))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54ba2990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "frame_boxes = [box for box in filtered_boxes if box[-1] == 'frame']\n",
    "\n",
    "print(frame_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "924113f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "def calculate_distance_x(x1, x2):\n",
    "    return abs(x2 - x1)\n",
    "\n",
    "frame_instances = []\n",
    "\n",
    "for box in frame_boxes:\n",
    "    x1 = box[1]\n",
    "    x2 = box[3]\n",
    "\n",
    "    # Get the closest node to x1 and x2\n",
    "    closest_node_1 = min(node_instances, key=lambda node: calculate_distance_x(x1, node.bbox_x))\n",
    "    closest_node_2 = min(node_instances, key=lambda node: calculate_distance_x(x2, node.bbox_x))\n",
    "\n",
    "    frame_instance = Frame(closest_node_1, closest_node_2)\n",
    "    frame_instances.append(frame_instance)\n",
    "    \n",
    "for frame in frame_instances:\n",
    "    for node in node_instances:\n",
    "        if frame.contains(node) and node not in frame.nodes:\n",
    "            frame.add_node(node)\n",
    "\n",
    "print(frame_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f0acd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point load related operations done below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69ac8c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointLoad:\n",
    "    def __init__(self, node=None, direction=\"+\", value=None, unit=None):\n",
    "        self.node = node\n",
    "        self.direction = direction\n",
    "        self.value = value\n",
    "        self.unit = unit\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"PointLoad(node={self.node}, direction={self.direction}, value={self.value}, unit={self.unit})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d95c869b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22, 99, 102, 116, 'point_load'], [24, 362, 101, 377, 'point_load'], [22, 230, 102, 246, 'point_load']]\n"
     ]
    }
   ],
   "source": [
    "pl_boxes = [box for box in filtered_boxes if box[-1] == 'point_load']\n",
    "print(pl_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b8f3571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(x1, y1, x2, y2):\n",
    "    return ((x2 - x1) ** 2 + (y2 - y1) ** 2) ** 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d67ed2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PointLoad(node=Node(name=None, bbox_x=109, bbox_y=154, shape_x=1, shape_y=0), direction=+, value=None, unit=None), PointLoad(node=Node(name=E, bbox_x=369, bbox_y=151, shape_x=5, shape_y=0), direction=+, value=None, unit=None), PointLoad(node=Node(name=X, bbox_x=236, bbox_y=154, shape_x=3, shape_y=0), direction=+, value=None, unit=None)]\n"
     ]
    }
   ],
   "source": [
    "point_load_instances = []\n",
    "\n",
    "for box in pl_boxes:\n",
    "    center_x = (box[1] + box[3]) / 2\n",
    "    center_y = (box[0] + box[2]) / 2\n",
    "    \n",
    "    closest_node = min(node_instances, key=lambda node: calculate_distance(center_x, center_y, node.bbox_x, node.bbox_y))\n",
    "\n",
    "    # For simplicity, I'm not assigning direction, value, and unit. \n",
    "    # These can be assigned based on further criteria or user input.\n",
    "    pl_instance = PointLoad(node=closest_node)\n",
    "    point_load_instances.append(pl_instance)\n",
    "\n",
    "print(point_load_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b652d644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['10 kN', [115.0, 25.0, 157.0, 24.0, 157.0, 38.0, 115.0, 38.0]], ['20 kN', [244.0, 23.0, 286.0, 22.0, 287.0, 36.0, 244.0, 37.0]], ['A', [22.0, 84.0, 33.0, 84.0, 34.0, 95.0, 23.0, 95.0]], ['B.', [86.0, 82.0, 102.0, 83.0, 103.0, 96.0, 86.0, 94.0]], ['C', [215.0, 81.0, 225.0, 81.0, 226.0, 94.0, 215.0, 94.0]], ['D', [297.0, 81.0, 307.0, 81.0, 307.0, 93.0, 297.0, 93.0]], ['1 m', [61.0, 141.0, 88.0, 142.0, 88.0, 153.0, 61.0, 153.0]], ['2 m', [159.0, 139.0, 186.0, 140.0, 186.0, 153.0, 158.0, 152.0]], ['1 m', [257.0, 139.0, 284.0, 140.0, 284.0, 151.0, 256.0, 152.0]], ['-', [112.0, 146.0, 112.0, 158.0, 103.0, 158.0, 103.0, 146.0]], ['X', [245.0, 158.0, 237.0, 172.0, 225.0, 162.0, 233.0, 148.0]], ['20 kN', [244.0, 23.0, 286.0, 22.0, 287.0, 36.0, 244.0, 37.0]], ['5 kN', [375.0, 22.0, 410.0, 22.0, 409.0, 35.0, 375.0, 35.0]], ['C', [215.0, 81.0, 225.0, 81.0, 226.0, 94.0, 215.0, 94.0]], ['D', [297.0, 81.0, 307.0, 81.0, 307.0, 93.0, 297.0, 93.0]], ['E', [347.0, 79.0, 358.0, 80.0, 357.0, 93.0, 347.0, 92.0]], ['1 m', [257.0, 139.0, 284.0, 140.0, 284.0, 151.0, 256.0, 152.0]], ['1 m', [326.0, 139.0, 351.0, 139.0, 352.0, 152.0, 326.0, 151.0]], ['-', [308.0, 145.0, 308.0, 158.0, 300.0, 157.0, 300.0, 145.0]], ['X', [245.0, 158.0, 237.0, 172.0, 225.0, 162.0, 233.0, 148.0]], ['10 kN', [115.0, 25.0, 157.0, 24.0, 157.0, 38.0, 115.0, 38.0]], ['20 kN', [244.0, 23.0, 286.0, 22.0, 287.0, 36.0, 244.0, 37.0]], ['5 kN', [375.0, 22.0, 410.0, 22.0, 409.0, 35.0, 375.0, 35.0]], ['B.', [86.0, 82.0, 102.0, 83.0, 103.0, 96.0, 86.0, 94.0]], ['C', [215.0, 81.0, 225.0, 81.0, 226.0, 94.0, 215.0, 94.0]], ['D', [297.0, 81.0, 307.0, 81.0, 307.0, 93.0, 297.0, 93.0]], ['E', [347.0, 79.0, 358.0, 80.0, 357.0, 93.0, 347.0, 92.0]], ['1 m', [61.0, 141.0, 88.0, 142.0, 88.0, 153.0, 61.0, 153.0]], ['2 m', [159.0, 139.0, 186.0, 140.0, 186.0, 153.0, 158.0, 152.0]], ['1 m', [257.0, 139.0, 284.0, 140.0, 284.0, 151.0, 256.0, 152.0]], ['1 m', [326.0, 139.0, 351.0, 139.0, 352.0, 152.0, 326.0, 151.0]], ['-', [308.0, 145.0, 308.0, 158.0, 300.0, 157.0, 300.0, 145.0]], ['-', [112.0, 146.0, 112.0, 158.0, 103.0, 158.0, 103.0, 146.0]], ['X', [245.0, 158.0, 237.0, 172.0, 225.0, 162.0, 233.0, 148.0]]]\n"
     ]
    }
   ],
   "source": [
    "def calculate_distance(x1, y1, x2, y2):\n",
    "    return ((x2 - x1) ** 2 + (y2 - y1) ** 2) ** 0.5\n",
    "\n",
    "texts_within_range = []\n",
    "\n",
    "for pl_box in pl_boxes:\n",
    "    pl_center_x = (pl_box[1] + pl_box[3]) / 2\n",
    "    pl_center_y = (pl_box[0] + pl_box[2]) / 2\n",
    "\n",
    "    for text_entry in ocr_results:\n",
    "        text, bbox = text_entry[0], text_entry[1]\n",
    "        center_x = sum(bbox[i] for i in [0, 2, 4, 6]) / 4\n",
    "        center_y = sum(bbox[i] for i in [1, 3, 5, 7]) / 4\n",
    "        \n",
    "        if calculate_distance(pl_center_x, pl_center_y, center_x, center_y) <= 200:\n",
    "            texts_within_range.append(text_entry)\n",
    "\n",
    "print(texts_within_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be48111d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointLoad(node=Node(name=None, bbox_x=109, bbox_y=154, shape_x=1, shape_y=0), direction=+, value=10, unit=kN)\n",
      "PointLoad(node=Node(name=X, bbox_x=236, bbox_y=154, shape_x=3, shape_y=0), direction=+, value=20, unit=kN)\n",
      "PointLoad(node=Node(name=X, bbox_x=236, bbox_y=154, shape_x=3, shape_y=0), direction=+, value=20, unit=kN)\n",
      "PointLoad(node=Node(name=E, bbox_x=369, bbox_y=151, shape_x=5, shape_y=0), direction=+, value=5, unit=kN)\n",
      "PointLoad(node=Node(name=None, bbox_x=109, bbox_y=154, shape_x=1, shape_y=0), direction=+, value=10, unit=kN)\n",
      "PointLoad(node=Node(name=X, bbox_x=236, bbox_y=154, shape_x=3, shape_y=0), direction=+, value=20, unit=kN)\n",
      "PointLoad(node=Node(name=E, bbox_x=369, bbox_y=151, shape_x=5, shape_y=0), direction=+, value=5, unit=kN)\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"(?:[A-Za-z]*\\s*=\\s*)?(?P<value>\\d+)\\s*(?P<unit>kN)\"\n",
    "\n",
    "for text_entry in texts_within_range:\n",
    "    text = text_entry[0]\n",
    "    bbox = text_entry[1]\n",
    "    center_x = sum(bbox[i] for i in [0, 2, 4, 6]) / 4\n",
    "    center_y = sum(bbox[i] for i in [1, 3, 5, 7]) / 4\n",
    "    \n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        value = match.group(\"value\")\n",
    "        unit = match.group(\"unit\")\n",
    "\n",
    "        # Find the closest PointLoad instance\n",
    "        closest_pl = min(point_load_instances, key=lambda pl: calculate_distance(center_x, center_y, pl.node.bbox_x, pl.node.bbox_y))\n",
    "\n",
    "        # Assign the value and unit to the closest PointLoad instance\n",
    "        closest_pl.value = value\n",
    "        closest_pl.unit = unit\n",
    "        print(closest_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "373856ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline till this point is working fine, below is the image recreating phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e097884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Node(name=A, bbox_x=43, bbox_y=154, shape_x=0, shape_y=0), Node(name=None, bbox_x=109, bbox_y=154, shape_x=1, shape_y=0), Node(name=X, bbox_x=236, bbox_y=154, shape_x=3, shape_y=0), Node(name=D, bbox_x=305, bbox_y=152, shape_x=4, shape_y=0), Node(name=E, bbox_x=369, bbox_y=151, shape_x=5, shape_y=0)]\n"
     ]
    }
   ],
   "source": [
    "sorted_nodes = sorted(node_instances, key=lambda node: (node.shape_y, node.shape_x))\n",
    "\n",
    "print(sorted_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c58fd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "---------\n",
      "[PointLoad(node=Node(name=None, bbox_x=109, bbox_y=154, shape_x=1, shape_y=0), direction=+, value=10, unit=kN)]\n",
      "---------\n",
      "[PointLoad(node=Node(name=X, bbox_x=236, bbox_y=154, shape_x=3, shape_y=0), direction=+, value=20, unit=kN)]\n",
      "---------\n",
      "[]\n",
      "---------\n",
      "[PointLoad(node=Node(name=E, bbox_x=369, bbox_y=151, shape_x=5, shape_y=0), direction=+, value=5, unit=kN)]\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "connected_elements = []\n",
    "for node in sorted_nodes:\n",
    "    dummy_list = []\n",
    "    # Check frames\n",
    "    for frame in frame_instances:\n",
    "        if node in frame.nodes:\n",
    "            dummy_list.append(frame)\n",
    "    \n",
    "    # Check fix_supports\n",
    "    for fix_support in fix_support_instances:\n",
    "        if fix_support.node == node:\n",
    "            dummy_list.append(fix_support)\n",
    "\n",
    "    # Check point_loads\n",
    "    for point_load in point_load_instances:\n",
    "        if point_load.node == node:\n",
    "            dummy_list.append(point_load)\n",
    "    connected_elements.append(dummy_list)\n",
    "for element in connected_elements:\n",
    "    print(element)\n",
    "    print(\"---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0dafe1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "created_image_save_dir_path = \"C:\\\\Users\\\\METE\\\\Desktop\\\\created_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91232bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import display\n",
    "\n",
    "def generate_image(width, height):\n",
    "    \"\"\" Generates image\n",
    "    :arg\n",
    "        width : width of image\n",
    "        height : height of image\n",
    "    :return\n",
    "        generated_image : generated image\n",
    "        \"\"\"\n",
    "    generated_image = Image.new('RGBA', (width, height), (255, 255, 255))\n",
    "    return generated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3dca4af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max shape_x: 5, Max shape_y: 0\n"
     ]
    }
   ],
   "source": [
    "def find_max_values(node_instances):\n",
    "    max_shape_x = max(node.shape_x for node in node_instances)\n",
    "    max_shape_y = max(node.shape_y for node in node_instances)\n",
    "    return max_shape_x, max_shape_y\n",
    "max_shape_x, max_shape_y = find_max_values(node_instances)\n",
    "print(f\"Max shape_x: {max_shape_x}, Max shape_y: {max_shape_y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "54b3557b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050 300\n"
     ]
    }
   ],
   "source": [
    "extra_pixels_x = 300\n",
    "extra_pixels_y = 300\n",
    "node_value_pixels = 150\n",
    "def arrange_drawing_area(shape_x, shape_y):\n",
    "    image_width = extra_pixels_y + node_value_pixels * int(shape_x)\n",
    "    image_height = extra_pixels_x + node_value_pixels * int(shape_y)\n",
    "    return image_width, image_height\n",
    "width, height = arrange_drawing_area(max_shape_x, max_shape_y)\n",
    "image = generate_image(width, height)\n",
    "print(width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5ae3aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_frame(frame_instance, img):\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    min_node = min(frame_instance.nodes, key=lambda node: (node.shape_x, node.shape_y))\n",
    "    max_node = max(frame_instance.nodes, key=lambda node: (node.shape_x, node.shape_y))\n",
    "    min_x = extra_pixels_x/2 + node_value_pixels * min_node.shape_x\n",
    "    min_y = extra_pixels_y/2 + node_value_pixels * min_node.shape_y\n",
    "    max_x = extra_pixels_x/2 + node_value_pixels * max_node.shape_x\n",
    "    max_y = extra_pixels_y/2 + node_value_pixels * max_node.shape_y\n",
    "    draw.line((min_x, min_y, max_x, max_y), fill='gray', width=5)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "05fe47d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFont\n",
    "\n",
    "# Define a larger font; 20 is the size, adjust as required\n",
    "font = ImageFont.truetype(\"arial.ttf\", 25)\n",
    "\n",
    "def write_point_load_value_directly(pl_instance, img):\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    start_x = int(extra_pixels_x / 2 + pl_instance.node.shape_x * node_value_pixels)\n",
    "    start_y = int(extra_pixels_y / 2 + pl_instance.node.shape_y * node_value_pixels - arrow_length)\n",
    "    \n",
    "    text = f\"{pl_instance.value} {pl_instance.unit}\"\n",
    "    draw.text((int(start_x)-10, start_y-30), text, fill=\"black\", font=font)  # Subtract 30 instead of 20\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c9ad1cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrow_length = 75\n",
    "def draw_pl(pl_instance, img):\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    node_of_action = pl_instance.node\n",
    "    \n",
    "    # End point (arrow's head)\n",
    "    end_x = extra_pixels_x / 2 + node_of_action.shape_x * node_value_pixels\n",
    "    end_y = extra_pixels_y / 2 + node_of_action.shape_y * node_value_pixels - 3\n",
    "    \n",
    "    # Arrow's tail\n",
    "    start_x = end_x\n",
    "    start_y = end_y - arrow_length\n",
    "\n",
    "    draw.line((start_x, start_y, end_x, end_y-5), fill='green', width=3)\n",
    "    \n",
    "    # Arrowhead points, no need for trigonometry as it's vertical\n",
    "    x1 = end_x - 5  # 5 is half of the arrowhead width\n",
    "    y1 = end_y - 10  # 10 is the arrowhead length\n",
    "    \n",
    "    x2 = end_x + 5\n",
    "    y2 = y1\n",
    "    \n",
    "    draw.polygon([(end_x, end_y), (x1, y1), (x2, y2)], fill=\"green\")\n",
    "    img = write_point_load_value_directly(pl_instance, img)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "74b79b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_direction_from_node(current_node, frame_instances):\n",
    "    direction = None\n",
    "    for frame in frame_instances:\n",
    "        if current_node in frame.nodes:\n",
    "            # Extracting nodes' shape_x and shape_y values\n",
    "            x_values = [node.shape_x for node in frame.nodes]\n",
    "            y_values = [node.shape_y for node in frame.nodes]\n",
    "            \n",
    "            # Check if the frame goes horizontally or vertically from current_node\n",
    "            if max(x_values) == current_node.shape_x:\n",
    "                direction = 'left'\n",
    "            elif min(x_values) == current_node.shape_x:\n",
    "                direction = 'right'\n",
    "            elif max(y_values) == current_node.shape_y:\n",
    "                direction = 'up'\n",
    "            else:\n",
    "                direction = 'down'\n",
    "                \n",
    "            break  # Once we found the frame, exit the loop\n",
    "            \n",
    "    return direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d34066c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_fix_support(fs_instance, img):\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    node = fs_instance.node\n",
    "    frame_direction = frame_direction_from_node(node, frame_instances)\n",
    "    if frame_direction == \"right\":\n",
    "         # End point (arrow's head)\n",
    "        center_x = extra_pixels_x / 2 + node.shape_x * node_value_pixels\n",
    "        center_y = extra_pixels_y / 2 + node.shape_y * node_value_pixels\n",
    "        start_x,start_y = center_x-12, center_y-50\n",
    "        for i in range(10):\n",
    "            end_x, end_y = start_x+12, start_y+5\n",
    "            draw.line((start_x, start_y, end_x, end_y), fill='black', width=2)\n",
    "            start_y +=10\n",
    "        draw.line((center_x, center_y-50, center_x, center_y+50), fill='black', width=2)\n",
    "    # Fill this later\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2d95fd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=1050x300>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for element in connected_elements:\n",
    "    for sub_element in element:\n",
    "        has_frame = isinstance(sub_element, Frame)\n",
    "        if has_frame:\n",
    "            image = draw_frame(sub_element, image)\n",
    "            \n",
    "        # Similarly, you can check for other classes too if needed\n",
    "        has_point_load = isinstance(sub_element, PointLoad)\n",
    "        if has_point_load:\n",
    "            image = draw_pl(sub_element, image)\n",
    "        has_fix_support = isinstance(sub_element, FixSupport)\n",
    "        if has_fix_support:\n",
    "            # Do something if the sub_element is an instance of FixSupport\n",
    "            image = draw_fix_support(sub_element, image)\n",
    "display(image)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6b6bfa96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=1050x300>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pixel_difference = 65\n",
    "def draw_dimension(dimensions, img):\n",
    "    \"\"\"\n",
    "    Draws dimensions on a given image based on the provided Dimension instances.\n",
    "    \n",
    "    Args:\n",
    "    - dimensions (list): List of Dimension objects.\n",
    "    - img (Image): PIL Image object where the dimensions should be drawn.\n",
    "    \n",
    "    Returns:\n",
    "    - Modified Image object with lines drawn and texts added.\n",
    "    \"\"\"\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    font = ImageFont.truetype(\"arial.ttf\", 25)  # Adjust as necessary\n",
    "    line_color = 'black'\n",
    "\n",
    "    for dimension in dimensions:\n",
    "        # Use shape_x of node_1 and node_2 for determining x-coordinates and offset it by extra_pixels_x/2.\n",
    "        start_x = dimension.node_1.shape_x * node_value_pixels + extra_pixels_x/2\n",
    "        start_y = extra_pixels_y/2 + pixel_difference\n",
    "        end_x = dimension.node_2.shape_x * node_value_pixels + extra_pixels_x/2\n",
    "        end_y = start_y\n",
    "\n",
    "        # Draw the horizontal line\n",
    "        draw.line((start_x, start_y, end_x, end_y), fill=line_color, width=2)\n",
    "\n",
    "        # Draw the vertical lines at the start and end of each horizontal line\n",
    "        draw.line((start_x, start_y - 8, start_x, start_y + 8), fill=line_color, width=2)\n",
    "        draw.line((end_x, end_y - 8, end_x, end_y + 8), fill=line_color, width=2)\n",
    "\n",
    "        # Write the value and unit just below the horizontal line\n",
    "        text_x = (start_x + end_x) / 2 - 10  # A small offset to center the text\n",
    "        text_y = end_y + 5  # A small offset to place the text below the line\n",
    "        draw.text((text_x, text_y), f\"{dimension.value} {dimension.unit}\", fill=line_color, font=font)\n",
    "\n",
    "    return img\n",
    "\n",
    "# Example usage:\n",
    "image = draw_dimension(spacing_instances, image)\n",
    "display(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "751d8cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=1050x300>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pixel_difference = 15\n",
    "def label_nodes(node_instances, img):\n",
    "    \"\"\"\n",
    "    Adds labels (node names) to the nodes on the given image.\n",
    "    \n",
    "    Args:\n",
    "    - node_instances (list): List of Node objects.\n",
    "    - img (Image): PIL Image object where the node names should be written.\n",
    "    \n",
    "    Returns:\n",
    "    - Modified Image object with node names written.\n",
    "    \"\"\"\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    font = ImageFont.truetype(\"arial.ttf\", 25)\n",
    "    \n",
    "    for node in node_instances:\n",
    "        if node.name:  # Only label nodes that have a name\n",
    "            x = node.shape_x * node_value_pixels + extra_pixels_x/2 - 30\n",
    "            y = node.shape_y * node_value_pixels + extra_pixels_y/2 - pixel_difference\n",
    "\n",
    "            draw.text((x, y), node.name, font=font, fill=\"black\")\n",
    "    \n",
    "    return img\n",
    "\n",
    "image = label_nodes(node_instances, image)\n",
    "display(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ffbb3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_path = image_path\n",
    "output_path = os.path.join(created_image_save_dir_path, \"output.pdf\")\n",
    "\n",
    "import os\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from PyPDF2 import PdfMerger\n",
    "\n",
    "def create_pdf_pages(image, image_path, output_path):\n",
    "    # Function to center text or images\n",
    "    def calculate_centered_position(draw, text, font, page_width, y_position):\n",
    "        text_width, text_height = draw.textsize(text, font=font)\n",
    "        return ((page_width - text_width) / 2, y_position)\n",
    "    \n",
    "    # Page setup\n",
    "    page_width = 595\n",
    "    page_height = 842\n",
    "    \n",
    "    # Create a blank A4 size white background for first page\n",
    "    pdf_page1 = Image.new('RGB', (page_width, page_height), 'white')\n",
    "    draw1 = ImageDraw.Draw(pdf_page1)\n",
    "    \n",
    "    # Create a blank A4 size white background for second page\n",
    "    pdf_page2 = Image.new('RGB', (page_width, page_height), 'white')\n",
    "    draw2 = ImageDraw.Draw(pdf_page2)\n",
    "    \n",
    "    # Load fonts\n",
    "    header_font = ImageFont.truetype(\"arial.ttf\", 24)\n",
    "    title_font = ImageFont.truetype(\"arial.ttf\", 24)\n",
    "    \n",
    "    # Insert \"Gnderilen Resim / Input Image\" at the top of the first page\n",
    "    x, y = calculate_centered_position(draw1, \"Gnderilen Resim / Input Image\", header_font, page_width, 20)\n",
    "    draw1.text((x, y), \"Gnderilen Resim / Input Image\", font=header_font, fill=\"black\")\n",
    "    \n",
    "    # Load and insert the input image below the header on the first page\n",
    "    input_img = Image.open(image_path)\n",
    "    input_img = input_img.resize((495, int(495/input_img.width * input_img.height)))  # maintain aspect ratio\n",
    "    x, y = (page_width - input_img.width) // 2, y + 50\n",
    "    pdf_page1.paste(input_img, (x, y))\n",
    "    \n",
    "    # Calculate starting y-position for the detected image based on the height of the input image\n",
    "    detected_img_start_y = y + input_img.height + 30\n",
    "    \n",
    "    # Insert \"Alglanan ekil / Detected Shape\" below the input image on the first page\n",
    "    x, y = calculate_centered_position(draw1, \"Alglanan ekil / Detected Shape\", title_font, page_width, detected_img_start_y)\n",
    "    draw1.text((x, y), \"Alglanan ekil / Detected Shape\", font=title_font, fill=\"black\")\n",
    "    \n",
    "    # Resize the detected image to fit within the PDF and maintain its aspect ratio\n",
    "    detected_img = image.resize((495, int(495/image.width * image.height)))\n",
    "    x, y = (page_width - detected_img.width) // 2, y + 40\n",
    "    pdf_page1.paste(detected_img, (x, y))\n",
    "    \n",
    "    # Insert \"zm/ Solution\" at the top of the second page\n",
    "    x, y = calculate_centered_position(draw2, \"zm/ Solution\", header_font, page_width, 20)\n",
    "    draw2.text((x, y), \"zm/ Solution\", font=header_font, fill=\"black\")\n",
    "    \n",
    "    # Save individual pages as PDF\n",
    "    temp_output_path_1 = \"temp_page1.pdf\"\n",
    "    temp_output_path_2 = \"temp_page2.pdf\"\n",
    "    pdf_page1.save(temp_output_path_1, \"PDF\")\n",
    "    pdf_page2.save(temp_output_path_2, \"PDF\")\n",
    "    \n",
    "    # Use PyPDF2 to merge the two pages\n",
    "    merger = PdfMerger()\n",
    "    with open(temp_output_path_1, 'rb') as file1, open(temp_output_path_2, 'rb') as file2:\n",
    "        merger.append(file1)\n",
    "        merger.append(file2)\n",
    "        with open(output_path, \"wb\") as output_pdf:\n",
    "            merger.write(output_pdf)\n",
    "\n",
    "    # Clean up temporary files\n",
    "    os.remove(temp_output_path_1)\n",
    "    os.remove(temp_output_path_2)\n",
    "\n",
    "# Use the function\n",
    "create_pdf_pages(image, input_image_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6027857d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb2945e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7644a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
